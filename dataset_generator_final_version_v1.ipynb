{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-dGHbvRQC5-"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üéØ VALENTINA DATASET GENERATOR v4.0 - COMERCIAL EDITION\n",
        "# =============================================================================\n",
        "#\n",
        "# üé® OBJETIVO: Gerar dataset premium da Valentina Moreau para uso comercial\n",
        "# üíé ESTRAT√âGIA: Union ControlNet + Valida√ß√£o Autom√°tica + Qualidade Comercial\n",
        "# üöÄ PLATAFORMA: Google Colab otimizado para A100/V100\n",
        "# üí∞ FOCO: Monetiza√ß√£o em TopFans, OnlyFans e plataformas similares\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üéØ VALENTINA DATASET GENERATOR v4.0 - COMERCIAL EDITION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"üé® Estrat√©gia: Union ControlNet + Valida√ß√£o Comercial Autom√°tica\")\n",
        "print(\"üíé Objetivo: Dataset premium para modelo digital Valentina Moreau\")\n",
        "print(\"üöÄ Plataforma: Google Colab A100/V100 otimizado\")\n",
        "print(\"üí∞ Foco: Monetiza√ß√£o comercial em plataformas premium\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# üìã FASE 1: SETUP GOOGLE COLAB OTIMIZADO\n",
        "# =============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 1.1: DETEC√á√ÉO E CONFIGURA√á√ÉO DO AMBIENTE\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import psutil\n",
        "import json\n",
        "from typing import Dict, Tuple, Optional\n",
        "\n",
        "def detect_gpu_environment() -> Dict:\n",
        "    \"\"\"\n",
        "    Detecta automaticamente o ambiente GPU e configura otimiza√ß√µes espec√≠ficas\n",
        "\n",
        "    Returns:\n",
        "        Dict com informa√ß√µes completas do ambiente GPU\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüîç DETEC√á√ÉO AUTOM√ÅTICA DO AMBIENTE GPU\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    gpu_info = {\n",
        "        'name': 'Unknown',\n",
        "        'memory_total': 0,\n",
        "        'memory_free': 0,\n",
        "        'tier': 'unknown',\n",
        "        'recommended_config': {},\n",
        "        'cuda_version': 'unknown'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Detectar informa√ß√µes da GPU via nvidia-smi\n",
        "        result = subprocess.run([\n",
        "            'nvidia-smi',\n",
        "            '--query-gpu=name,memory.total,memory.free,driver_version',\n",
        "            '--format=csv,noheader,nounits'\n",
        "        ], capture_output=True, text=True, check=True)\n",
        "\n",
        "        gpu_data = result.stdout.strip().split(', ')\n",
        "        gpu_info['name'] = gpu_data[0].strip()\n",
        "        gpu_info['memory_total'] = int(gpu_data[1])\n",
        "        gpu_info['memory_free'] = int(gpu_data[2])\n",
        "        gpu_info['driver_version'] = gpu_data[3].strip()\n",
        "\n",
        "        print(f\"üñ•Ô∏è GPU Detectada: {gpu_info['name']}\")\n",
        "        print(f\"üíæ VRAM Total: {gpu_info['memory_total']:,} MB\")\n",
        "        print(f\"üíæ VRAM Livre: {gpu_info['memory_free']:,} MB\")\n",
        "        print(f\"üîß Driver: {gpu_info['driver_version']}\")\n",
        "\n",
        "        # Detectar vers√£o CUDA\n",
        "        try:\n",
        "            cuda_result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
        "            if cuda_result.returncode == 0:\n",
        "                cuda_line = [line for line in cuda_result.stdout.split('\\n') if 'release' in line]\n",
        "                if cuda_line:\n",
        "                    cuda_version = cuda_line[0].split('release ')[1].split(',')[0]\n",
        "                    gpu_info['cuda_version'] = cuda_version\n",
        "                    print(f\"üéØ CUDA: {cuda_version}\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è CUDA nvcc n√£o detectado via nvcc, usando configura√ß√£o padr√£o\")\n",
        "\n",
        "        # Classificar GPU e configurar otimiza√ß√µes espec√≠ficas\n",
        "        gpu_name = gpu_info['name'].upper()\n",
        "\n",
        "        if 'A100' in gpu_name:\n",
        "            gpu_info['tier'] = 'premium'\n",
        "            gpu_info['recommended_config'] = {\n",
        "                'dtype': 'bfloat16',\n",
        "                'enable_cpu_offload': False,\n",
        "                'inference_steps': 28,\n",
        "                'guidance_scale': 3.5,\n",
        "                'batch_size': 4,\n",
        "                'max_resolution': 1024,\n",
        "                'enable_attention_slicing': False,\n",
        "                'enable_tf32': True,\n",
        "                'enable_flash_attention': True\n",
        "            }\n",
        "            print(\"üî• TIER: PREMIUM (A100) - Configura√ß√£o m√°xima qualidade\")\n",
        "\n",
        "        elif 'V100' in gpu_name:\n",
        "            gpu_info['tier'] = 'high'\n",
        "            gpu_info['recommended_config'] = {\n",
        "                'dtype': 'float16',\n",
        "                'enable_cpu_offload': False,\n",
        "                'inference_steps': 24,\n",
        "                'guidance_scale': 3.5,\n",
        "                'batch_size': 2,\n",
        "                'max_resolution': 1024,\n",
        "                'enable_attention_slicing': False,\n",
        "                'enable_tf32': True,\n",
        "                'enable_flash_attention': True\n",
        "            }\n",
        "            print(\"üíé TIER: HIGH (V100) - Configura√ß√£o high-end\")\n",
        "\n",
        "        elif any(gpu_type in gpu_name for gpu_type in ['T4', 'P100', 'K80']):\n",
        "            gpu_info['tier'] = 'standard'\n",
        "            gpu_info['recommended_config'] = {\n",
        "                'dtype': 'float16',\n",
        "                'enable_cpu_offload': True,\n",
        "                'inference_steps': 20,\n",
        "                'guidance_scale': 3.0,\n",
        "                'batch_size': 1,\n",
        "                'max_resolution': 768,\n",
        "                'enable_attention_slicing': True,\n",
        "                'enable_tf32': False,\n",
        "                'enable_flash_attention': False\n",
        "            }\n",
        "            print(\"üì± TIER: STANDARD - Configura√ß√£o otimizada para efici√™ncia\")\n",
        "\n",
        "        else:\n",
        "            gpu_info['tier'] = 'fallback'\n",
        "            gpu_info['recommended_config'] = {\n",
        "                'dtype': 'float16',\n",
        "                'enable_cpu_offload': True,\n",
        "                'inference_steps': 16,\n",
        "                'guidance_scale': 2.5,\n",
        "                'batch_size': 1,\n",
        "                'max_resolution': 512,\n",
        "                'enable_attention_slicing': True,\n",
        "                'enable_tf32': False,\n",
        "                'enable_flash_attention': False\n",
        "            }\n",
        "            print(\"‚ö° TIER: FALLBACK - Configura√ß√£o conservadora\")\n",
        "\n",
        "        # Verificar se h√° VRAM suficiente para opera√ß√£o comercial\n",
        "        min_vram_required = {\n",
        "            'premium': 24000,    # A100 requer pelo menos 24GB\n",
        "            'high': 16000,       # V100 requer pelo menos 16GB\n",
        "            'standard': 8000,    # T4 requer pelo menos 8GB\n",
        "            'fallback': 4000     # M√≠nimo absoluto\n",
        "        }\n",
        "\n",
        "        required_vram = min_vram_required.get(gpu_info['tier'], 4000)\n",
        "\n",
        "        if gpu_info['memory_total'] >= required_vram:\n",
        "            print(f\"‚úÖ VRAM Adequada: {gpu_info['memory_total']:,}MB >= {required_vram:,}MB requeridos\")\n",
        "            gpu_info['vram_adequate'] = True\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è VRAM Limitada: {gpu_info['memory_total']:,}MB < {required_vram:,}MB requeridos\")\n",
        "            print(\"üîß Aplicando otimiza√ß√µes de mem√≥ria adicionais...\")\n",
        "            gpu_info['vram_adequate'] = False\n",
        "            # Ajustar configura√ß√µes para VRAM limitada\n",
        "            gpu_info['recommended_config']['enable_cpu_offload'] = True\n",
        "            gpu_info['recommended_config']['enable_attention_slicing'] = True\n",
        "            gpu_info['recommended_config']['batch_size'] = 1\n",
        "\n",
        "        # Detectar RAM do sistema\n",
        "        system_ram = psutil.virtual_memory().total // (1024**3)  # GB\n",
        "        print(f\"üñ•Ô∏è RAM Sistema: {system_ram}GB\")\n",
        "        gpu_info['system_ram_gb'] = system_ram\n",
        "\n",
        "        if system_ram < 12:\n",
        "            print(\"‚ö†Ô∏è RAM do sistema limitada - ativando otimiza√ß√µes de mem√≥ria\")\n",
        "            gpu_info['recommended_config']['enable_cpu_offload'] = True\n",
        "\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"‚ùå Erro ao detectar GPU via nvidia-smi\")\n",
        "        print(\"üîß Usando configura√ß√£o fallback conservadora\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado na detec√ß√£o: {e}\")\n",
        "        print(\"üîß Usando configura√ß√£o fallback conservadora\")\n",
        "\n",
        "    return gpu_info\n",
        "\n",
        "def configure_torch_optimizations(gpu_info: Dict) -> None:\n",
        "    \"\"\"\n",
        "    Configura otimiza√ß√µes do PyTorch baseadas na GPU detectada\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n‚öôÔ∏è CONFIGURANDO OTIMIZA√á√ïES PYTORCH PARA {gpu_info['tier'].upper()}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    import torch\n",
        "\n",
        "    # Configura√ß√µes base sempre aplicadas\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    print(\"‚úÖ CUDNN benchmark ativado\")\n",
        "\n",
        "    # Configura√ß√µes espec√≠ficas por tier\n",
        "    config = gpu_info['recommended_config']\n",
        "\n",
        "    if config.get('enable_tf32', False):\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "        print(\"‚úÖ TF32 ativado para performance em Ampere/Ada\")\n",
        "\n",
        "    # Configurar device placement\n",
        "    if torch.cuda.is_available():\n",
        "        device_count = torch.cuda.device_count()\n",
        "        current_device = torch.cuda.current_device()\n",
        "        device_name = torch.cuda.get_device_name(current_device)\n",
        "\n",
        "        print(f\"üéØ CUDA Devices: {device_count}\")\n",
        "        print(f\"üéØ Device Atual: {current_device} ({device_name})\")\n",
        "        print(f\"üéØ CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "        # Configurar cache do CUDA\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"üßπ Cache CUDA limpo\")\n",
        "\n",
        "        # Definir dtype recomendado globalmente\n",
        "        dtype_str = config.get('dtype', 'float16')\n",
        "        if dtype_str == 'bfloat16':\n",
        "            recommended_dtype = torch.bfloat16\n",
        "            print(\"üéØ Dtype: bfloat16 (optimal for FLUX)\")\n",
        "        else:\n",
        "            recommended_dtype = torch.float16\n",
        "            print(\"üéØ Dtype: float16 (compatible)\")\n",
        "\n",
        "        # Salvar configura√ß√£o para uso posterior\n",
        "        gpu_info['torch_dtype'] = recommended_dtype\n",
        "        gpu_info['device'] = f\"cuda:{current_device}\"\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå CUDA n√£o dispon√≠vel - usando CPU (n√£o recomendado para comercial)\")\n",
        "        gpu_info['torch_dtype'] = torch.float32\n",
        "        gpu_info['device'] = \"cpu\"\n",
        "\n",
        "    # Imprimir resumo da configura√ß√£o\n",
        "    print(f\"\\nüìä CONFIGURA√á√ÉO FINAL:\")\n",
        "    for key, value in config.items():\n",
        "        print(f\"   ‚Ä¢ {key}: {value}\")\n",
        "\n",
        "    return gpu_info\n",
        "\n",
        "# Executar detec√ß√£o autom√°tica\n",
        "print(\"üöÄ Iniciando detec√ß√£o autom√°tica do ambiente...\")\n",
        "GPU_CONFIG = detect_gpu_environment()\n",
        "GPU_CONFIG = configure_torch_optimizations(GPU_CONFIG)\n",
        "\n",
        "print(f\"\\n‚úÖ AMBIENTE CONFIGURADO:\")\n",
        "print(f\"   üéØ GPU: {GPU_CONFIG['name']} ({GPU_CONFIG['tier'].upper()})\")\n",
        "print(f\"   üíæ VRAM: {GPU_CONFIG['memory_total']:,}MB\")\n",
        "print(f\"   üé® Qualidade: {'COMERCIAL' if GPU_CONFIG['vram_adequate'] else 'OTIMIZADA'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 1.2: INSTALA√á√ÉO DE DEPEND√äNCIAS ZERO-CONFLITO\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def install_dependencies_zero_conflict():\n",
        "    \"\"\"\n",
        "    Instala stack otimizado sem conflitos para FLUX ControlNet comercial\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüì¶ INSTALA√á√ÉO DE DEPEND√äNCIAS ZERO-CONFLITO\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"üéØ Stack: PyTorch 2.5+ + Diffusers 0.33.0+ + ControlNet-Aux + Valida√ß√£o Facial\")\n",
        "    print(\"‚öôÔ∏è Estrat√©gia: Instala√ß√£o em fases para evitar conflitos\")\n",
        "    print(\"üîß Baseado em pesquisa t√©cnica para m√°xima compatibilidade\")\n",
        "\n",
        "    # Verificar se j√° temos as depend√™ncias principais\n",
        "    try:\n",
        "        import torch\n",
        "        import diffusers\n",
        "        print(f\"üì¶ PyTorch j√° instalado: {torch.__version__}\")\n",
        "        print(f\"üì¶ Diffusers j√° instalado: {diffusers.__version__}\")\n",
        "\n",
        "        # Verificar se vers√µes s√£o adequadas\n",
        "        torch_version = torch.__version__.split('+')[0]  # Remove CUDA suffix\n",
        "        diffusers_version = diffusers.__version__\n",
        "\n",
        "        torch_adequate = tuple(map(int, torch_version.split('.')[:2])) >= (2, 5)\n",
        "        diffusers_adequate = tuple(map(int, diffusers_version.split('.')[:2])) >= (0, 33)\n",
        "\n",
        "        if torch_adequate and diffusers_adequate:\n",
        "            print(\"‚úÖ Vers√µes adequadas detectadas - pulando reinstala√ß√£o do core\")\n",
        "            skip_core_install = True\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Vers√µes inadequadas - ser√° necess√°rio atualizar\")\n",
        "            skip_core_install = False\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"üì¶ Depend√™ncias principais n√£o encontradas - instala√ß√£o completa necess√°ria\")\n",
        "        skip_core_install = False\n",
        "\n",
        "    if not skip_core_install:\n",
        "        print(\"\\nüîß FASE 1: CORE DEPENDENCIES (PyTorch + CUDA)\")\n",
        "\n",
        "        # Instalar PyTorch com CUDA espec√≠fico\n",
        "        torch_install_cmd = [\n",
        "            sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\",\n",
        "            \"torch>=2.5.0\", \"torchvision>=0.20.0\", \"torchaudio>=2.5.0\",\n",
        "            \"--index-url\", \"https://download.pytorch.org/whl/cu124\"\n",
        "        ]\n",
        "\n",
        "        print(\"‚è≥ Instalando PyTorch 2.5+ com CUDA 12.4...\")\n",
        "        result = subprocess.run(torch_install_cmd, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ PyTorch instalado com sucesso\")\n",
        "        else:\n",
        "            print(f\"‚ùå Erro na instala√ß√£o do PyTorch: {result.stderr}\")\n",
        "            raise Exception(\"Falha na instala√ß√£o do PyTorch\")\n",
        "\n",
        "    print(\"\\nüîß FASE 2: DIFFUSION STACK (Diffusers + Transformers)\")\n",
        "\n",
        "    # Instalar diffusers e transformers com vers√µes espec√≠ficas\n",
        "    diffusion_packages = [\n",
        "        \"diffusers>=0.33.0\",\n",
        "        \"transformers>=4.48.0\",\n",
        "        \"accelerate>=1.0.0\",\n",
        "        \"safetensors>=0.4.3\",\n",
        "        \"huggingface-hub>=0.32.0\"\n",
        "    ]\n",
        "\n",
        "    for package in diffusion_packages:\n",
        "        print(f\"‚è≥ Instalando {package}...\")\n",
        "        result = subprocess.run([\n",
        "            sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úÖ {package} instalado\")\n",
        "        else:\n",
        "            print(f\"‚ùå Erro em {package}: {result.stderr}\")\n",
        "\n",
        "    print(\"\\nüîß FASE 3: CONTROLNET & PROCESSAMENTO\")\n",
        "\n",
        "    # ControlNet e processadores de imagem\n",
        "    controlnet_packages = [\n",
        "        \"controlnet-aux>=0.0.10\",\n",
        "        \"opencv-python-headless>=4.8.0\",\n",
        "        \"scikit-image>=0.24.0\"\n",
        "    ]\n",
        "\n",
        "    for package in controlnet_packages:\n",
        "        print(f\"‚è≥ Instalando {package}...\")\n",
        "        result = subprocess.run([\n",
        "            sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úÖ {package} instalado\")\n",
        "        else:\n",
        "            print(f\"‚ùå Erro em {package}: {result.stderr}\")\n",
        "\n",
        "    print(\"\\nüîß FASE 4: VALIDA√á√ÉO FACIAL & QUALIDADE\")\n",
        "\n",
        "    # Bibliotecas para valida√ß√£o facial e qualidade comercial\n",
        "    validation_packages = [\n",
        "        \"insightface>=0.7.0\",\n",
        "        \"onnxruntime-gpu>=1.16.0\",\n",
        "        \"lpips>=0.1.4\",\n",
        "        \"facexlib>=0.3.0\"\n",
        "    ]\n",
        "\n",
        "    for package in validation_packages:\n",
        "        print(f\"‚è≥ Instalando {package}...\")\n",
        "        try:\n",
        "            result = subprocess.run([\n",
        "                sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package\n",
        "            ], capture_output=True, text=True, timeout=300)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                print(f\"‚úÖ {package} instalado\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è {package} falhou - continuando sem valida√ß√£o facial avan√ßada\")\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"‚ö†Ô∏è {package} timeout - pulando\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è {package} erro: {e} - pulando\")\n",
        "\n",
        "    print(\"\\nüîß FASE 5: UTILIT√ÅRIOS & OPTIMIZA√á√ÉO\")\n",
        "\n",
        "    # Utilit√°rios finais\n",
        "    utility_packages = [\n",
        "        \"pillow>=10.0.0\",\n",
        "        \"numpy>=1.24.0\",\n",
        "        \"matplotlib>=3.7.0\",\n",
        "        \"tqdm>=4.66.0\",\n",
        "        \"psutil>=5.9.0\"\n",
        "    ]\n",
        "\n",
        "    for package in utility_packages:\n",
        "        print(f\"‚è≥ Instalando {package}...\")\n",
        "        result = subprocess.run([\n",
        "            sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úÖ {package} instalado\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è {package} falhou - usando vers√£o dispon√≠vel\")\n",
        "\n",
        "def verify_installation_compatibility():\n",
        "    \"\"\"\n",
        "    Verifica compatibilidade total do stack instalado\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüîç VERIFICA√á√ÉO DE COMPATIBILIDADE DO STACK\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    compatibility_report = {\n",
        "        'core_packages': {},\n",
        "        'flux_support': False,\n",
        "        'controlnet_support': False,\n",
        "        'validation_support': False,\n",
        "        'overall_status': 'unknown'\n",
        "    }\n",
        "\n",
        "    # Verificar pacotes principais\n",
        "    core_packages = {\n",
        "        'torch': '2.5.0',\n",
        "        'diffusers': '0.33.0',\n",
        "        'transformers': '4.48.0',\n",
        "        'accelerate': '1.0.0'\n",
        "    }\n",
        "\n",
        "    print(\"üì¶ VERIFICANDO PACOTES PRINCIPAIS:\")\n",
        "    for package, min_version in core_packages.items():\n",
        "        try:\n",
        "            module = __import__(package)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "            compatibility_report['core_packages'][package] = version\n",
        "            print(f\"   ‚úÖ {package}: {version}\")\n",
        "        except ImportError:\n",
        "            print(f\"   ‚ùå {package}: N√ÉO INSTALADO\")\n",
        "            compatibility_report['core_packages'][package] = None\n",
        "\n",
        "    # Verificar suporte ao FLUX ControlNet\n",
        "    print(\"\\nüéÆ VERIFICANDO SUPORTE FLUX CONTROLNET:\")\n",
        "    try:\n",
        "        from diffusers import FluxControlNetPipeline, FluxControlNetModel\n",
        "        print(\"   ‚úÖ FluxControlNetPipeline: Dispon√≠vel\")\n",
        "        print(\"   ‚úÖ FluxControlNetModel: Dispon√≠vel\")\n",
        "        compatibility_report['flux_support'] = True\n",
        "    except ImportError as e:\n",
        "        print(f\"   ‚ùå FLUX ControlNet: {e}\")\n",
        "        # Tentar import alternativo\n",
        "        try:\n",
        "            from diffusers.models.controlnets.controlnet_flux import FluxControlNetModel\n",
        "            from diffusers.pipelines.flux.pipeline_flux_controlnet import FluxControlNetPipeline\n",
        "            print(\"   ‚úÖ FLUX ControlNet: Dispon√≠vel via import alternativo\")\n",
        "            compatibility_report['flux_support'] = True\n",
        "        except ImportError:\n",
        "            print(\"   ‚ùå FLUX ControlNet: N√ÉO DISPON√çVEL\")\n",
        "            compatibility_report['flux_support'] = False\n",
        "\n",
        "    # Verificar processadores ControlNet\n",
        "    print(\"\\nüîß VERIFICANDO PROCESSADORES CONTROLNET:\")\n",
        "    try:\n",
        "        from controlnet_aux import CannyDetector, MidasDetector\n",
        "        print(\"   ‚úÖ CannyDetector: Dispon√≠vel\")\n",
        "        print(\"   ‚úÖ MidasDetector: Dispon√≠vel\")\n",
        "        compatibility_report['controlnet_support'] = True\n",
        "    except ImportError as e:\n",
        "        print(f\"   ‚ö†Ô∏è Alguns processadores indispon√≠veis: {e}\")\n",
        "        compatibility_report['controlnet_support'] = False\n",
        "\n",
        "    # Verificar valida√ß√£o facial\n",
        "    print(\"\\nüë§ VERIFICANDO VALIDA√á√ÉO FACIAL:\")\n",
        "    try:\n",
        "        import insightface\n",
        "        print(\"   ‚úÖ InsightFace: Dispon√≠vel\")\n",
        "        compatibility_report['validation_support'] = True\n",
        "    except ImportError:\n",
        "        print(\"   ‚ö†Ô∏è InsightFace: Indispon√≠vel - valida√ß√£o facial b√°sica apenas\")\n",
        "        compatibility_report['validation_support'] = False\n",
        "\n",
        "    # Status geral\n",
        "    if (compatibility_report['flux_support'] and\n",
        "        compatibility_report['controlnet_support']):\n",
        "        compatibility_report['overall_status'] = 'excellent'\n",
        "        status_msg = \"üî• EXCELENTE - Pronto para gera√ß√£o comercial premium\"\n",
        "    elif compatibility_report['flux_support']:\n",
        "        compatibility_report['overall_status'] = 'good'\n",
        "        status_msg = \"‚úÖ BOM - Funcionalidades principais dispon√≠veis\"\n",
        "    else:\n",
        "        compatibility_report['overall_status'] = 'limited'\n",
        "        status_msg = \"‚ö†Ô∏è LIMITADO - Algumas funcionalidades podem n√£o funcionar\"\n",
        "\n",
        "    print(f\"\\nüìä STATUS GERAL: {status_msg}\")\n",
        "\n",
        "    return compatibility_report\n",
        "\n",
        "# Executar instala√ß√£o e verifica√ß√£o\n",
        "print(\"üöÄ Iniciando instala√ß√£o de depend√™ncias...\")\n",
        "install_dependencies_zero_conflict()\n",
        "COMPATIBILITY_REPORT = verify_installation_compatibility()"
      ],
      "metadata": {
        "id": "Urm43VbpQJfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 1.3: ESTRUTURA DE DIRET√ìRIOS E CONFIGURA√á√ÉO\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def setup_directory_structure():\n",
        "    \"\"\"\n",
        "    Cria estrutura de diret√≥rios otimizada para produ√ß√£o comercial\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìÅ CONFIGURANDO ESTRUTURA DE DIRET√ìRIOS\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Estrutura base do projeto\n",
        "    base_structure = {\n",
        "        '/content/valentina_dataset_v4': 'Diret√≥rio principal do dataset',\n",
        "        '/content/valentina_dataset_v4/generated_images': 'Imagens geradas aprovadas',\n",
        "        '/content/valentina_dataset_v4/reference_images': 'Imagens de refer√™ncia',\n",
        "        '/content/valentina_dataset_v4/control_images': 'Imagens processadas para ControlNet',\n",
        "        '/content/valentina_dataset_v4/metadata': 'Metadados e logs',\n",
        "        '/content/valentina_dataset_v4/quality_reports': 'Relat√≥rios de qualidade',\n",
        "        '/content/valentina_dataset_v4/rejected_images': 'Imagens rejeitadas na valida√ß√£o',\n",
        "        '/content/models_cache': 'Cache de modelos baixados',\n",
        "        '/content/temp_processing': 'Processamento tempor√°rio'\n",
        "    }\n",
        "\n",
        "    created_dirs = []\n",
        "\n",
        "    for dir_path, description in base_structure.items():\n",
        "        try:\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "            created_dirs.append(dir_path)\n",
        "            print(f\"üìÇ {dir_path} - {description}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro criando {dir_path}: {e}\")\n",
        "\n",
        "    print(f\"\\n‚úÖ {len(created_dirs)} diret√≥rios criados com sucesso\")\n",
        "\n",
        "    return created_dirs\n",
        "\n",
        "def configure_logging_system():\n",
        "    \"\"\"\n",
        "    Configura sistema de logging detalhado para produ√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìù CONFIGURANDO SISTEMA DE LOGGING\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    import logging\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Configurar formata√ß√£o de logs\n",
        "    log_format = '%(asctime)s | %(levelname)s | %(module)s | %(funcName)s | %(message)s'\n",
        "    date_format = '%Y-%m-%d %H:%M:%S'\n",
        "\n",
        "    # Criar logger principal\n",
        "    logger = logging.getLogger('valentina_generator')\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Handler para arquivo\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    log_file = f'/content/valentina_dataset_v4/metadata/generation_log_{timestamp}.log'\n",
        "\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_formatter = logging.Formatter(log_format, date_format)\n",
        "    file_handler.setFormatter(file_formatter)\n",
        "\n",
        "    # Handler para console (mais simples)\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    console_formatter = logging.Formatter('%(levelname)s | %(message)s')\n",
        "    console_handler.setFormatter(console_formatter)\n",
        "\n",
        "    # Adicionar handlers\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    print(f\"üìù Log principal: {log_file}\")\n",
        "    print(\"‚úÖ Sistema de logging configurado\")\n",
        "\n",
        "    return logger\n",
        "\n",
        "def create_production_config():\n",
        "    \"\"\"\n",
        "    Cria arquivo de configura√ß√£o para ambiente de produ√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n‚öôÔ∏è CRIANDO CONFIGURA√á√ÉO DE PRODU√á√ÉO\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    config = {\n",
        "        'version': '4.0',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'environment': {\n",
        "            'gpu_config': GPU_CONFIG,\n",
        "            'compatibility': COMPATIBILITY_REPORT,\n",
        "            'colab_runtime': 'detected'\n",
        "        },\n",
        "        'paths': {\n",
        "            'base_dir': '/content/valentina_dataset_v4',\n",
        "            'models_cache': '/content/models_cache',\n",
        "            'output_dir': '/content/valentina_dataset_v4/generated_images',\n",
        "            'metadata_dir': '/content/valentina_dataset_v4/metadata'\n",
        "        },\n",
        "        'commercial_settings': {\n",
        "            'target_platform': ['TopFans', 'OnlyFans', 'Premium'],\n",
        "            'quality_threshold': 0.85,\n",
        "            'face_consistency_threshold': 0.3,\n",
        "            'min_resolution': 1024,\n",
        "            'max_batch_size': GPU_CONFIG['recommended_config'].get('batch_size', 1)\n",
        "        },\n",
        "        'model_settings': {\n",
        "            'base_model': 'black-forest-labs/FLUX.1-dev',\n",
        "            'preferred_controlnet': 'InstantX/FLUX.1-dev-Controlnet-Union',\n",
        "            'fallback_controlnets': [\n",
        "                'Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro',\n",
        "                'XLabs-AI/flux-controlnet-canny-v3'\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Salvar configura√ß√£o\n",
        "    config_file = '/content/valentina_dataset_v4/metadata/production_config.json'\n",
        "\n",
        "    try:\n",
        "        with open(config_file, 'w') as f:\n",
        "            json.dump(config, f, indent=2, default=str)\n",
        "\n",
        "        print(f\"‚öôÔ∏è Configura√ß√£o salva: {config_file}\")\n",
        "        print(\"‚úÖ Ambiente de produ√ß√£o configurado\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro salvando configura√ß√£o: {e}\")\n",
        "\n",
        "    return config\n",
        "\n",
        "# Executar configura√ß√£o de estrutura\n",
        "print(\"üöÄ Configurando estrutura de produ√ß√£o...\")\n",
        "CREATED_DIRS = setup_directory_structure()\n",
        "LOGGER = configure_logging_system()\n",
        "PRODUCTION_CONFIG = create_production_config()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# üìä RESUMO DA FASE 1\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä RESUMO DA FASE 1: SETUP COLAB OTIMIZADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üñ•Ô∏è GPU: {GPU_CONFIG['name']} ({GPU_CONFIG['tier'].upper()})\")\n",
        "print(f\"üíæ VRAM: {GPU_CONFIG['memory_total']:,}MB\")\n",
        "print(f\"üéØ Qualidade: {'COMERCIAL PREMIUM' if GPU_CONFIG['vram_adequate'] else 'OTIMIZADA'}\")\n",
        "print(f\"üì¶ Stack: {COMPATIBILITY_REPORT['overall_status'].upper()}\")\n",
        "print(f\"üéÆ FLUX ControlNet: {'‚úÖ Dispon√≠vel' if COMPATIBILITY_REPORT['flux_support'] else '‚ùå Indispon√≠vel'}\")\n",
        "print(f\"üë§ Valida√ß√£o Facial: {'‚úÖ Avan√ßada' if COMPATIBILITY_REPORT['validation_support'] else '‚ö†Ô∏è B√°sica'}\")\n",
        "print(f\"üìÅ Diret√≥rios: {len(CREATED_DIRS)} criados\")\n",
        "print(f\"üìù Logging: Configurado e ativo\")\n",
        "\n",
        "if COMPATIBILITY_REPORT['overall_status'] in ['excellent', 'good']:\n",
        "    print(\"\\nüöÄ AMBIENTE PRONTO PARA FASE 2: CARREGAMENTO DOS MODELOS\")\n",
        "    print(\"üíé Qualidade comercial garantida!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è ATEN√á√ÉO: Algumas limita√ß√µes detectadas\")\n",
        "    print(\"üîß Continuando com configura√ß√µes otimizadas...\")\n",
        "\n",
        "LOGGER.info(\"FASE 1 conclu√≠da: Setup Colab Otimizado\")\n",
        "LOGGER.info(f\"GPU: {GPU_CONFIG['name']}, VRAM: {GPU_CONFIG['memory_total']}MB\")\n",
        "LOGGER.info(f\"Stack status: {COMPATIBILITY_REPORT['overall_status']}\")\n",
        "\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "mC1DreTPQbaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üìã FASE 2: CARREGAMENTO INTELIGENTE DOS MODELOS\n",
        "# =============================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "import time\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 2.1: SISTEMA DE DETEC√á√ÉO AUTOM√ÅTICA DE CONTROLNET\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def get_available_union_controlnets() -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Lista de modelos Union ControlNet ordenados por qualidade comercial\n",
        "\n",
        "    Returns:\n",
        "        Lista de dicion√°rios com informa√ß√µes dos modelos dispon√≠veis\n",
        "    \"\"\"\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"id\": \"InstantX/FLUX.1-dev-Controlnet-Union\",\n",
        "            \"name\": \"InstantX Union\",\n",
        "            \"description\": \"Modelo Union premium com 7 modos de controle\",\n",
        "            \"modes\": {\n",
        "                0: \"canny\",\n",
        "                1: \"tile\",\n",
        "                2: \"depth\",\n",
        "                3: \"blur\",\n",
        "                4: \"pose\",\n",
        "                5: \"gray\",\n",
        "                6: \"low_quality\"\n",
        "            },\n",
        "            \"commercial_quality\": \"premium\",\n",
        "            \"face_support\": True,\n",
        "            \"recommended_modes\": [0, 2, 4],  # canny, depth, pose para faces\n",
        "            \"memory_efficient\": True,\n",
        "            \"batch_support\": True\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro\",\n",
        "            \"name\": \"Shakker Union Pro\",\n",
        "            \"description\": \"Modelo Union profissional otimizado\",\n",
        "            \"modes\": {\n",
        "                0: \"canny\",\n",
        "                1: \"depth\",\n",
        "                2: \"pose\",\n",
        "                3: \"hed\"\n",
        "            },\n",
        "            \"commercial_quality\": \"high\",\n",
        "            \"face_support\": True,\n",
        "            \"recommended_modes\": [0, 1, 2],  # canny, depth, pose\n",
        "            \"memory_efficient\": True,\n",
        "            \"batch_support\": True\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro-2.0\",\n",
        "            \"name\": \"Shakker Union Pro 2.0\",\n",
        "            \"description\": \"Vers√£o atualizada do Union Pro\",\n",
        "            \"modes\": {\n",
        "                0: \"canny\",\n",
        "                1: \"depth\",\n",
        "                2: \"pose\",\n",
        "                3: \"hed\",\n",
        "                4: \"mlsd\"\n",
        "            },\n",
        "            \"commercial_quality\": \"high\",\n",
        "            \"face_support\": True,\n",
        "            \"recommended_modes\": [0, 1, 2],\n",
        "            \"memory_efficient\": True,\n",
        "            \"batch_support\": True\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"XLabs-AI/flux-controlnet-canny-v3\",\n",
        "            \"name\": \"XLabs Canny v3\",\n",
        "            \"description\": \"ControlNet especializado em Canny\",\n",
        "            \"modes\": {0: \"canny\"},\n",
        "            \"commercial_quality\": \"good\",\n",
        "            \"face_support\": True,\n",
        "            \"recommended_modes\": [0],\n",
        "            \"memory_efficient\": True,\n",
        "            \"batch_support\": False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def detect_best_available_controlnet() -> Tuple[Dict, bool]:\n",
        "    \"\"\"\n",
        "    Detecta automaticamente o melhor ControlNet Union dispon√≠vel\n",
        "\n",
        "    Returns:\n",
        "        Tupla (modelo_selecionado, sucesso)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüéÆ DETEC√á√ÉO AUTOM√ÅTICA DE UNION CONTROLNET\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Importar depend√™ncias necess√°rias\n",
        "    try:\n",
        "        from diffusers import FluxControlNetModel\n",
        "        print(\"‚úÖ FluxControlNetModel importado com sucesso\")\n",
        "    except ImportError:\n",
        "        try:\n",
        "            from diffusers.models.controlnets.controlnet_flux import FluxControlNetModel\n",
        "            print(\"‚úÖ FluxControlNetModel importado via path alternativo\")\n",
        "        except ImportError as e:\n",
        "            print(f\"‚ùå Erro cr√≠tico: FluxControlNetModel n√£o dispon√≠vel: {e}\")\n",
        "            return None, False\n",
        "\n",
        "    available_models = get_available_union_controlnets()\n",
        "    selected_model = None\n",
        "\n",
        "    for model_info in available_models:\n",
        "        print(f\"\\nüß™ Testando: {model_info['name']}\")\n",
        "        print(f\"   üìù ID: {model_info['id']}\")\n",
        "        print(f\"   üéØ Modos: {list(model_info['modes'].values())}\")\n",
        "        print(f\"   üíé Qualidade: {model_info['commercial_quality']}\")\n",
        "\n",
        "        try:\n",
        "            # Teste de carregamento r√°pido\n",
        "            print(f\"   ‚è≥ Carregando modelo para teste...\")\n",
        "\n",
        "            start_time = time.time()\n",
        "            test_controlnet = FluxControlNetModel.from_pretrained(\n",
        "                model_info[\"id\"],\n",
        "                torch_dtype=GPU_CONFIG['torch_dtype'],\n",
        "                use_safetensors=True,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            load_time = time.time() - start_time\n",
        "\n",
        "            print(f\"   ‚úÖ Carregamento bem-sucedido ({load_time:.1f}s)\")\n",
        "            print(f\"   üéØ Modelo funcional e compat√≠vel!\")\n",
        "\n",
        "            # Verificar informa√ß√µes do modelo\n",
        "            if hasattr(test_controlnet, 'config'):\n",
        "                print(f\"   üìä Configura√ß√£o detectada: {type(test_controlnet.config).__name__}\")\n",
        "\n",
        "            # Limpeza imediata do teste\n",
        "            del test_controlnet\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            selected_model = model_info\n",
        "            print(f\"\\nüèÜ MODELO SELECIONADO: {model_info['name']}\")\n",
        "            print(f\"   üíé Qualidade comercial: {model_info['commercial_quality'].upper()}\")\n",
        "            print(f\"   üéØ Suporte facial: {'‚úÖ Sim' if model_info['face_support'] else '‚ùå N√£o'}\")\n",
        "            print(f\"   üöÄ Modos recomendados para faces: {[model_info['modes'][i] for i in model_info['recommended_modes']]}\")\n",
        "\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Modelo indispon√≠vel: {str(e)[:100]}...\")\n",
        "            print(f\"   üîÑ Tentando pr√≥ximo modelo...\")\n",
        "            continue\n",
        "\n",
        "    if selected_model is None:\n",
        "        print(\"\\n‚ùå ERRO CR√çTICO: Nenhum Union ControlNet compat√≠vel encontrado!\")\n",
        "        print(\"üîß Verifique:\")\n",
        "        print(\"   ‚Ä¢ Conex√£o com internet para download de modelos\")\n",
        "        print(\"   ‚Ä¢ Autentica√ß√£o HuggingFace para modelos privados\")\n",
        "        print(\"   ‚Ä¢ Espa√ßo em disco suficiente\")\n",
        "        return None, False\n",
        "\n",
        "    return selected_model, True"
      ],
      "metadata": {
        "id": "4l3hzlHqQfC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üöÄ EXECU√á√ÉO DA FASE 2\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüöÄ INICIANDO FASE 2: CARREGAMENTO INTELIGENTE DOS MODELOS\")\n",
        "LOGGER.info(\"Iniciando FASE 2: Carregamento dos modelos\")\n",
        "\n",
        "# Tarefa 2.1: Detec√ß√£o de ControlNet\n",
        "print(\"üìã Executando Tarefa 2.1: Detec√ß√£o autom√°tica de ControlNet...\")\n",
        "SELECTED_CONTROLNET, controlnet_success = detect_best_available_controlnet()\n",
        "\n",
        "if not controlnet_success:\n",
        "    print(\"‚ùå ERRO CR√çTICO: Falha na detec√ß√£o de ControlNet\")\n",
        "    LOGGER.error(\"FASE 2 falhou: Nenhum ControlNet dispon√≠vel\")\n",
        "    raise Exception(\"Setup de ControlNet falhou - imposs√≠vel continuar\")"
      ],
      "metadata": {
        "id": "xKbWN6GjSccT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 2.3: AUTENTICA√á√ÉO E DOWNLOAD AUTOM√ÅTICO\n",
        "# -----------------------------------------------------------------------------\n",
        "from datetime import datetime\n",
        "import time\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "\n",
        "def setup_huggingface_authentication():\n",
        "    \"\"\"\n",
        "    Configura autentica√ß√£o HuggingFace para acesso aos modelos\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüîë CONFIGURA√á√ÉO DE AUTENTICA√á√ÉO HUGGINGFACE\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    try:\n",
        "        from huggingface_hub import notebook_login, whoami\n",
        "\n",
        "        # Verificar se j√° est√° autenticado\n",
        "        try:\n",
        "            user_info = whoami()\n",
        "            print(f\"‚úÖ J√° autenticado como: {user_info['name']}\")\n",
        "            print(f\"üéØ Tipo de conta: {user_info.get('type', 'user')}\")\n",
        "            return True\n",
        "        except Exception:\n",
        "            print(\"üîê Autentica√ß√£o necess√°ria para acessar FLUX.1-dev\")\n",
        "\n",
        "        # Solicitar login se necess√°rio\n",
        "        print(\"üìù Por favor, fa√ßa login na HuggingFace:\")\n",
        "        print(\"   1. Acesse: https://huggingface.co/settings/tokens\")\n",
        "        print(\"   2. Crie um token com permiss√£o 'read'\")\n",
        "        print(\"   3. Cole o token abaixo:\")\n",
        "\n",
        "        notebook_login()\n",
        "\n",
        "        # Verificar autentica√ß√£o ap√≥s login\n",
        "        try:\n",
        "            user_info = whoami()\n",
        "            print(f\"‚úÖ Login bem-sucedido! Usu√°rio: {user_info['name']}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro na verifica√ß√£o p√≥s-login: {e}\")\n",
        "            return False\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"‚ùå huggingface_hub n√£o dispon√≠vel\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na autentica√ß√£o: {e}\")\n",
        "        return False\n",
        "\n",
        "def validate_model_access():\n",
        "    \"\"\"\n",
        "    Valida acesso aos modelos necess√°rios\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüîç VALIDANDO ACESSO AOS MODELOS\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    models_to_check = [\n",
        "        PRODUCTION_CONFIG['model_settings']['base_model'],\n",
        "        *PRODUCTION_CONFIG['model_settings']['fallback_controlnets']\n",
        "    ]\n",
        "\n",
        "    accessible_models = []\n",
        "\n",
        "    for model_id in models_to_check:\n",
        "        try:\n",
        "            from huggingface_hub import model_info\n",
        "            info = model_info(model_id)\n",
        "            print(f\"‚úÖ {model_id}: Acess√≠vel\")\n",
        "            accessible_models.append(model_id)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå {model_id}: {str(e)[:50]}...\")\n",
        "\n",
        "    print(f\"\\nüìä Modelos acess√≠veis: {len(accessible_models)}/{len(models_to_check)}\")\n",
        "    return accessible_models\n",
        "\n",
        "# Tarefa 2.3: Autentica√ß√£o (executar antes do carregamento)\n",
        "print(\"\\nüìã Executando Tarefa 2.3: Autentica√ß√£o HuggingFace...\")\n",
        "auth_success = setup_huggingface_authentication()\n",
        "\n",
        "if auth_success:\n",
        "    accessible_models = validate_model_access()\n",
        "    LOGGER.info(f\"Modelos acess√≠veis: {len(accessible_models)}\")"
      ],
      "metadata": {
        "id": "eld4Q6UmSqG_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 2.2: PIPELINE FLUX OTIMIZADO\n",
        "# -----------------------------------------------------------------------------\n",
        "from datetime import datetime\n",
        "import time\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "\n",
        "\n",
        "def setup_flux_pipeline_optimized(controlnet_model_info: Dict) -> Tuple[Any, Any, bool]:\n",
        "    \"\"\"\n",
        "    Configura pipeline FLUX otimizado com ControlNet selecionado\n",
        "\n",
        "    Args:\n",
        "        controlnet_model_info: Informa√ß√µes do modelo ControlNet selecionado\n",
        "\n",
        "    Returns:\n",
        "        Tupla (pipeline, controlnet, sucesso)\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüöÄ CONFIGURANDO PIPELINE FLUX OTIMIZADO\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"üéØ Base Model: {PRODUCTION_CONFIG['model_settings']['base_model']}\")\n",
        "    print(f\"üéÆ ControlNet: {controlnet_model_info['name']}\")\n",
        "    print(f\"üñ•Ô∏è GPU: {GPU_CONFIG['name']} ({GPU_CONFIG['tier'].upper()})\")\n",
        "\n",
        "    try:\n",
        "        # Imports necess√°rios\n",
        "        from diffusers import FluxControlNetPipeline, FluxControlNetModel\n",
        "        from diffusers.utils import load_image\n",
        "        import torch\n",
        "\n",
        "        print(\"‚úÖ Imports do pipeline realizados com sucesso\")\n",
        "\n",
        "        # Carregar ControlNet\n",
        "        print(f\"‚è≥ Carregando ControlNet: {controlnet_model_info['id']}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        controlnet = FluxControlNetModel.from_pretrained(\n",
        "            controlnet_model_info[\"id\"],\n",
        "            torch_dtype=GPU_CONFIG['torch_dtype'],\n",
        "            use_safetensors=True,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        controlnet_load_time = time.time() - start_time\n",
        "        print(f\"‚úÖ ControlNet carregado ({controlnet_load_time:.1f}s)\")\n",
        "\n",
        "        # Carregar pipeline base FLUX\n",
        "        print(f\"‚è≥ Carregando FLUX.1-dev pipeline...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        pipeline = FluxControlNetPipeline.from_pretrained(\n",
        "            PRODUCTION_CONFIG['model_settings']['base_model'],\n",
        "            controlnet=controlnet,\n",
        "            torch_dtype=GPU_CONFIG['torch_dtype'],\n",
        "            use_safetensors=True,\n",
        "            variant=\"fp16\" if GPU_CONFIG['torch_dtype'] == torch.float16 else None\n",
        "        )\n",
        "\n",
        "        pipeline_load_time = time.time() - start_time\n",
        "        print(f\"‚úÖ Pipeline FLUX carregado ({pipeline_load_time:.1f}s)\")\n",
        "\n",
        "        # Aplicar otimiza√ß√µes espec√≠ficas da GPU\n",
        "        print(f\"‚öôÔ∏è Aplicando otimiza√ß√µes para {GPU_CONFIG['tier'].upper()}...\")\n",
        "\n",
        "        config = GPU_CONFIG['recommended_config']\n",
        "\n",
        "        if config.get('enable_cpu_offload', False):\n",
        "            pipeline.enable_model_cpu_offload()\n",
        "            print(\"‚úÖ CPU offload ativado (economia de VRAM)\")\n",
        "        else:\n",
        "            pipeline.to(GPU_CONFIG['device'])\n",
        "            print(f\"‚úÖ Pipeline movido para {GPU_CONFIG['device']}\")\n",
        "\n",
        "        if config.get('enable_attention_slicing', False):\n",
        "            pipeline.enable_attention_slicing()\n",
        "            print(\"‚úÖ Attention slicing ativado\")\n",
        "\n",
        "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
        "        if GPU_CONFIG['tier'] == 'premium':  # A100\n",
        "            print(\"üî• Configura√ß√µes A100 PREMIUM aplicadas:\")\n",
        "            print(\"   ‚Ä¢ Precision: bfloat16\")\n",
        "            print(\"   ‚Ä¢ TF32: Ativado\")\n",
        "            print(\"   ‚Ä¢ Batch size: 4\")\n",
        "            print(\"   ‚Ä¢ CPU offload: Desativado\")\n",
        "        elif GPU_CONFIG['tier'] == 'high':  # V100\n",
        "            print(\"üíé Configura√ß√µes V100 HIGH-END aplicadas:\")\n",
        "            print(\"   ‚Ä¢ Precision: float16\")\n",
        "            print(\"   ‚Ä¢ Batch size: 2\")\n",
        "            print(\"   ‚Ä¢ CPU offload: Desativado\")\n",
        "        else:\n",
        "            print(\"üì± Configura√ß√µes STANDARD/FALLBACK aplicadas:\")\n",
        "            print(\"   ‚Ä¢ Precision: float16\")\n",
        "            print(\"   ‚Ä¢ Batch size: 1\")\n",
        "            print(\"   ‚Ä¢ CPU offload: Ativado\")\n",
        "            print(\"   ‚Ä¢ Attention slicing: Ativado\")\n",
        "\n",
        "        # Limpeza de mem√≥ria\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"üßπ Cache GPU limpo\")\n",
        "\n",
        "        total_load_time = controlnet_load_time + pipeline_load_time\n",
        "        print(f\"\\n‚úÖ PIPELINE CONFIGURADO COM SUCESSO!\")\n",
        "        print(f\"‚è±Ô∏è Tempo total de carregamento: {total_load_time:.1f}s\")\n",
        "\n",
        "        return pipeline, controlnet, True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRO no setup do pipeline: {e}\")\n",
        "        print(f\"üîß Stack trace para debugging:\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, False\n",
        "\n",
        "# Tarefa 2.2: Pipeline FLUX\n",
        "print(\"\\nüìã Executando Tarefa 2.2: Configura√ß√£o do pipeline FLUX...\")\n",
        "FLUX_PIPELINE, FLUX_CONTROLNET, pipeline_success = setup_flux_pipeline_optimized(SELECTED_CONTROLNET)\n",
        "\n",
        "if not pipeline_success:\n",
        "    print(\"‚ùå ERRO CR√çTICO: Falha na configura√ß√£o do pipeline\")\n",
        "    LOGGER.error(\"FASE 2 falhou: Pipeline FLUX n√£o configurado\")\n",
        "    raise Exception(\"Setup do pipeline falhou - imposs√≠vel continuar\")\n"
      ],
      "metadata": {
        "id": "YDrCwH9PRcr7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# ‚úÖ TAREFA 2.4: APLICA√á√ÉO DE LORAS BALANCEADOS\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def apply_commercial_loras(pipeline) -> bool:\n",
        "    \"\"\"\n",
        "    Aplica LoRAs balanceados para qualidade comercial\n",
        "\n",
        "    Args:\n",
        "        pipeline: Pipeline FLUX configurado\n",
        "\n",
        "    Returns:\n",
        "        bool: Sucesso na aplica√ß√£o dos LoRAs\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüé® APLICANDO LORAS COMERCIAIS BALANCEADOS\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # LoRAs otimizados para qualidade comercial (baseado na pesquisa anterior)\n",
        "    commercial_loras = [\n",
        "        {\n",
        "            \"id\": \"XLabs-AI/flux-RealismLora\",\n",
        "            \"adapter_name\": \"realism\",\n",
        "            \"weight\": 0.7,  # Reduzido para balancear com ControlNet\n",
        "            \"purpose\": \"Fotorrealismo facial\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"Shakker-Labs/FLUX.1-dev-LoRA-AntiBlur\",\n",
        "            \"adapter_name\": \"antiblur\",\n",
        "            \"weight\": 0.5,  # Detalhes sutis\n",
        "            \"purpose\": \"Detalhes de beleza\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"alvdansen/flux_film_foto\",\n",
        "            \"adapter_name\": \"film_foto\",\n",
        "            \"weight\": 0.4,  # Est√©tica sutil\n",
        "            \"purpose\": \"Qualidade fotogr√°fica\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    applied_loras = []\n",
        "    lora_adapters = []\n",
        "    lora_weights = []\n",
        "\n",
        "    for lora_info in commercial_loras:\n",
        "        try:\n",
        "            print(f\"‚è≥ Carregando: {lora_info['purpose']}\")\n",
        "            print(f\"   üìù ID: {lora_info['id']}\")\n",
        "            print(f\"   ‚öñÔ∏è Peso: {lora_info['weight']}\")\n",
        "\n",
        "            pipeline.load_lora_weights(\n",
        "                lora_info[\"id\"],\n",
        "                adapter_name=lora_info[\"adapter_name\"]\n",
        "            )\n",
        "\n",
        "            applied_loras.append(lora_info)\n",
        "            lora_adapters.append(lora_info[\"adapter_name\"])\n",
        "            lora_weights.append(lora_info[\"weight\"])\n",
        "\n",
        "            print(f\"   ‚úÖ Aplicado com sucesso!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è Falha: {str(e)[:60]}... - Continuando sem este LoRA\")\n",
        "            continue\n",
        "\n",
        "    if applied_loras:\n",
        "        # Configurar adaptadores com pesos balanceados\n",
        "        pipeline.set_adapters(lora_adapters, adapter_weights=lora_weights)\n",
        "\n",
        "        print(f\"\\n‚úÖ LORAS APLICADOS COM SUCESSO:\")\n",
        "        for lora in applied_loras:\n",
        "            print(f\"   üé® {lora['purpose']}: peso {lora['weight']}\")\n",
        "\n",
        "        print(f\"\\nüí° ESTRAT√âGIA DE BALANCEAMENTO:\")\n",
        "        print(f\"   ‚Ä¢ Pesos reduzidos para complementar ControlNet\")\n",
        "        print(f\"   ‚Ä¢ Foco em realismo e qualidade fotogr√°fica\")\n",
        "        print(f\"   ‚Ä¢ Evita oversaturation com m√∫ltiplas t√©cnicas\")\n",
        "\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è Nenhum LoRA aplicado - continuando apenas com ControlNet\")\n",
        "        return False\n",
        "\n",
        "# Tarefa 2.4: LoRAs comerciais\n",
        "print(\"\\nüìã Executando Tarefa 2.4: Aplica√ß√£o de LoRAs comerciais...\")\n",
        "loras_success = apply_commercial_loras(FLUX_PIPELINE)\n",
        "LOGGER.info(f\"LoRAs aplicados: {loras_success}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "BUsOzMOBRzqE",
        "outputId": "002a7be7-7e02-4cf4-8030-f5b86e7d63f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ INICIANDO FASE 2: CARREGAMENTO INTELIGENTE DOS MODELOS\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LOGGER' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c028c1f596d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüöÄ INICIANDO FASE 2: CARREGAMENTO INTELIGENTE DOS MODELOS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iniciando FASE 2: Carregamento dos modelos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Tarefa 2.1: Detec√ß√£o de ControlNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LOGGER' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üìä RESUMO DA FASE 2\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä RESUMO DA FASE 2: CARREGAMENTO INTELIGENTE DOS MODELOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üéÆ ControlNet: {SELECTED_CONTROLNET['name']}\")\n",
        "print(f\"üíé Qualidade: {SELECTED_CONTROLNET['commercial_quality'].upper()}\")\n",
        "print(f\"üéØ Modos dispon√≠veis: {list(SELECTED_CONTROLNET['modes'].values())}\")\n",
        "print(f\"üöÄ Pipeline FLUX: {'‚úÖ Configurado' if pipeline_success else '‚ùå Falhou'}\")\n",
        "print(f\"üé® LoRAs comerciais: {'‚úÖ Aplicados' if loras_success else '‚ö†Ô∏è B√°sico'}\")\n",
        "print(f\"üîë Autentica√ß√£o HF: {'‚úÖ Ativa' if auth_success else '‚ö†Ô∏è Limitada'}\")\n",
        "\n",
        "# Configura√ß√µes finais para pr√≥xima fase\n",
        "PIPELINE_CONFIG = {\n",
        "    'controlnet_model': SELECTED_CONTROLNET,\n",
        "    'pipeline': FLUX_PIPELINE,\n",
        "    'controlnet': FLUX_CONTROLNET,\n",
        "    'loras_active': loras_success,\n",
        "    'recommended_modes': SELECTED_CONTROLNET['recommended_modes'],\n",
        "    'generation_config': {\n",
        "        'num_inference_steps': GPU_CONFIG['recommended_config']['inference_steps'],\n",
        "        'guidance_scale': GPU_CONFIG['recommended_config']['guidance_scale'],\n",
        "        'width': GPU_CONFIG['recommended_config']['max_resolution'],\n",
        "        'height': GPU_CONFIG['recommended_config']['max_resolution'],\n",
        "        'controlnet_conditioning_scale': 0.7,  # Balanceado para identidade\n",
        "        'control_guidance_start': 0.0,\n",
        "        'control_guidance_end': 0.8\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"\\nüî• CONFIGURA√á√ÉO DE GERA√á√ÉO:\")\n",
        "for key, value in PIPELINE_CONFIG['generation_config'].items():\n",
        "    print(f\"   ‚Ä¢ {key}: {value}\")\n",
        "\n",
        "if pipeline_success and SELECTED_CONTROLNET['commercial_quality'] in ['premium', 'high']:\n",
        "    print(\"\\nüöÄ PRONTO PARA FASE 3: PROCESSAMENTO DA IMAGEM DE REFER√äNCIA\")\n",
        "    print(\"üíé Qualidade comercial garantida!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è CONFIGURA√á√ÉO LIMITADA - Prosseguindo com otimiza√ß√µes\")\n",
        "\n",
        "LOGGER.info(\"FASE 2 conclu√≠da: Modelos carregados com sucesso\")\n",
        "LOGGER.info(f\"ControlNet: {SELECTED_CONTROLNET['name']}\")\n",
        "LOGGER.info(f\"Pipeline status: {pipeline_success}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üé® Estrat√©gia: Union ControlNet + Valida√ß√£o Comercial Autom√°tica\")\n",
        "print(\"üíé Objetivo: Dataset premium para modelo digital Valentina Moreau\")\n",
        "print(\"üöÄ Plataforma: Google Colab A100/V100 otimizado\")\n",
        "print(\"üí∞ Foco: Monetiza√ß√£o comercial em plataformas premium\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "GBhGKNEsR3rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 1: FASE 3.1 - Imports e Fun√ß√µes de Upload/Valida√ß√£o =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üì± C√âLULA 1: Imports e Fun√ß√µes de Upload/Valida√ß√£o\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def validate_reference_image(image_path: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Valida imagem de refer√™ncia para uso comercial\n",
        "\n",
        "    Args:\n",
        "        image_path: Caminho para a imagem\n",
        "\n",
        "    Returns:\n",
        "        Dict com informa√ß√µes de valida√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüîç VALIDANDO IMAGEM DE REFER√äNCIA\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    validation_result = {\n",
        "        'valid': False,\n",
        "        'path': image_path,\n",
        "        'format': None,\n",
        "        'dimensions': (0, 0),\n",
        "        'size_mb': 0,\n",
        "        'face_detected': False,\n",
        "        'quality_score': 0.0,\n",
        "        'commercial_suitable': False,\n",
        "        'issues': [],\n",
        "        'recommendations': []\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Verificar se arquivo existe\n",
        "        if not os.path.exists(image_path):\n",
        "            validation_result['issues'].append(\"Arquivo n√£o encontrado\")\n",
        "            return validation_result\n",
        "\n",
        "        # Carregar imagem\n",
        "        image = Image.open(image_path)\n",
        "        validation_result['format'] = image.format\n",
        "        validation_result['dimensions'] = image.size\n",
        "        validation_result['size_mb'] = os.path.getsize(image_path) / (1024 * 1024)\n",
        "\n",
        "        print(f\"üìä Formato: {image.format}\")\n",
        "        print(f\"üìê Dimens√µes: {image.size[0]}x{image.size[1]}\")\n",
        "        print(f\"üíæ Tamanho: {validation_result['size_mb']:.2f}MB\")\n",
        "\n",
        "        # Valida√ß√µes b√°sicas\n",
        "        min_resolution = 512\n",
        "        max_size_mb = 50\n",
        "\n",
        "        if image.size[0] < min_resolution or image.size[1] < min_resolution:\n",
        "            validation_result['issues'].append(f\"Resolu√ß√£o muito baixa (m√≠n: {min_resolution}px)\")\n",
        "\n",
        "        if validation_result['size_mb'] > max_size_mb:\n",
        "            validation_result['issues'].append(f\"Arquivo muito grande (m√°x: {max_size_mb}MB)\")\n",
        "\n",
        "        if image.format not in ['JPEG', 'PNG', 'WEBP']:\n",
        "            validation_result['issues'].append(\"Formato n√£o suportado (use JPEG, PNG ou WEBP)\")\n",
        "\n",
        "        # Converter para array para an√°lises\n",
        "        image_array = np.array(image.convert('RGB'))\n",
        "\n",
        "        # An√°lise de qualidade b√°sica\n",
        "        quality_score = analyze_image_quality(image_array)\n",
        "        validation_result['quality_score'] = quality_score\n",
        "\n",
        "        print(f\"‚≠ê Score de qualidade: {quality_score:.2f}/1.0\")\n",
        "\n",
        "        if quality_score < 0.5:\n",
        "            validation_result['issues'].append(\"Qualidade de imagem baixa\")\n",
        "            validation_result['recommendations'].append(\"Use imagem com melhor resolu√ß√£o e nitidez\")\n",
        "\n",
        "        # Detec√ß√£o de face\n",
        "        face_detected = detect_face_in_image(image_array)\n",
        "        validation_result['face_detected'] = face_detected\n",
        "\n",
        "        if face_detected:\n",
        "            print(\"üë§ ‚úÖ Face detectada na imagem\")\n",
        "        else:\n",
        "            validation_result['issues'].append(\"Nenhuma face detectada\")\n",
        "            validation_result['recommendations'].append(\"Use imagem com face claramente vis√≠vel\")\n",
        "\n",
        "        # Determinar adequa√ß√£o comercial\n",
        "        commercial_score = calculate_commercial_suitability(validation_result)\n",
        "        validation_result['commercial_suitable'] = commercial_score > 0.7\n",
        "\n",
        "        print(f\"üí∞ Adequa√ß√£o comercial: {commercial_score:.2f}/1.0\")\n",
        "\n",
        "        # Status final\n",
        "        validation_result['valid'] = len(validation_result['issues']) == 0\n",
        "\n",
        "        if validation_result['valid']:\n",
        "            print(\"‚úÖ IMAGEM APROVADA para uso comercial\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è PROBLEMAS DETECTADOS:\")\n",
        "            for issue in validation_result['issues']:\n",
        "                print(f\"   ‚Ä¢ {issue}\")\n",
        "\n",
        "        if validation_result['recommendations']:\n",
        "            print(\"üí° RECOMENDA√á√ïES:\")\n",
        "            for rec in validation_result['recommendations']:\n",
        "                print(f\"   ‚Ä¢ {rec}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        validation_result['issues'].append(f\"Erro no processamento: {str(e)}\")\n",
        "        print(f\"‚ùå Erro na valida√ß√£o: {e}\")\n",
        "\n",
        "    return validation_result\n",
        "\n",
        "def analyze_image_quality(image_array: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Analisa qualidade da imagem usando m√©tricas autom√°ticas\n",
        "\n",
        "    Args:\n",
        "        image_array: Array numpy da imagem\n",
        "\n",
        "    Returns:\n",
        "        Score de qualidade de 0.0 a 1.0\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Converter para grayscale para an√°lises\n",
        "        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # An√°lise de nitidez (variance of Laplacian)\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        sharpness_score = min(laplacian_var / 1000.0, 1.0)  # Normalizar\n",
        "\n",
        "        # An√°lise de contraste\n",
        "        contrast = gray.std()\n",
        "        contrast_score = min(contrast / 100.0, 1.0)  # Normalizar\n",
        "\n",
        "        # An√°lise de brilho (evitar muito escuro ou muito claro)\n",
        "        brightness = gray.mean()\n",
        "        brightness_score = 1.0 - abs(brightness - 127.5) / 127.5\n",
        "\n",
        "        # Score combinado\n",
        "        quality_score = (sharpness_score * 0.5 + contrast_score * 0.3 + brightness_score * 0.2)\n",
        "\n",
        "        return min(quality_score, 1.0)\n",
        "\n",
        "    except Exception:\n",
        "        return 0.5  # Score neutro em caso de erro\n",
        "\n",
        "def detect_face_in_image(image_array: np.ndarray) -> bool:\n",
        "    \"\"\"\n",
        "    Detecta presen√ßa de face na imagem\n",
        "\n",
        "    Args:\n",
        "        image_array: Array numpy da imagem\n",
        "\n",
        "    Returns:\n",
        "        True se face detectada, False caso contr√°rio\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Usar OpenCV Haar Cascade como fallback r√°pido\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        faces = face_cascade.detectMultiScale(\n",
        "            gray,\n",
        "            scaleFactor=1.1,\n",
        "            minNeighbors=5,\n",
        "            minSize=(30, 30)\n",
        "        )\n",
        "\n",
        "        return len(faces) > 0\n",
        "\n",
        "    except Exception:\n",
        "        # Em caso de erro, assumir que h√° face (melhor falso positivo)\n",
        "        return True\n",
        "\n",
        "def calculate_commercial_suitability(validation_result: Dict) -> float:\n",
        "    \"\"\"\n",
        "    Calcula adequa√ß√£o para uso comercial\n",
        "\n",
        "    Args:\n",
        "        validation_result: Resultado da valida√ß√£o\n",
        "\n",
        "    Returns:\n",
        "        Score de 0.0 a 1.0\n",
        "    \"\"\"\n",
        "\n",
        "    score = 1.0\n",
        "\n",
        "    # Penalidades por problemas\n",
        "    if not validation_result['face_detected']:\n",
        "        score -= 0.5\n",
        "\n",
        "    if validation_result['quality_score'] < 0.6:\n",
        "        score -= 0.3\n",
        "\n",
        "    if validation_result['dimensions'][0] < 768 or validation_result['dimensions'][1] < 768:\n",
        "        score -= 0.2\n",
        "\n",
        "    # B√¥nus por qualidade alta\n",
        "    if validation_result['quality_score'] > 0.8:\n",
        "        score += 0.1\n",
        "\n",
        "    if min(validation_result['dimensions']) > 1024:\n",
        "        score += 0.1\n",
        "\n",
        "    return max(score, 0.0)\n",
        "\n",
        "print(\"‚úÖ C√âLULA 1 CARREGADA: Fun√ß√µes de valida√ß√£o definidas\")"
      ],
      "metadata": {
        "id": "GWZ4wO3-U6Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 2: FASE 3.1 - Upload e Valida√ß√£o da Refer√™ncia =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 2: Upload e Valida√ß√£o da Refer√™ncia\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def upload_reference_image():\n",
        "    \"\"\"\n",
        "    Interface de upload para imagem de refer√™ncia da Valentina\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üì§ UPLOAD DA IMAGEM DE REFER√äNCIA DA VALENTINA\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"üéØ Objetivo: Imagem base para gerar dataset comercial\")\n",
        "    print(\"üí° Dicas para melhor resultado:\")\n",
        "    print(\"   ‚Ä¢ Use imagem de alta qualidade (m√≠n. 768x768)\")\n",
        "    print(\"   ‚Ä¢ Face bem iluminada e vis√≠vel\")\n",
        "    print(\"   ‚Ä¢ Formato JPEG ou PNG\")\n",
        "    print(\"   ‚Ä¢ Fundo neutro prefer√≠vel\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\nüìÅ Selecione a imagem de refer√™ncia:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            print(\"‚ùå Nenhum arquivo carregado\")\n",
        "            return None, None\n",
        "\n",
        "        # Pegar primeiro arquivo carregado\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(f\"üìÅ Arquivo carregado: {filename}\")\n",
        "\n",
        "        # Mover para diret√≥rio correto\n",
        "        reference_dir = \"/content/valentina_dataset_v4/reference_images\"\n",
        "        reference_path = os.path.join(reference_dir, f\"valentina_reference_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{filename.split('.')[-1]}\")\n",
        "\n",
        "        # Copiar arquivo\n",
        "        import shutil\n",
        "        shutil.move(filename, reference_path)\n",
        "\n",
        "        print(f\"üìÇ Salvo em: {reference_path}\")\n",
        "        return reference_path, filename\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è Google Colab n√£o detectado - usando upload manual\")\n",
        "        print(\"üìù Para upload manual:\")\n",
        "        print(\"   1. Fa√ßa upload da imagem para /content/valentina_dataset_v4/reference_images/\")\n",
        "        print(\"   2. Execute a pr√≥xima c√©lula com o caminho correto\")\n",
        "\n",
        "        # Para teste, usar uma imagem exemplo\n",
        "        example_path = \"/content/valentina_dataset_v4/reference_images/valentina_reference.jpg\"\n",
        "        print(f\"üîß Usando exemplo: {example_path}\")\n",
        "        return example_path, \"valentina_reference.jpg\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro no upload: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Executar upload\n",
        "REFERENCE_IMAGE_PATH, ORIGINAL_FILENAME = upload_reference_image()\n",
        "\n",
        "if REFERENCE_IMAGE_PATH:\n",
        "    print(f\"\\n‚úÖ UPLOAD CONCLU√çDO\")\n",
        "    print(f\"üìÅ Arquivo: {ORIGINAL_FILENAME}\")\n",
        "    print(f\"üìÇ Localiza√ß√£o: {REFERENCE_IMAGE_PATH}\")\n",
        "\n",
        "    # Executar valida√ß√£o\n",
        "    print(f\"\\nüîç INICIANDO VALIDA√á√ÉO AUTOM√ÅTICA...\")\n",
        "    VALIDATION_RESULT = validate_reference_image(REFERENCE_IMAGE_PATH)\n",
        "\n",
        "    # Salvar resultado da valida√ß√£o\n",
        "    validation_file = \"/content/valentina_dataset_v4/metadata/reference_validation.json\"\n",
        "    with open(validation_file, 'w') as f:\n",
        "        json.dump(VALIDATION_RESULT, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"üìä Valida√ß√£o salva em: {validation_file}\")\n",
        "\n",
        "    # Log da opera√ß√£o\n",
        "    LOGGER.info(f\"Imagem de refer√™ncia carregada: {ORIGINAL_FILENAME}\")\n",
        "    LOGGER.info(f\"Valida√ß√£o: {'APROVADA' if VALIDATION_RESULT['valid'] else 'COM PROBLEMAS'}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå FALHA NO UPLOAD - N√£o √© poss√≠vel continuar\")\n",
        "    VALIDATION_RESULT = None\n",
        "\n",
        "print(\"‚úÖ C√âLULA 2 CONCLU√çDA: Upload e valida√ß√£o realizados\")"
      ],
      "metadata": {
        "id": "IUvOg7sUU7GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 3: FASE 3.2 - Fun√ß√µes de Pr√©-processamento Multi-Modal =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 3: Fun√ß√µes de Pr√©-processamento Multi-Modal\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def setup_controlnet_processors():\n",
        "    \"\"\"\n",
        "    Configura processadores ControlNet otimizados\n",
        "\n",
        "    Returns:\n",
        "        Dict com processadores configurados\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üîß CONFIGURANDO PROCESSADORES CONTROLNET\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    processors = {}\n",
        "\n",
        "    try:\n",
        "        from controlnet_aux import (\n",
        "            CannyDetector,\n",
        "            MidasDetector,\n",
        "            OpenposeDetector,\n",
        "            HEDdetector,\n",
        "            LineartDetector\n",
        "        )\n",
        "\n",
        "        # Processador Canny (contornos) - otimizado para faces\n",
        "        print(\"‚è≥ Configurando Canny Detector...\")\n",
        "        processors['canny'] = CannyDetector()\n",
        "        print(\"‚úÖ Canny Detector configurado\")\n",
        "\n",
        "        # Processador Depth (profundidade) - estrutura 3D\n",
        "        print(\"‚è≥ Configurando Depth Detector...\")\n",
        "        processors['depth'] = MidasDetector.from_pretrained('valhalla/t2iadapter-aux-models')\n",
        "        print(\"‚úÖ Depth Detector configurado\")\n",
        "\n",
        "        # Processador Pose (postura corporal)\n",
        "        print(\"‚è≥ Configurando OpenPose Detector...\")\n",
        "        processors['pose'] = OpenposeDetector.from_pretrained('lllyasviel/Annotators')\n",
        "        print(\"‚úÖ OpenPose Detector configurado\")\n",
        "\n",
        "        # Processador HED (bordas suaves) - backup\n",
        "        try:\n",
        "            print(\"‚è≥ Configurando HED Detector...\")\n",
        "            processors['hed'] = HEDdetector.from_pretrained('lllyasviel/Annotators')\n",
        "            print(\"‚úÖ HED Detector configurado\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è HED Detector indispon√≠vel - usando alternativas\")\n",
        "\n",
        "        print(f\"\\n‚úÖ PROCESSADORES CONFIGURADOS: {len(processors)}\")\n",
        "        for name in processors.keys():\n",
        "            print(f\"   üéØ {name.upper()}: Dispon√≠vel\")\n",
        "\n",
        "        return processors\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå Erro importando controlnet_aux: {e}\")\n",
        "        print(\"üîß Tentando configura√ß√£o alternativa...\")\n",
        "        return setup_fallback_processors()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na configura√ß√£o: {e}\")\n",
        "        return {}\n",
        "\n",
        "def setup_fallback_processors():\n",
        "    \"\"\"\n",
        "    Configura√ß√£o alternativa usando OpenCV apenas\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üîß CONFIGURA√á√ÉO FALLBACK - OpenCV\")\n",
        "\n",
        "    processors = {}\n",
        "\n",
        "    def opencv_canny(image, low_threshold=50, high_threshold=150):\n",
        "        gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
        "        edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
        "        return Image.fromarray(edges)\n",
        "\n",
        "    processors['canny'] = opencv_canny\n",
        "    print(\"‚úÖ OpenCV Canny configurado como fallback\")\n",
        "\n",
        "    return processors\n",
        "\n",
        "def detect_best_control_mode(image_path: str, available_modes: List[int]) -> int:\n",
        "    \"\"\"\n",
        "    Detecta automaticamente o melhor modo ControlNet para a imagem\n",
        "\n",
        "    Args:\n",
        "        image_path: Caminho da imagem de refer√™ncia\n",
        "        available_modes: Modos dispon√≠veis no ControlNet selecionado\n",
        "\n",
        "    Returns:\n",
        "        Modo ControlNet recomendado\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüß† DETEC√á√ÉO AUTOM√ÅTICA DO MELHOR MODO CONTROLNET\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        image_array = np.array(image.convert('RGB'))\n",
        "\n",
        "        # Analisar caracter√≠sticas da imagem\n",
        "        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # An√°lise de bordas (favorece Canny - modo 0)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])\n",
        "\n",
        "        # An√°lise de varia√ß√£o de profundidade (favorece Depth - modo 2)\n",
        "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "        depth_variation = np.var(laplacian)\n",
        "\n",
        "        # An√°lise de estrutura corporal (favorece Pose - modo 4)\n",
        "        height, width = image_array.shape[:2]\n",
        "        aspect_ratio = height / width\n",
        "\n",
        "        print(f\"üìä Densidade de bordas: {edge_density:.3f}\")\n",
        "        print(f\"üìä Varia√ß√£o de profundidade: {depth_variation:.1f}\")\n",
        "        print(f\"üìä Aspect ratio: {aspect_ratio:.2f}\")\n",
        "\n",
        "        # L√≥gica de decis√£o baseada nas caracter√≠sticas\n",
        "        scores = {}\n",
        "\n",
        "        # Score para Canny (modo 0) - bom para contornos faciais n√≠tidos\n",
        "        if 0 in available_modes:\n",
        "            scores[0] = edge_density * 2.0 + (1.0 if depth_variation > 100 else 0.5)\n",
        "\n",
        "        # Score para Depth (modo 2) - bom para estrutura 3D facial\n",
        "        if 2 in available_modes:\n",
        "            scores[2] = (depth_variation / 500.0) + (1.0 if edge_density > 0.05 else 0.5)\n",
        "\n",
        "        # Score para Pose (modo 4) - bom para corpo inteiro\n",
        "        if 4 in available_modes:\n",
        "            scores[4] = (1.5 if aspect_ratio > 1.2 else 0.8) + (0.5 if edge_density > 0.03 else 0.2)\n",
        "\n",
        "        # Selecionar modo com maior score\n",
        "        if scores:\n",
        "            best_mode = max(scores.keys(), key=lambda k: scores[k])\n",
        "            mode_names = {0: \"Canny\", 1: \"Tile\", 2: \"Depth\", 3: \"Blur\", 4: \"Pose\", 5: \"Gray\", 6: \"Low Quality\"}\n",
        "\n",
        "            print(f\"\\nüèÜ MODO RECOMENDADO: {best_mode} ({mode_names.get(best_mode, 'Unknown')})\")\n",
        "            print(f\"üìä Score: {scores[best_mode]:.2f}\")\n",
        "\n",
        "            for mode, score in scores.items():\n",
        "                print(f\"   ‚Ä¢ Modo {mode} ({mode_names.get(mode, 'Unknown')}): {score:.2f}\")\n",
        "\n",
        "            return best_mode\n",
        "        else:\n",
        "            # Fallback para primeiro modo dispon√≠vel\n",
        "            fallback_mode = available_modes[0]\n",
        "            print(f\"üîß FALLBACK: Usando modo {fallback_mode}\")\n",
        "            return fallback_mode\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na detec√ß√£o autom√°tica: {e}\")\n",
        "        # Fallback para Canny se dispon√≠vel, sen√£o primeiro modo\n",
        "        return 0 if 0 in available_modes else available_modes[0]\n",
        "\n",
        "def process_control_image(image_path: str, mode: int, processors: Dict) -> Tuple[Image.Image, Dict]:\n",
        "    \"\"\"\n",
        "    Processa imagem de refer√™ncia para o modo ControlNet especificado\n",
        "\n",
        "    Args:\n",
        "        image_path: Caminho da imagem de refer√™ncia\n",
        "        mode: Modo ControlNet (0=canny, 2=depth, 4=pose, etc.)\n",
        "        processors: Dict com processadores configurados\n",
        "\n",
        "    Returns:\n",
        "        Tupla (imagem_processada, informa√ß√µes_do_processamento)\n",
        "    \"\"\"\n",
        "\n",
        "    mode_names = {0: \"Canny\", 1: \"Tile\", 2: \"Depth\", 3: \"Blur\", 4: \"Pose\", 5: \"Gray\", 6: \"Low Quality\"}\n",
        "    mode_name = mode_names.get(mode, f\"Mode_{mode}\")\n",
        "\n",
        "    print(f\"\\nüé® PROCESSANDO IMAGEM PARA MODO: {mode_name}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    processing_info = {\n",
        "        'mode': mode,\n",
        "        'mode_name': mode_name,\n",
        "        'success': False,\n",
        "        'processing_time': 0,\n",
        "        'output_path': None,\n",
        "        'quality_metrics': {}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        # Carregar imagem original\n",
        "        original_image = Image.open(image_path)\n",
        "        print(f\"üìÅ Imagem original: {original_image.size}\")\n",
        "\n",
        "        # Processar baseado no modo\n",
        "        if mode == 0:  # Canny\n",
        "            if 'canny' in processors:\n",
        "                if callable(processors['canny']):\n",
        "                    # Fallback OpenCV\n",
        "                    control_image = processors['canny'](original_image)\n",
        "                else:\n",
        "                    # ControlNet-aux\n",
        "                    control_image = processors['canny'](original_image, low_threshold=50, high_threshold=150)\n",
        "                print(\"‚úÖ Processamento Canny conclu√≠do\")\n",
        "            else:\n",
        "                raise Exception(\"Processador Canny n√£o dispon√≠vel\")\n",
        "\n",
        "        elif mode == 2:  # Depth\n",
        "            if 'depth' in processors:\n",
        "                control_image = processors['depth'](original_image)\n",
        "                print(\"‚úÖ Processamento Depth conclu√≠do\")\n",
        "            else:\n",
        "                # Fallback para Canny\n",
        "                print(\"‚ö†Ô∏è Depth indispon√≠vel - usando Canny como fallback\")\n",
        "                control_image = processors['canny'](original_image) if 'canny' in processors else original_image.convert('L')\n",
        "\n",
        "        elif mode == 4:  # Pose\n",
        "            if 'pose' in processors:\n",
        "                control_image = processors['pose'](original_image)\n",
        "                print(\"‚úÖ Processamento Pose conclu√≠do\")\n",
        "            else:\n",
        "                # Fallback para Canny\n",
        "                print(\"‚ö†Ô∏è Pose indispon√≠vel - usando Canny como fallback\")\n",
        "                control_image = processors['canny'](original_image) if 'canny' in processors else original_image.convert('L')\n",
        "\n",
        "        else:\n",
        "            # Para outros modos, usar Canny como base\n",
        "            print(f\"‚ö†Ô∏è Modo {mode} n√£o implementado - usando Canny\")\n",
        "            control_image = processors['canny'](original_image) if 'canny' in processors else original_image.convert('L')\n",
        "\n",
        "        # Converter para RGB se necess√°rio\n",
        "        if control_image.mode != 'RGB':\n",
        "            if control_image.mode == 'L':\n",
        "                control_image = Image.merge('RGB', [control_image, control_image, control_image])\n",
        "            else:\n",
        "                control_image = control_image.convert('RGB')\n",
        "\n",
        "        # Calcular tempo de processamento\n",
        "        processing_time = (datetime.now() - start_time).total_seconds()\n",
        "        processing_info['processing_time'] = processing_time\n",
        "\n",
        "        print(f\"‚è±Ô∏è Tempo de processamento: {processing_time:.2f}s\")\n",
        "        print(f\"üìê Imagem processada: {control_image.size}\")\n",
        "\n",
        "        processing_info['success'] = True\n",
        "\n",
        "        return control_image, processing_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro no processamento: {e}\")\n",
        "        processing_info['error'] = str(e)\n",
        "        return None, processing_info\n",
        "\n",
        "print(\"‚úÖ C√âLULA 3 CARREGADA: Fun√ß√µes de pr√©-processamento definidas\")"
      ],
      "metadata": {
        "id": "bEu06FiuVAJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 4: FASE 3.2 - Processamento Autom√°tico da Imagem =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 4: Processamento Autom√°tico da Imagem\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verificar se temos imagem v√°lida da c√©lula anterior\n",
        "if REFERENCE_IMAGE_PATH and VALIDATION_RESULT and VALIDATION_RESULT['valid']:\n",
        "\n",
        "    print(f\"üéØ PROCESSANDO: {ORIGINAL_FILENAME}\")\n",
        "    print(f\"üìÅ Caminho: {REFERENCE_IMAGE_PATH}\")\n",
        "\n",
        "    # Configurar processadores\n",
        "    print(\"\\nüîß CONFIGURANDO PROCESSADORES...\")\n",
        "    CONTROLNET_PROCESSORS = setup_controlnet_processors()\n",
        "\n",
        "    if not CONTROLNET_PROCESSORS:\n",
        "        print(\"‚ùå ERRO: Nenhum processador configurado\")\n",
        "        print(\"üîß Verifique instala√ß√£o do controlnet-aux\")\n",
        "    else:\n",
        "        # Detectar melhor modo baseado no ControlNet selecionado\n",
        "        available_modes = SELECTED_CONTROLNET['recommended_modes']\n",
        "        print(f\"\\nüéØ Modos dispon√≠veis no {SELECTED_CONTROLNET['name']}: {available_modes}\")\n",
        "\n",
        "        BEST_CONTROL_MODE = detect_best_control_mode(REFERENCE_IMAGE_PATH, available_modes)\n",
        "\n",
        "        # Processar imagem para o modo selecionado\n",
        "        print(f\"\\nüöÄ PROCESSANDO PARA MODO {BEST_CONTROL_MODE}...\")\n",
        "        CONTROL_IMAGE, PROCESSING_INFO = process_control_image(\n",
        "            REFERENCE_IMAGE_PATH,\n",
        "            BEST_CONTROL_MODE,\n",
        "            CONTROLNET_PROCESSORS\n",
        "        )\n",
        "\n",
        "        if CONTROL_IMAGE and PROCESSING_INFO['success']:\n",
        "            print(\"‚úÖ PROCESSAMENTO BEM-SUCEDIDO!\")\n",
        "\n",
        "            # Salvar imagem de controle\n",
        "            control_filename = f\"valentina_control_{PROCESSING_INFO['mode_name'].lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "            control_path = f\"/content/valentina_dataset_v4/control_images/{control_filename}\"\n",
        "\n",
        "            CONTROL_IMAGE.save(control_path)\n",
        "            PROCESSING_INFO['output_path'] = control_path\n",
        "\n",
        "            print(f\"üíæ Imagem de controle salva: {control_path}\")\n",
        "\n",
        "            # Log da opera√ß√£o\n",
        "            LOGGER.info(f\"Imagem de controle processada: modo {BEST_CONTROL_MODE}\")\n",
        "            LOGGER.info(f\"Tempo de processamento: {PROCESSING_INFO['processing_time']:.2f}s\")\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå FALHA NO PROCESSAMENTO\")\n",
        "            CONTROL_IMAGE = None\n",
        "            PROCESSING_INFO = {'success': False}\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå ERRO: Imagem de refer√™ncia inv√°lida ou n√£o carregada\")\n",
        "    print(\"üîß Execute as c√©lulas anteriores corretamente\")\n",
        "    CONTROLNET_PROCESSORS = {}\n",
        "    CONTROL_IMAGE = None\n",
        "    PROCESSING_INFO = {'success': False}\n",
        "    BEST_CONTROL_MODE = 0\n",
        "\n",
        "print(\"‚úÖ C√âLULA 4 CONCLU√çDA: Processamento autom√°tico realizado\")"
      ],
      "metadata": {
        "id": "71K0WHpaVF1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 5: FASE 3.3 - Otimiza√ß√£o e Valida√ß√£o das Imagens de Controle =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 5: Otimiza√ß√£o e Valida√ß√£o das Imagens de Controle\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def optimize_control_image(control_image: Image.Image, target_size: int = 1024) -> Tuple[Image.Image, Dict]:\n",
        "    \"\"\"\n",
        "    Otimiza imagem de controle para uso comercial\n",
        "\n",
        "    Args:\n",
        "        control_image: Imagem de controle processada\n",
        "        target_size: Tamanho alvo (padr√£o 1024x1024)\n",
        "\n",
        "    Returns:\n",
        "        Tupla (imagem_otimizada, m√©tricas_de_otimiza√ß√£o)\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüé® OTIMIZANDO IMAGEM DE CONTROLE PARA {target_size}x{target_size}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    optimization_metrics = {\n",
        "        'original_size': control_image.size,\n",
        "        'target_size': (target_size, target_size),\n",
        "        'resize_method': 'smart_pad',\n",
        "        'quality_preserved': False,\n",
        "        'aspect_ratio_maintained': False\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        original_width, original_height = control_image.size\n",
        "        print(f\"üìê Tamanho original: {original_width}x{original_height}\")\n",
        "\n",
        "        # Calcular aspect ratio\n",
        "        aspect_ratio = original_width / original_height\n",
        "        optimization_metrics['original_aspect_ratio'] = aspect_ratio\n",
        "\n",
        "        # Estrat√©gia de redimensionamento inteligente\n",
        "        if aspect_ratio == 1.0:\n",
        "            # J√° √© quadrado - apenas redimensionar\n",
        "            optimized_image = control_image.resize((target_size, target_size), Image.Resampling.LANCZOS)\n",
        "            print(\"üîÑ Redimensionamento direto (imagem j√° quadrada)\")\n",
        "            optimization_metrics['resize_method'] = 'direct_resize'\n",
        "\n",
        "        else:\n",
        "            # Imagem retangular - fazer padding inteligente\n",
        "            # Redimensionar mantendo aspect ratio para caber no target_size\n",
        "            if original_width > original_height:\n",
        "                new_width = target_size\n",
        "                new_height = int(target_size / aspect_ratio)\n",
        "            else:\n",
        "                new_height = target_size\n",
        "                new_width = int(target_size * aspect_ratio)\n",
        "\n",
        "            # Redimensionar mantendo propor√ß√£o\n",
        "            resized_image = control_image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "            # Criar imagem final com padding\n",
        "            optimized_image = Image.new('RGB', (target_size, target_size), color=(0, 0, 0))  # Padding preto\n",
        "\n",
        "            # Centralizar imagem redimensionada\n",
        "            paste_x = (target_size - new_width) // 2\n",
        "            paste_y = (target_size - new_height) // 2\n",
        "\n",
        "            optimized_image.paste(resized_image, (paste_x, paste_y))\n",
        "\n",
        "            print(f\"üîÑ Redimensionamento com padding: {new_width}x{new_height} -> {target_size}x{target_size}\")\n",
        "            print(f\"üìç Posi√ß√£o central: ({paste_x}, {paste_y})\")\n",
        "\n",
        "            optimization_metrics['resize_method'] = 'smart_pad'\n",
        "            optimization_metrics['aspect_ratio_maintained'] = True\n",
        "            optimization_metrics['padding_applied'] = (paste_x, paste_y)\n",
        "\n",
        "        # Validar qualidade da otimiza√ß√£o\n",
        "        quality_score = validate_control_image_quality(optimized_image)\n",
        "        optimization_metrics['quality_score'] = quality_score\n",
        "        optimization_metrics['quality_preserved'] = quality_score > 0.7\n",
        "\n",
        "        print(f\"‚≠ê Score de qualidade: {quality_score:.2f}/1.0\")\n",
        "\n",
        "        if optimization_metrics['quality_preserved']:\n",
        "            print(\"‚úÖ Qualidade preservada com sucesso\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Poss√≠vel perda de qualidade detectada\")\n",
        "\n",
        "        return optimized_image, optimization_metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na otimiza√ß√£o: {e}\")\n",
        "        optimization_metrics['error'] = str(e)\n",
        "        return control_image, optimization_metrics\n",
        "\n",
        "def validate_control_image_quality(control_image: Image.Image) -> float:\n",
        "    \"\"\"\n",
        "    Valida qualidade da imagem de controle otimizada\n",
        "\n",
        "    Args:\n",
        "        control_image: Imagem de controle\n",
        "\n",
        "    Returns:\n",
        "        Score de qualidade de 0.0 a 1.0\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Converter para array\n",
        "        image_array = np.array(control_image)\n",
        "\n",
        "        # Se √© grayscale expandido para RGB, converter de volta\n",
        "        if len(image_array.shape) == 3 and np.array_equal(image_array[:,:,0], image_array[:,:,1]):\n",
        "            gray = image_array[:,:,0]\n",
        "        else:\n",
        "            gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # An√°lise de defini√ß√£o das bordas/caracter√≠sticas\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])\n",
        "\n",
        "        # An√°lise de contraste\n",
        "        contrast = gray.std()\n",
        "\n",
        "        # An√°lise de informa√ß√£o (evitar imagens muito uniformes)\n",
        "        unique_values = len(np.unique(gray))\n",
        "        information_score = min(unique_values / 255.0, 1.0)\n",
        "\n",
        "        # Score combinado\n",
        "        quality_score = (\n",
        "            min(edge_density * 10, 1.0) * 0.4 +  # Densidade de bordas\n",
        "            min(contrast / 100.0, 1.0) * 0.3 +   # Contraste\n",
        "            information_score * 0.3               # Diversidade de informa√ß√£o\n",
        "        )\n",
        "\n",
        "        return min(quality_score, 1.0)\n",
        "\n",
        "    except Exception:\n",
        "        return 0.5  # Score neutro em caso de erro\n",
        "\n",
        "# Executar otimiza√ß√£o se temos imagem de controle v√°lida\n",
        "if CONTROL_IMAGE and PROCESSING_INFO['success']:\n",
        "\n",
        "    print(f\"üéØ OTIMIZANDO IMAGEM DE CONTROLE\")\n",
        "    print(f\"üé® Modo: {PROCESSING_INFO['mode_name']}\")\n",
        "\n",
        "    # Determinar tamanho alvo baseado na GPU\n",
        "    target_resolution = GPU_CONFIG['recommended_config']['max_resolution']\n",
        "    print(f\"üéØ Resolu√ß√£o alvo: {target_resolution}x{target_resolution}\")\n",
        "\n",
        "    # Otimizar imagem\n",
        "    OPTIMIZED_CONTROL_IMAGE, OPTIMIZATION_METRICS = optimize_control_image(\n",
        "        CONTROL_IMAGE,\n",
        "        target_resolution\n",
        "    )\n",
        "\n",
        "    if OPTIMIZATION_METRICS.get('quality_preserved', False):\n",
        "        # Salvar imagem otimizada\n",
        "        optimized_filename = f\"valentina_control_optimized_{PROCESSING_INFO['mode_name'].lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        optimized_path = f\"/content/valentina_dataset_v4/control_images/{optimized_filename}\"\n",
        "\n",
        "        OPTIMIZED_CONTROL_IMAGE.save(optimized_path)\n",
        "\n",
        "        print(f\"üíæ Imagem otimizada salva: {optimized_path}\")\n",
        "\n",
        "        # Atualizar informa√ß√µes para pr√≥xima fase\n",
        "        PROCESSING_INFO['optimized_path'] = optimized_path\n",
        "        PROCESSING_INFO['optimization_metrics'] = OPTIMIZATION_METRICS\n",
        "\n",
        "        # Log da opera√ß√£o\n",
        "        LOGGER.info(f\"Imagem de controle otimizada: {target_resolution}x{target_resolution}\")\n",
        "        LOGGER.info(f\"Qualidade preservada: {OPTIMIZATION_METRICS['quality_preserved']}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Otimiza√ß√£o n√£o atingiu padr√£o de qualidade\")\n",
        "        OPTIMIZED_CONTROL_IMAGE = CONTROL_IMAGE\n",
        "        OPTIMIZATION_METRICS = {'quality_preserved': False}\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå ERRO: Nenhuma imagem de controle para otimizar\")\n",
        "    print(\"üîß Execute as c√©lulas anteriores corretamente\")\n",
        "    OPTIMIZED_CONTROL_IMAGE = None\n",
        "    OPTIMIZATION_METRICS = {'success': False}\n",
        "\n",
        "print(\"‚úÖ C√âLULA 5 CONCLU√çDA: Otimiza√ß√£o e valida√ß√£o realizadas\")"
      ],
      "metadata": {
        "id": "DImxHDIKVIrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 6: FASE 3.3 - Preview e Resumo da FASE 3 =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 6: Preview e Resumo da FASE 3\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def create_processing_preview():\n",
        "    \"\"\"\n",
        "    Cria preview visual do processamento realizado\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üñºÔ∏è CRIANDO PREVIEW DO PROCESSAMENTO\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Configurar matplotlib para m√∫ltiplas imagens\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        fig.suptitle('Valentina Dataset Generator v4.0 - Processamento da Refer√™ncia', fontsize=16)\n",
        "\n",
        "        # Imagem original\n",
        "        if REFERENCE_IMAGE_PATH and os.path.exists(REFERENCE_IMAGE_PATH):\n",
        "            original_img = Image.open(REFERENCE_IMAGE_PATH)\n",
        "            axes[0].imshow(original_img)\n",
        "            axes[0].set_title(f'Original\\n{original_img.size[0]}x{original_img.size[1]}', fontsize=12)\n",
        "            axes[0].axis('off')\n",
        "        else:\n",
        "            axes[0].text(0.5, 0.5, 'Imagem Original\\nN√£o Dispon√≠vel', ha='center', va='center', fontsize=12)\n",
        "            axes[0].set_title('Original', fontsize=12)\n",
        "            axes[0].axis('off')\n",
        "\n",
        "        # Imagem de controle processada\n",
        "        if CONTROL_IMAGE:\n",
        "            axes[1].imshow(CONTROL_IMAGE)\n",
        "            mode_name = PROCESSING_INFO.get('mode_name', 'Processed')\n",
        "            axes[1].set_title(f'Controle ({mode_name})\\n{CONTROL_IMAGE.size[0]}x{CONTROL_IMAGE.size[1]}', fontsize=12)\n",
        "            axes[1].axis('off')\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.5, 'Imagem de Controle\\nN√£o Processada', ha='center', va='center', fontsize=12)\n",
        "            axes[1].set_title('Controle', fontsize=12)\n",
        "            axes[1].axis('off')\n",
        "\n",
        "        # Imagem otimizada\n",
        "        if OPTIMIZED_CONTROL_IMAGE:\n",
        "            axes[2].imshow(OPTIMIZED_CONTROL_IMAGE)\n",
        "            opt_size = OPTIMIZED_CONTROL_IMAGE.size\n",
        "            axes[2].set_title(f'Otimizada\\n{opt_size[0]}x{opt_size[1]}', fontsize=12)\n",
        "            axes[2].axis('off')\n",
        "        else:\n",
        "            axes[2].text(0.5, 0.5, 'Imagem Otimizada\\nN√£o Dispon√≠vel', ha='center', va='center', fontsize=12)\n",
        "            axes[2].set_title('Otimizada', fontsize=12)\n",
        "            axes[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Salvar preview\n",
        "        preview_path = f\"/content/valentina_dataset_v4/metadata/processing_preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        plt.savefig(preview_path, dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"üì∏ Preview salvo: {preview_path}\")\n",
        "        return preview_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro criando preview: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_phase3_report():\n",
        "    \"\"\"\n",
        "    Gera relat√≥rio completo da FASE 3\n",
        "\n",
        "    Returns:\n",
        "        Dict com relat√≥rio completo\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìä GERANDO RELAT√ìRIO DA FASE 3\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    report = {\n",
        "        'phase': 3,\n",
        "        'title': 'Processamento Inteligente da Imagem de Refer√™ncia',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'reference_image': {\n",
        "            'path': REFERENCE_IMAGE_PATH,\n",
        "            'filename': ORIGINAL_FILENAME,\n",
        "            'validation': VALIDATION_RESULT\n",
        "        },\n",
        "        'control_processing': {\n",
        "            'mode_selected': BEST_CONTROL_MODE,\n",
        "            'mode_name': PROCESSING_INFO.get('mode_name', 'Unknown'),\n",
        "            'processing_info': PROCESSING_INFO,\n",
        "            'processors_available': list(CONTROLNET_PROCESSORS.keys())\n",
        "        },\n",
        "        'optimization': {\n",
        "            'metrics': OPTIMIZATION_METRICS,\n",
        "            'target_resolution': GPU_CONFIG['recommended_config']['max_resolution'],\n",
        "            'success': OPTIMIZATION_METRICS.get('quality_preserved', False)\n",
        "        },\n",
        "        'outputs': {\n",
        "            'control_image_path': PROCESSING_INFO.get('output_path'),\n",
        "            'optimized_image_path': PROCESSING_INFO.get('optimized_path'),\n",
        "            'preview_path': None\n",
        "        },\n",
        "        'ready_for_generation': False\n",
        "    }\n",
        "\n",
        "    # Determinar se est√° pronto para gera√ß√£o\n",
        "    conditions = [\n",
        "        VALIDATION_RESULT and VALIDATION_RESULT['valid'],\n",
        "        PROCESSING_INFO.get('success', False),\n",
        "        OPTIMIZATION_METRICS.get('quality_preserved', False),\n",
        "        OPTIMIZED_CONTROL_IMAGE is not None\n",
        "    ]\n",
        "\n",
        "    report['ready_for_generation'] = all(conditions)\n",
        "\n",
        "    # Criar preview\n",
        "    preview_path = create_processing_preview()\n",
        "    if preview_path:\n",
        "        report['outputs']['preview_path'] = preview_path\n",
        "\n",
        "    # Salvar relat√≥rio\n",
        "    report_path = \"/content/valentina_dataset_v4/metadata/phase3_report.json\"\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(report, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"üìÑ Relat√≥rio salvo: {report_path}\")\n",
        "\n",
        "    return report\n",
        "\n",
        "# Gerar relat√≥rio final\n",
        "PHASE3_REPORT = generate_phase3_report()\n",
        "\n",
        "# =============================================================================\n",
        "# üìä RESUMO FINAL DA FASE 3\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä RESUMO DA FASE 3: PROCESSAMENTO DA IMAGEM DE REFER√äNCIA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if VALIDATION_RESULT:\n",
        "    print(f\"üìÅ Imagem de refer√™ncia: {ORIGINAL_FILENAME}\")\n",
        "    print(f\"‚úÖ Valida√ß√£o: {'APROVADA' if VALIDATION_RESULT['valid'] else 'COM PROBLEMAS'}\")\n",
        "    print(f\"üìê Dimens√µes: {VALIDATION_RESULT['dimensions'][0]}x{VALIDATION_RESULT['dimensions'][1]}\")\n",
        "    print(f\"‚≠ê Qualidade: {VALIDATION_RESULT['quality_score']:.2f}/1.0\")\n",
        "    print(f\"üë§ Face detectada: {'‚úÖ Sim' if VALIDATION_RESULT['face_detected'] else '‚ùå N√£o'}\")\n",
        "else:\n",
        "    print(\"‚ùå Imagem de refer√™ncia: N√ÉO PROCESSADA\")\n",
        "\n",
        "if PROCESSING_INFO.get('success'):\n",
        "    print(f\"\\nüéÆ ControlNet processamento: {PROCESSING_INFO['mode_name']} (modo {BEST_CONTROL_MODE})\")\n",
        "    print(f\"‚è±Ô∏è Tempo: {PROCESSING_INFO['processing_time']:.2f}s\")\n",
        "    print(f\"üîß Processadores: {len(CONTROLNET_PROCESSORS)}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå ControlNet processamento: FALHOU\")\n",
        "\n",
        "if OPTIMIZATION_METRICS.get('quality_preserved'):\n",
        "    target_res = GPU_CONFIG['recommended_config']['max_resolution']\n",
        "    print(f\"\\nüé® Otimiza√ß√£o: {target_res}x{target_res}\")\n",
        "    print(f\"‚≠ê Qualidade preservada: {'‚úÖ Sim' if OPTIMIZATION_METRICS['quality_preserved'] else '‚ùå N√£o'}\")\n",
        "    print(f\"üìê M√©todo: {OPTIMIZATION_METRICS.get('resize_method', 'Unknown')}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Otimiza√ß√£o: N√ÉO REALIZADA\")\n",
        "\n",
        "# Status para pr√≥xima fase\n",
        "if PHASE3_REPORT['ready_for_generation']:\n",
        "    print(f\"\\nüöÄ STATUS: PRONTO PARA FASE 4\")\n",
        "    print(f\"üíé Todos os pr√©-requisitos atendidos para gera√ß√£o comercial\")\n",
        "    print(f\"üéØ ControlNet: {SELECTED_CONTROLNET['name']}\")\n",
        "    print(f\"üñ•Ô∏è GPU: {GPU_CONFIG['name']} ({GPU_CONFIG['tier'].upper()})\")\n",
        "    print(f\"üìÅ Imagem de controle: {PROCESSING_INFO.get('optimized_path', 'N/A')}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è STATUS: PROBLEMAS DETECTADOS\")\n",
        "    print(f\"üîß Revise as etapas anteriores antes de continuar\")\n",
        "\n",
        "    issues = []\n",
        "    if not (VALIDATION_RESULT and VALIDATION_RESULT['valid']):\n",
        "        issues.append(\"Valida√ß√£o da imagem de refer√™ncia\")\n",
        "    if not PROCESSING_INFO.get('success'):\n",
        "        issues.append(\"Processamento ControlNet\")\n",
        "    if not OPTIMIZATION_METRICS.get('quality_preserved'):\n",
        "        issues.append(\"Otimiza√ß√£o da imagem\")\n",
        "\n",
        "    print(f\"‚ùå Problemas em: {', '.join(issues)}\")\n",
        "\n",
        "# Configura√ß√£o final para FASE 4\n",
        "CONTROL_CONFIG = {\n",
        "    'reference_image_path': REFERENCE_IMAGE_PATH,\n",
        "    'control_image_path': PROCESSING_INFO.get('optimized_path'),\n",
        "    'control_mode': BEST_CONTROL_MODE,\n",
        "    'control_strength': 0.7,  # Balanceado para manter identidade\n",
        "    'processing_validated': PHASE3_REPORT['ready_for_generation']\n",
        "}\n",
        "\n",
        "print(f\"\\nüî• CONFIGURA√á√ÉO PARA FASE 4:\")\n",
        "for key, value in CONTROL_CONFIG.items():\n",
        "    if 'path' in key and value:\n",
        "        print(f\"   ‚Ä¢ {key}: {os.path.basename(value)}\")\n",
        "    else:\n",
        "        print(f\"   ‚Ä¢ {key}: {value}\")\n",
        "\n",
        "LOGGER.info(\"FASE 3 conclu√≠da: Processamento da imagem de refer√™ncia\")\n",
        "LOGGER.info(f\"Status: {'SUCESSO' if PHASE3_REPORT['ready_for_generation'] else 'COM PROBLEMAS'}\")\n",
        "LOGGER.info(f\"Modo ControlNet: {BEST_CONTROL_MODE}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"‚úÖ C√âLULA 6 CONCLU√çDA: Preview e resumo da FASE 3\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "KPO0P0tuVOC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 1: FASE 4.1 - Templates de Prompts Comerciais Base =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üì± C√âLULA 1: Templates de Prompts Comerciais Base\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import random\n",
        "import re\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from datetime import datetime\n",
        "\n",
        "def get_commercial_prompt_templates() -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Templates de prompts otimizados para uso comercial (<77 tokens)\n",
        "\n",
        "    Returns:\n",
        "        Dict com categorias de templates comerciais\n",
        "    \"\"\"\n",
        "\n",
        "    templates = {\n",
        "        'portrait_elegante': [\n",
        "            \"elegant portrait of beautiful young woman, professional lighting, soft makeup, natural beauty, high quality photography\",\n",
        "            \"stunning portrait, natural beauty, soft lighting, elegant pose, professional photography, beautiful eyes, flawless skin\",\n",
        "            \"beautiful woman portrait, elegant style, natural makeup, soft studio lighting, high-end fashion photography\",\n",
        "            \"professional portrait, natural beauty, elegant pose, soft makeup, studio lighting, fashion photography quality\",\n",
        "            \"gorgeous portrait photography, natural elegance, soft professional lighting, beautiful features, high quality\"\n",
        "        ],\n",
        "\n",
        "        'lifestyle_premium': [\n",
        "            \"beautiful woman in luxury setting, elegant lifestyle, natural pose, professional photography, soft lighting\",\n",
        "            \"premium lifestyle photography, elegant woman, natural beauty, sophisticated setting, professional quality\",\n",
        "            \"luxury lifestyle portrait, beautiful model, elegant pose, natural lighting, high-end photography\",\n",
        "            \"sophisticated lifestyle shot, natural beauty, elegant setting, professional lighting, premium quality\",\n",
        "            \"upscale lifestyle photography, beautiful woman, natural elegance, soft lighting, professional style\"\n",
        "        ],\n",
        "\n",
        "        'fashion_comercial': [\n",
        "            \"fashion portrait of beautiful woman, elegant style, natural pose, professional photography, studio lighting\",\n",
        "            \"commercial fashion photography, stunning model, elegant outfit, natural beauty, professional lighting\",\n",
        "            \"high-end fashion portrait, beautiful woman, elegant pose, natural makeup, professional studio setup\",\n",
        "            \"fashion photography, natural beauty, elegant style, soft lighting, commercial quality, beautiful features\",\n",
        "            \"professional fashion shoot, elegant model, natural pose, beautiful styling, studio photography\"\n",
        "        ],\n",
        "\n",
        "        'beauty_natural': [\n",
        "            \"natural beauty portrait, beautiful woman, soft makeup, elegant pose, professional photography, studio lighting\",\n",
        "            \"beautiful natural portrait, elegant woman, soft lighting, minimal makeup, professional photography quality\",\n",
        "            \"natural beauty photography, stunning features, soft professional lighting, elegant pose, high quality\",\n",
        "            \"beauty portrait, natural elegance, soft makeup, professional lighting, beautiful woman, studio quality\",\n",
        "            \"natural beauty shoot, elegant woman, soft lighting, minimal styling, professional photography\"\n",
        "        ],\n",
        "\n",
        "        'sensual_elegante': [\n",
        "            \"elegant sensual portrait, beautiful woman, natural beauty, soft lighting, professional photography, artistic quality\",\n",
        "            \"sophisticated portrait, natural sensuality, elegant pose, soft professional lighting, beautiful features\",\n",
        "            \"artistic portrait photography, natural beauty, elegant sensuality, soft lighting, professional quality\",\n",
        "            \"refined portrait, natural elegance, sophisticated pose, soft lighting, professional photography style\",\n",
        "            \"tasteful portrait, natural beauty, elegant sensuality, professional lighting, artistic photography\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    print(f\"üìù TEMPLATES CARREGADOS:\")\n",
        "    for category, prompts in templates.items():\n",
        "        print(f\"   üéØ {category}: {len(prompts)} templates\")\n",
        "\n",
        "    print(f\"\\nüí° CARACTER√çSTICAS DOS TEMPLATES:\")\n",
        "    print(f\"   ‚Ä¢ Otimizados para <77 tokens (CLIP compatibility)\")\n",
        "    print(f\"   ‚Ä¢ Foco em qualidade comercial e eleg√¢ncia\")\n",
        "    print(f\"   ‚Ä¢ Evitam termos expl√≠citos ou inadequados\")\n",
        "    print(f\"   ‚Ä¢ Enfatizam professional photography e natural beauty\")\n",
        "    print(f\"   ‚Ä¢ Incluem quality triggers para FLUX\")\n",
        "\n",
        "    return templates\n",
        "\n",
        "def get_quality_enhancers() -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Enhancers de qualidade espec√≠ficos para FLUX\n",
        "\n",
        "    Returns:\n",
        "        Dict com enhancers por categoria\n",
        "    \"\"\"\n",
        "\n",
        "    enhancers = {\n",
        "        'technical_quality': [\n",
        "            \"high quality photography\",\n",
        "            \"professional photography\",\n",
        "            \"studio quality\",\n",
        "            \"commercial photography\",\n",
        "            \"professional lighting\",\n",
        "            \"high resolution\",\n",
        "            \"detailed photography\",\n",
        "            \"premium quality\"\n",
        "        ],\n",
        "\n",
        "        'lighting_setup': [\n",
        "            \"soft lighting\",\n",
        "            \"professional lighting\",\n",
        "            \"studio lighting\",\n",
        "            \"natural lighting\",\n",
        "            \"soft studio setup\",\n",
        "            \"professional studio lighting\",\n",
        "            \"elegant lighting\",\n",
        "            \"soft professional setup\"\n",
        "        ],\n",
        "\n",
        "        'aesthetic_quality': [\n",
        "            \"natural beauty\",\n",
        "            \"elegant style\",\n",
        "            \"sophisticated\",\n",
        "            \"refined\",\n",
        "            \"tasteful\",\n",
        "            \"artistic\",\n",
        "            \"premium\",\n",
        "            \"luxury\"\n",
        "        ],\n",
        "\n",
        "        'photographic_style': [\n",
        "            \"portrait photography\",\n",
        "            \"fashion photography\",\n",
        "            \"beauty photography\",\n",
        "            \"lifestyle photography\",\n",
        "            \"commercial photography\",\n",
        "            \"professional portrait\",\n",
        "            \"studio portrait\",\n",
        "            \"artistic portrait\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    print(f\"‚ú® QUALITY ENHANCERS CARREGADOS:\")\n",
        "    for category, items in enhancers.items():\n",
        "        print(f\"   üîß {category}: {len(items)} enhancers\")\n",
        "\n",
        "    return enhancers\n",
        "\n",
        "def get_negative_prompt_commercial() -> str:\n",
        "    \"\"\"\n",
        "    Prompt negativo otimizado para uso comercial\n",
        "\n",
        "    Returns:\n",
        "        String com prompt negativo\n",
        "    \"\"\"\n",
        "\n",
        "    negative_elements = [\n",
        "        # Qualidade t√©cnica\n",
        "        \"low quality\", \"blurry\", \"out of focus\", \"pixelated\", \"grainy\", \"noisy\",\n",
        "        \"low resolution\", \"compressed\", \"artifacts\", \"distorted\", \"deformed\",\n",
        "\n",
        "        # Problemas faciais\n",
        "        \"bad anatomy\", \"disfigured face\", \"ugly face\", \"asymmetric face\",\n",
        "        \"double face\", \"multiple faces\", \"extra limbs\", \"missing limbs\",\n",
        "\n",
        "        # Problemas t√©cnicos\n",
        "        \"overexposed\", \"underexposed\", \"harsh lighting\", \"bad lighting\",\n",
        "        \"amateur photography\", \"phone camera\", \"snapshot\", \"candid\",\n",
        "\n",
        "        # Elementos indesejados\n",
        "        \"watermark\", \"text\", \"signature\", \"logo\", \"brand\", \"copyright\",\n",
        "        \"frame\", \"border\", \"duplicate\", \"cropped\", \"cut off\",\n",
        "\n",
        "        # Estilo inadequado\n",
        "        \"cartoon\", \"anime\", \"3d render\", \"digital art\", \"painting\",\n",
        "        \"illustration\", \"sketch\", \"drawing\", \"artificial\"\n",
        "    ]\n",
        "\n",
        "    negative_prompt = \", \".join(negative_elements)\n",
        "\n",
        "    print(f\"üö´ PROMPT NEGATIVO COMERCIAL ({len(negative_prompt)} caracteres)\")\n",
        "    print(f\"   ‚Ä¢ Elementos t√©cnicos: qualidade, foco, resolu√ß√£o\")\n",
        "    print(f\"   ‚Ä¢ Elementos faciais: anatomia, simetria\")\n",
        "    print(f\"   ‚Ä¢ Elementos de lighting: exposi√ß√£o, setup\")\n",
        "    print(f\"   ‚Ä¢ Elementos indesejados: watermarks, text\")\n",
        "    print(f\"   ‚Ä¢ Estilo: mant√©m fotografia realista\")\n",
        "\n",
        "    return negative_prompt\n",
        "\n",
        "def count_tokens_estimate(text: str) -> int:\n",
        "    \"\"\"\n",
        "    Estima contagem de tokens para CLIP (aproxima√ß√£o)\n",
        "\n",
        "    Args:\n",
        "        text: Texto do prompt\n",
        "\n",
        "    Returns:\n",
        "        Estimativa de tokens\n",
        "    \"\"\"\n",
        "\n",
        "    # Aproxima√ß√£o: palavras + pontua√ß√£o + espa√ßos\n",
        "    words = len(text.split())\n",
        "    punctuation = len(re.findall(r'[,\\.!?;:]', text))\n",
        "\n",
        "    # CLIP tokenizer aproximadamente: 1.2-1.5 tokens por palavra\n",
        "    estimated_tokens = int(words * 1.3 + punctuation * 0.5)\n",
        "\n",
        "    return estimated_tokens\n",
        "\n",
        "# Executar carregamento dos templates\n",
        "print(\"üöÄ CARREGANDO SISTEMA DE TEMPLATES COMERCIAIS...\")\n",
        "\n",
        "COMMERCIAL_TEMPLATES = get_commercial_prompt_templates()\n",
        "QUALITY_ENHANCERS = get_quality_enhancers()\n",
        "NEGATIVE_PROMPT_COMMERCIAL = get_negative_prompt_commercial()\n",
        "\n",
        "print(f\"\\n‚úÖ SISTEMA DE TEMPLATES CONFIGURADO:\")\n",
        "print(f\"   üìù {sum(len(v) for v in COMMERCIAL_TEMPLATES.values())} templates comerciais\")\n",
        "print(f\"   ‚ú® {sum(len(v) for v in QUALITY_ENHANCERS.values())} quality enhancers\")\n",
        "print(f\"   üö´ Prompt negativo: {len(NEGATIVE_PROMPT_COMMERCIAL.split(', '))} elementos\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 1 CARREGADA: Templates comerciais definidos\")"
      ],
      "metadata": {
        "id": "QlajSsZjAnWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 2: FASE 4.2 - Sistema de Caracter√≠sticas da Valentina =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 2: Sistema de Caracter√≠sticas da Valentina\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def get_valentina_core_identity() -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Caracter√≠sticas fundamentais da Valentina Moreau (sempre inclu√≠das)\n",
        "\n",
        "    Returns:\n",
        "        Dict com caracter√≠sticas core obrigat√≥rias\n",
        "    \"\"\"\n",
        "\n",
        "    core_identity = {\n",
        "        'base_description': \"beautiful young woman\",\n",
        "        'facial_features': \"beautiful eyes, elegant facial features\",\n",
        "        'style_essence': \"natural beauty, elegant\",\n",
        "        'age_range': \"young adult woman\",\n",
        "        'overall_aesthetic': \"sophisticated, natural elegance\"\n",
        "    }\n",
        "\n",
        "    print(f\"üë§ IDENTIDADE CORE DA VALENTINA:\")\n",
        "    for key, value in core_identity.items():\n",
        "        print(f\"   ‚Ä¢ {key}: {value}\")\n",
        "\n",
        "    return core_identity\n",
        "\n",
        "def get_valentina_variable_features() -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Caracter√≠sticas vari√°veis da Valentina para diversidade do dataset\n",
        "\n",
        "    Returns:\n",
        "        Dict com features que podem variar entre gera√ß√µes\n",
        "    \"\"\"\n",
        "\n",
        "    variable_features = {\n",
        "        'hair_styles': [\n",
        "            \"long flowing hair\",\n",
        "            \"elegant updo\",\n",
        "            \"soft waves\",\n",
        "            \"sleek straight hair\",\n",
        "            \"natural waves\",\n",
        "            \"professional hairstyle\",\n",
        "            \"elegant styling\"\n",
        "        ],\n",
        "\n",
        "        'makeup_styles': [\n",
        "            \"natural makeup\",\n",
        "            \"soft makeup\",\n",
        "            \"minimal makeup\",\n",
        "            \"elegant makeup\",\n",
        "            \"professional makeup\",\n",
        "            \"subtle makeup\",\n",
        "            \"refined makeup\"\n",
        "        ],\n",
        "\n",
        "        'expressions': [\n",
        "            \"gentle smile\",\n",
        "            \"confident expression\",\n",
        "            \"serene expression\",\n",
        "            \"elegant pose\",\n",
        "            \"natural expression\",\n",
        "            \"sophisticated look\",\n",
        "            \"warm smile\",\n",
        "            \"professional demeanor\"\n",
        "        ],\n",
        "\n",
        "        'poses_angles': [\n",
        "            \"three-quarter view\",\n",
        "            \"slight angle\",\n",
        "            \"front facing\",\n",
        "            \"elegant pose\",\n",
        "            \"natural pose\",\n",
        "            \"professional pose\",\n",
        "            \"confident posture\",\n",
        "            \"graceful positioning\"\n",
        "        ],\n",
        "\n",
        "        'outfits_styles': [\n",
        "            \"elegant outfit\",\n",
        "            \"professional attire\",\n",
        "            \"sophisticated clothing\",\n",
        "            \"classy ensemble\",\n",
        "            \"refined style\",\n",
        "            \"elegant fashion\",\n",
        "            \"tasteful outfit\",\n",
        "            \"premium styling\"\n",
        "        ],\n",
        "\n",
        "        'settings_backgrounds': [\n",
        "            \"soft background\",\n",
        "            \"neutral background\",\n",
        "            \"elegant setting\",\n",
        "            \"professional backdrop\",\n",
        "            \"sophisticated environment\",\n",
        "            \"luxury setting\",\n",
        "            \"refined background\",\n",
        "            \"premium setting\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    print(f\"üé≠ CARACTER√çSTICAS VARI√ÅVEIS:\")\n",
        "    for category, options in variable_features.items():\n",
        "        print(f\"   üéØ {category}: {len(options)} op√ß√µes\")\n",
        "\n",
        "    return variable_features\n",
        "\n",
        "def create_valentina_prompt_base(template_category: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Cria prompt base da Valentina com caracter√≠sticas core\n",
        "\n",
        "    Args:\n",
        "        template_category: Categoria do template (opcional)\n",
        "\n",
        "    Returns:\n",
        "        Prompt base com identidade da Valentina\n",
        "    \"\"\"\n",
        "\n",
        "    core_identity = get_valentina_core_identity()\n",
        "\n",
        "    # Template espec√≠fico ou escolha aleat√≥ria\n",
        "    if template_category and template_category in COMMERCIAL_TEMPLATES:\n",
        "        base_template = random.choice(COMMERCIAL_TEMPLATES[template_category])\n",
        "    else:\n",
        "        # Escolher categoria aleat√≥ria\n",
        "        category = random.choice(list(COMMERCIAL_TEMPLATES.keys()))\n",
        "        base_template = random.choice(COMMERCIAL_TEMPLATES[category])\n",
        "\n",
        "    # Integrar caracter√≠sticas da Valentina no template\n",
        "    valentina_prompt = base_template\n",
        "\n",
        "    # Adicionar caracter√≠sticas core se n√£o estiverem presentes\n",
        "    if \"beautiful\" not in valentina_prompt.lower():\n",
        "        valentina_prompt = f\"{core_identity['base_description']}, {valentina_prompt}\"\n",
        "\n",
        "    if \"beautiful eyes\" not in valentina_prompt.lower():\n",
        "        valentina_prompt = f\"{valentina_prompt}, {core_identity['facial_features']}\"\n",
        "\n",
        "    return valentina_prompt\n",
        "\n",
        "def enhance_prompt_with_variables(base_prompt: str, variation_level: str = \"medium\") -> Tuple[str, Dict]:\n",
        "    \"\"\"\n",
        "    Adiciona caracter√≠sticas vari√°veis ao prompt base\n",
        "\n",
        "    Args:\n",
        "        base_prompt: Prompt base da Valentina\n",
        "        variation_level: N√≠vel de varia√ß√£o (low, medium, high)\n",
        "\n",
        "    Returns:\n",
        "        Tupla (prompt_enhanced, variables_used)\n",
        "    \"\"\"\n",
        "\n",
        "    variable_features = get_valentina_variable_features()\n",
        "    variables_used = {}\n",
        "\n",
        "    # Configurar quantidade de varia√ß√µes por n√≠vel\n",
        "    variation_config = {\n",
        "        'low': 2,     # Poucas varia√ß√µes - mais consist√™ncia\n",
        "        'medium': 3,  # Equil√≠brio\n",
        "        'high': 4     # Mais varia√ß√µes - maior diversidade\n",
        "    }\n",
        "\n",
        "    num_variations = variation_config.get(variation_level, 3)\n",
        "\n",
        "    # Selecionar categorias aleat√≥rias para variar\n",
        "    categories_to_vary = random.sample(list(variable_features.keys()), num_variations)\n",
        "\n",
        "    enhanced_prompt = base_prompt\n",
        "\n",
        "    for category in categories_to_vary:\n",
        "        feature = random.choice(variable_features[category])\n",
        "        variables_used[category] = feature\n",
        "        enhanced_prompt = f\"{enhanced_prompt}, {feature}\"\n",
        "\n",
        "    return enhanced_prompt, variables_used\n",
        "\n",
        "def optimize_prompt_for_flux(prompt: str, max_tokens: int = 75) -> Tuple[str, Dict]:\n",
        "    \"\"\"\n",
        "    Otimiza prompt para FLUX mantendo <77 tokens\n",
        "\n",
        "    Args:\n",
        "        prompt: Prompt para otimizar\n",
        "        max_tokens: Limite m√°ximo de tokens\n",
        "\n",
        "    Returns:\n",
        "        Tupla (prompt_otimizado, m√©tricas)\n",
        "    \"\"\"\n",
        "\n",
        "    optimization_metrics = {\n",
        "        'original_length': len(prompt),\n",
        "        'original_tokens_estimate': count_tokens_estimate(prompt),\n",
        "        'optimized_length': 0,\n",
        "        'optimized_tokens_estimate': 0,\n",
        "        'optimization_applied': False,\n",
        "        'quality_maintained': True\n",
        "    }\n",
        "\n",
        "    current_tokens = count_tokens_estimate(prompt)\n",
        "    optimized_prompt = prompt\n",
        "\n",
        "    if current_tokens > max_tokens:\n",
        "        print(f\"‚ö†Ô∏è Prompt muito longo: {current_tokens} tokens (max: {max_tokens})\")\n",
        "\n",
        "        # Estrat√©gias de otimiza√ß√£o\n",
        "        # 1. Remover palavras redundantes\n",
        "        redundant_words = ['very', 'really', 'quite', 'extremely', 'highly']\n",
        "        for word in redundant_words:\n",
        "            optimized_prompt = re.sub(rf'\\b{word}\\b,?\\s*', '', optimized_prompt, flags=re.IGNORECASE)\n",
        "\n",
        "        # 2. Consolidar termos similares\n",
        "        consolidations = {\n",
        "            r'professional photography,?\\s*high quality': 'professional photography',\n",
        "            r'natural beauty,?\\s*beautiful': 'natural beauty',\n",
        "            r'elegant,?\\s*sophisticated': 'elegant',\n",
        "            r'soft lighting,?\\s*professional lighting': 'soft professional lighting'\n",
        "        }\n",
        "\n",
        "        for pattern, replacement in consolidations.items():\n",
        "            optimized_prompt = re.sub(pattern, replacement, optimized_prompt, flags=re.IGNORECASE)\n",
        "\n",
        "        # 3. Limpar espa√ßos e v√≠rgulas extras\n",
        "        optimized_prompt = re.sub(r',\\s*,', ',', optimized_prompt)\n",
        "        optimized_prompt = re.sub(r'\\s+', ' ', optimized_prompt).strip()\n",
        "\n",
        "        optimization_metrics['optimization_applied'] = True\n",
        "\n",
        "    # Atualizar m√©tricas finais\n",
        "    optimization_metrics['optimized_length'] = len(optimized_prompt)\n",
        "    optimization_metrics['optimized_tokens_estimate'] = count_tokens_estimate(optimized_prompt)\n",
        "\n",
        "    return optimized_prompt, optimization_metrics\n",
        "\n",
        "# Executar configura√ß√£o do sistema da Valentina\n",
        "print(\"üöÄ CONFIGURANDO SISTEMA DE CARACTER√çSTICAS DA VALENTINA...\")\n",
        "\n",
        "VALENTINA_CORE = get_valentina_core_identity()\n",
        "VALENTINA_VARIABLES = get_valentina_variable_features()\n",
        "\n",
        "# Teste de gera√ß√£o de prompt\n",
        "print(f\"\\nüß™ TESTE DE GERA√á√ÉO DE PROMPT:\")\n",
        "test_prompt = create_valentina_prompt_base(\"portrait_elegante\")\n",
        "enhanced_prompt, variables = enhance_prompt_with_variables(test_prompt, \"medium\")\n",
        "optimized_prompt, metrics = optimize_prompt_for_flux(enhanced_prompt)\n",
        "\n",
        "print(f\"üìù Prompt base: {test_prompt}\")\n",
        "print(f\"‚ú® Prompt enhanced: {enhanced_prompt}\")\n",
        "print(f\"‚ö° Prompt otimizado: {optimized_prompt}\")\n",
        "print(f\"üìä Tokens estimados: {metrics['optimized_tokens_estimate']}\")\n",
        "print(f\"üé≠ Vari√°veis usadas: {list(variables.keys())}\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 2 CARREGADA: Sistema da Valentina configurado\")"
      ],
      "metadata": {
        "id": "qvVNFiNhAoKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 3: FASE 4.3 - Configura√ß√£o Dual Encoder e Otimiza√ß√£o =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 3: Configura√ß√£o Dual Encoder e Otimiza√ß√£o\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def configure_flux_dual_encoder_settings() -> Dict:\n",
        "    \"\"\"\n",
        "    Configura par√¢metros otimizados para dual encoder do FLUX\n",
        "\n",
        "    Returns:\n",
        "        Dict com configura√ß√µes do dual encoder\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üîß CONFIGURANDO DUAL ENCODER FLUX (CLIP + T5)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    dual_encoder_config = {\n",
        "        'clip_encoder': {\n",
        "            'max_tokens': 77,           # Limite CLIP\n",
        "            'focus': 'visual_style',    # Estilo visual, qualidade\n",
        "            'optimization': 'keywords', # Palavras-chave eficientes\n",
        "            'weight': 0.7              # Peso na gera√ß√£o\n",
        "        },\n",
        "\n",
        "        't5_encoder': {\n",
        "            'max_tokens': 512,         # Limite T5 (mais flex√≠vel)\n",
        "            'focus': 'detailed_description', # Descri√ß√µes detalhadas\n",
        "            'optimization': 'natural_language', # Linguagem natural\n",
        "            'weight': 0.3              # Peso complementar\n",
        "        },\n",
        "\n",
        "        'prompt_strategy': {\n",
        "            'clip_priority': [\n",
        "                'technical_quality',   # professional photography, high quality\n",
        "                'style_keywords',      # portrait, fashion, beauty\n",
        "                'visual_aesthetics',   # elegant, sophisticated, natural\n",
        "                'lighting_setup'       # soft lighting, studio lighting\n",
        "            ],\n",
        "\n",
        "            't5_priority': [\n",
        "                'detailed_descriptions', # Descri√ß√µes mais espec√≠ficas\n",
        "                'scene_context',        # Contexto da cena\n",
        "                'artistic_direction',   # Dire√ß√£o art√≠stica\n",
        "                'emotional_tone'        # Tom emocional\n",
        "            ]\n",
        "        },\n",
        "\n",
        "        'optimization_rules': {\n",
        "            'avoid_redundancy': True,\n",
        "            'prioritize_quality_tokens': True,\n",
        "            'balance_encoders': True,\n",
        "            'maintain_commercial_focus': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"‚ö° CLIP Encoder:\")\n",
        "    print(f\"   ‚Ä¢ Max tokens: {dual_encoder_config['clip_encoder']['max_tokens']}\")\n",
        "    print(f\"   ‚Ä¢ Foco: {dual_encoder_config['clip_encoder']['focus']}\")\n",
        "    print(f\"   ‚Ä¢ Peso: {dual_encoder_config['clip_encoder']['weight']}\")\n",
        "\n",
        "    print(f\"üß† T5 Encoder:\")\n",
        "    print(f\"   ‚Ä¢ Max tokens: {dual_encoder_config['t5_encoder']['max_tokens']}\")\n",
        "    print(f\"   ‚Ä¢ Foco: {dual_encoder_config['t5_encoder']['focus']}\")\n",
        "    print(f\"   ‚Ä¢ Peso: {dual_encoder_config['t5_encoder']['weight']}\")\n",
        "\n",
        "    return dual_encoder_config\n",
        "\n",
        "def split_prompt_for_dual_encoder(full_prompt: str, config: Dict) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Divide prompt otimizado para CLIP e T5 encoders\n",
        "\n",
        "    Args:\n",
        "        full_prompt: Prompt completo\n",
        "        config: Configura√ß√£o do dual encoder\n",
        "\n",
        "    Returns:\n",
        "        Tupla (clip_prompt, t5_prompt)\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüîÄ DIVIDINDO PROMPT PARA DUAL ENCODER\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Palavras-chave priorizadas para CLIP\n",
        "    clip_keywords = [\n",
        "        'professional photography', 'high quality', 'studio lighting',\n",
        "        'portrait photography', 'fashion photography', 'beauty photography',\n",
        "        'elegant', 'sophisticated', 'natural beauty', 'beautiful woman',\n",
        "        'soft lighting', 'professional lighting', 'commercial photography'\n",
        "    ]\n",
        "\n",
        "    # Separar elementos do prompt\n",
        "    prompt_elements = [elem.strip() for elem in full_prompt.split(',')]\n",
        "\n",
        "    clip_elements = []\n",
        "    t5_elements = []\n",
        "\n",
        "    for element in prompt_elements:\n",
        "        # Verificar se elemento cont√©m keywords priorit√°rias para CLIP\n",
        "        is_clip_priority = any(keyword in element.lower() for keyword in clip_keywords)\n",
        "\n",
        "        if is_clip_priority and len(' '.join(clip_elements).split()) < config['clip_encoder']['max_tokens'] - 5:\n",
        "            clip_elements.append(element)\n",
        "        else:\n",
        "            t5_elements.append(element)\n",
        "\n",
        "    # Construir prompts\n",
        "    clip_prompt = ', '.join(clip_elements)\n",
        "    t5_prompt = ', '.join(t5_elements)\n",
        "\n",
        "    # Verificar limites\n",
        "    clip_tokens = count_tokens_estimate(clip_prompt)\n",
        "    t5_tokens = count_tokens_estimate(t5_prompt)\n",
        "\n",
        "    print(f\"‚ö° CLIP prompt ({clip_tokens} tokens): {clip_prompt[:100]}...\")\n",
        "    print(f\"üß† T5 prompt ({t5_tokens} tokens): {t5_prompt[:100]}...\")\n",
        "\n",
        "    # Otimizar se necess√°rio\n",
        "    if clip_tokens > config['clip_encoder']['max_tokens']:\n",
        "        print(\"‚ö†Ô∏è CLIP prompt muito longo - otimizando...\")\n",
        "        clip_prompt, _ = optimize_prompt_for_flux(clip_prompt, config['clip_encoder']['max_tokens'])\n",
        "\n",
        "    return clip_prompt, t5_prompt\n",
        "\n",
        "def create_quality_optimized_prompt(\n",
        "    template_category: str = None,\n",
        "    variation_level: str = \"medium\",\n",
        "    use_dual_encoder: bool = True\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Cria prompt comercial otimizado para qualidade m√°xima\n",
        "\n",
        "    Args:\n",
        "        template_category: Categoria do template\n",
        "        variation_level: N√≠vel de varia√ß√£o\n",
        "        use_dual_encoder: Se deve usar configura√ß√£o dual encoder\n",
        "\n",
        "    Returns:\n",
        "        Dict com prompt otimizado e metadados\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüé® CRIANDO PROMPT COMERCIAL OTIMIZADO\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Criar prompt base da Valentina\n",
        "    base_prompt = create_valentina_prompt_base(template_category)\n",
        "\n",
        "    # Adicionar varia√ß√µes\n",
        "    enhanced_prompt, variables_used = enhance_prompt_with_variables(base_prompt, variation_level)\n",
        "\n",
        "    # Adicionar quality enhancers\n",
        "    quality_boosts = []\n",
        "    for category, enhancers in QUALITY_ENHANCERS.items():\n",
        "        if category == 'technical_quality':\n",
        "            quality_boosts.append(random.choice(enhancers))\n",
        "\n",
        "    enhanced_prompt = f\"{enhanced_prompt}, {', '.join(quality_boosts)}\"\n",
        "\n",
        "    # Otimizar para FLUX\n",
        "    optimized_prompt, optimization_metrics = optimize_prompt_for_flux(enhanced_prompt)\n",
        "\n",
        "    prompt_result = {\n",
        "        'template_category': template_category or 'random',\n",
        "        'variation_level': variation_level,\n",
        "        'base_prompt': base_prompt,\n",
        "        'enhanced_prompt': enhanced_prompt,\n",
        "        'optimized_prompt': optimized_prompt,\n",
        "        'negative_prompt': NEGATIVE_PROMPT_COMMERCIAL,\n",
        "        'variables_used': variables_used,\n",
        "        'optimization_metrics': optimization_metrics,\n",
        "        'estimated_tokens': optimization_metrics['optimized_tokens_estimate'],\n",
        "        'quality_score': calculate_prompt_quality_score(optimized_prompt),\n",
        "        'commercial_suitable': True\n",
        "    }\n",
        "\n",
        "    # Configura√ß√£o dual encoder se solicitada\n",
        "    if use_dual_encoder:\n",
        "        config = configure_flux_dual_encoder_settings()\n",
        "        clip_prompt, t5_prompt = split_prompt_for_dual_encoder(optimized_prompt, config)\n",
        "\n",
        "        prompt_result['dual_encoder'] = {\n",
        "            'clip_prompt': clip_prompt,\n",
        "            't5_prompt': t5_prompt,\n",
        "            'config': config\n",
        "        }\n",
        "\n",
        "    print(f\"‚úÖ PROMPT OTIMIZADO CRIADO:\")\n",
        "    print(f\"   üìù Categoria: {prompt_result['template_category']}\")\n",
        "    print(f\"   üìä Tokens: {prompt_result['estimated_tokens']}\")\n",
        "    print(f\"   ‚≠ê Qualidade: {prompt_result['quality_score']:.2f}/1.0\")\n",
        "    print(f\"   üé≠ Vari√°veis: {len(variables_used)}\")\n",
        "\n",
        "    return prompt_result\n",
        "\n",
        "def calculate_prompt_quality_score(prompt: str) -> float:\n",
        "    \"\"\"\n",
        "    Calcula score de qualidade do prompt comercial\n",
        "\n",
        "    Args:\n",
        "        prompt: Prompt para avaliar\n",
        "\n",
        "    Returns:\n",
        "        Score de qualidade (0.0 a 1.0)\n",
        "    \"\"\"\n",
        "\n",
        "    quality_indicators = [\n",
        "        'professional', 'high quality', 'elegant', 'beautiful',\n",
        "        'natural beauty', 'sophisticated', 'studio', 'commercial'\n",
        "    ]\n",
        "\n",
        "    style_indicators = [\n",
        "        'photography', 'portrait', 'lighting', 'professional'\n",
        "    ]\n",
        "\n",
        "    technical_indicators = [\n",
        "        'soft lighting', 'professional lighting', 'studio lighting'\n",
        "    ]\n",
        "\n",
        "    prompt_lower = prompt.lower()\n",
        "\n",
        "    # Calcular scores por categoria\n",
        "    quality_score = sum(1 for indicator in quality_indicators if indicator in prompt_lower) / len(quality_indicators)\n",
        "    style_score = sum(1 for indicator in style_indicators if indicator in prompt_lower) / len(style_indicators)\n",
        "    technical_score = sum(1 for indicator in technical_indicators if indicator in prompt_lower) / len(technical_indicators)\n",
        "\n",
        "    # Score combinado\n",
        "    total_score = (quality_score * 0.4 + style_score * 0.3 + technical_score * 0.3)\n",
        "\n",
        "    return min(total_score, 1.0)\n",
        "\n",
        "# Executar configura√ß√£o do dual encoder\n",
        "print(\"üöÄ CONFIGURANDO SISTEMA DUAL ENCODER...\")\n",
        "\n",
        "DUAL_ENCODER_CONFIG = configure_flux_dual_encoder_settings()\n",
        "\n",
        "# Teste de cria√ß√£o de prompt otimizado\n",
        "print(f\"\\nüß™ TESTE DE PROMPT COMERCIAL OTIMIZADO:\")\n",
        "test_optimized = create_quality_optimized_prompt(\n",
        "    template_category=\"portrait_elegante\",\n",
        "    variation_level=\"medium\",\n",
        "    use_dual_encoder=True\n",
        ")\n",
        "\n",
        "print(f\"\\nüìã RESULTADO DO TESTE:\")\n",
        "print(f\"‚ú® Prompt: {test_optimized['optimized_prompt']}\")\n",
        "print(f\"üìä Tokens: {test_optimized['estimated_tokens']}\")\n",
        "print(f\"‚≠ê Qualidade: {test_optimized['quality_score']:.2f}\")\n",
        "\n",
        "if 'dual_encoder' in test_optimized:\n",
        "    print(f\"‚ö° CLIP: {test_optimized['dual_encoder']['clip_prompt'][:80]}...\")\n",
        "    print(f\"üß† T5: {test_optimized['dual_encoder']['t5_prompt'][:80]}...\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 3 CARREGADA: Dual encoder configurado\")"
      ],
      "metadata": {
        "id": "B954vjNnAsz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 4: FASE 4.4 - Gerador de Varia√ß√µes Autom√°ticas =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 4: Gerador de Varia√ß√µes Autom√°ticas\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def generate_prompt_variations(\n",
        "    num_variations: int = 10,\n",
        "    categories: List[str] = None,\n",
        "    variation_level: str = \"medium\"\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Gera m√∫ltiplas varia√ß√µes de prompts comerciais da Valentina\n",
        "\n",
        "    Args:\n",
        "        num_variations: Quantidade de varia√ß√µes\n",
        "        categories: Categorias espec√≠ficas (opcional)\n",
        "        variation_level: N√≠vel de varia√ß√£o\n",
        "\n",
        "    Returns:\n",
        "        Lista com prompts variados\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"üé≠ GERANDO {num_variations} VARIA√á√ïES DE PROMPTS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    variations = []\n",
        "    used_combinations = set()  # Evitar duplicatas\n",
        "\n",
        "    # Categorias padr√£o se n√£o especificadas\n",
        "    if categories is None:\n",
        "        categories = list(COMMERCIAL_TEMPLATES.keys())\n",
        "\n",
        "    for i in range(num_variations):\n",
        "        # Selecionar categoria (balanceada)\n",
        "        category = categories[i % len(categories)]\n",
        "\n",
        "        # Criar varia√ß√£o √∫nica\n",
        "        attempts = 0\n",
        "        while attempts < 10:  # M√°ximo 10 tentativas para evitar duplicata\n",
        "            variation = create_quality_optimized_prompt(\n",
        "                template_category=category,\n",
        "                variation_level=variation_level,\n",
        "                use_dual_encoder=True\n",
        "            )\n",
        "\n",
        "            # Criar signature √∫nica baseada no prompt\n",
        "            signature = hash(variation['optimized_prompt'])\n",
        "\n",
        "            if signature not in used_combinations:\n",
        "                used_combinations.add(signature)\n",
        "                variation['variation_id'] = i + 1\n",
        "                variation['generation_timestamp'] = datetime.now().isoformat()\n",
        "                variations.append(variation)\n",
        "                break\n",
        "\n",
        "            attempts += 1\n",
        "\n",
        "        if attempts >= 10:\n",
        "            print(f\"‚ö†Ô∏è Duplicata n√£o resolvida para varia√ß√£o {i+1}\")\n",
        "\n",
        "    print(f\"‚úÖ {len(variations)} VARIA√á√ïES GERADAS COM SUCESSO\")\n",
        "\n",
        "    # Estat√≠sticas das varia√ß√µes\n",
        "    category_counts = {}\n",
        "    for var in variations:\n",
        "        cat = var['template_category']\n",
        "        category_counts[cat] = category_counts.get(cat, 0) + 1\n",
        "\n",
        "    print(f\"\\nüìä DISTRIBUI√á√ÉO POR CATEGORIA:\")\n",
        "    for category, count in category_counts.items():\n",
        "        print(f\"   üéØ {category}: {count} varia√ß√µes\")\n",
        "\n",
        "    return variations\n",
        "\n",
        "def create_batch_generation_config(variations: List[Dict]) -> Dict:\n",
        "    \"\"\"\n",
        "    Cria configura√ß√£o para gera√ß√£o em lote\n",
        "\n",
        "    Args:\n",
        "        variations: Lista de varia√ß√µes de prompts\n",
        "\n",
        "    Returns:\n",
        "        Dict com configura√ß√£o de batch\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n‚öôÔ∏è CRIANDO CONFIGURA√á√ÉO DE BATCH\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Configura√ß√£o baseada na GPU detectada\n",
        "    gpu_config = GPU_CONFIG['recommended_config']\n",
        "\n",
        "    batch_config = {\n",
        "        'total_variations': len(variations),\n",
        "        'batch_size': gpu_config['batch_size'],\n",
        "        'num_batches': len(variations) // gpu_config['batch_size'] + (1 if len(variations) % gpu_config['batch_size'] else 0),\n",
        "\n",
        "        'generation_settings': {\n",
        "            'num_inference_steps': gpu_config['inference_steps'],\n",
        "            'guidance_scale': gpu_config['guidance_scale'],\n",
        "            'width': gpu_config['max_resolution'],\n",
        "            'height': gpu_config['max_resolution'],\n",
        "            'controlnet_conditioning_scale': 0.7,\n",
        "            'control_guidance_start': 0.0,\n",
        "            'control_guidance_end': 0.8\n",
        "        },\n",
        "\n",
        "        'quality_settings': {\n",
        "            'use_dual_encoder': True,\n",
        "            'enable_safety_checker': False,  # Para velocidade\n",
        "            'generator_seed': None,  # Randomico para cada varia√ß√£o\n",
        "            'use_optimized_attention': True\n",
        "        },\n",
        "\n",
        "        'output_settings': {\n",
        "            'save_metadata': True,\n",
        "            'save_intermediate': False,\n",
        "            'quality_validation': True,\n",
        "            'auto_rejection': True\n",
        "        },\n",
        "\n",
        "        'performance_optimization': {\n",
        "            'torch_dtype': GPU_CONFIG['torch_dtype'],\n",
        "            'enable_cpu_offload': gpu_config.get('enable_cpu_offload', False),\n",
        "            'enable_attention_slicing': gpu_config.get('enable_attention_slicing', False),\n",
        "            'memory_cleanup_between_batches': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"üì¶ CONFIGURA√á√ÉO DE BATCH:\")\n",
        "    print(f\"   üéØ Total de varia√ß√µes: {batch_config['total_variations']}\")\n",
        "    print(f\"   üìä Batch size: {batch_config['batch_size']}\")\n",
        "    print(f\"   üîÑ N√∫mero de batches: {batch_config['num_batches']}\")\n",
        "    print(f\"   ‚öôÔ∏è Steps: {batch_config['generation_settings']['num_inference_steps']}\")\n",
        "    print(f\"   üìê Resolu√ß√£o: {batch_config['generation_settings']['width']}x{batch_config['generation_settings']['height']}\")\n",
        "\n",
        "    return batch_config\n",
        "\n",
        "def create_themed_variation_sets() -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Cria sets de varia√ß√µes tem√°ticas para diferentes usos comerciais\n",
        "\n",
        "    Returns:\n",
        "        Dict com sets tem√°ticos\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüé® CRIANDO SETS TEM√ÅTICOS PARA USO COMERCIAL\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    themed_sets = {}\n",
        "\n",
        "    # Set 1: Portraits Elegantes (para perfil e marketing)\n",
        "    print(\"üé≠ Gerando set: Portraits Elegantes...\")\n",
        "    themed_sets['portraits_elegantes'] = generate_prompt_variations(\n",
        "        num_variations=6,\n",
        "        categories=['portrait_elegante', 'beauty_natural'],\n",
        "        variation_level=\"low\"  # Mais consist√™ncia\n",
        "    )\n",
        "\n",
        "    # Set 2: Lifestyle Premium (para conte√∫do premium)\n",
        "    print(\"üèÜ Gerando set: Lifestyle Premium...\")\n",
        "    themed_sets['lifestyle_premium'] = generate_prompt_variations(\n",
        "        num_variations=6,\n",
        "        categories=['lifestyle_premium', 'fashion_comercial'],\n",
        "        variation_level=\"medium\"\n",
        "    )\n",
        "\n",
        "    # Set 3: Fashion & Beauty (para portf√≥lio)\n",
        "    print(\"üíÑ Gerando set: Fashion & Beauty...\")\n",
        "    themed_sets['fashion_beauty'] = generate_prompt_variations(\n",
        "        num_variations=6,\n",
        "        categories=['fashion_comercial', 'beauty_natural'],\n",
        "        variation_level=\"medium\"\n",
        "    )\n",
        "\n",
        "    # Set 4: Sensual Elegante (para conte√∫do premium adulto)\n",
        "    print(\"üåπ Gerando set: Sensual Elegante...\")\n",
        "    themed_sets['sensual_elegante'] = generate_prompt_variations(\n",
        "        num_variations=6,\n",
        "        categories=['sensual_elegante'],\n",
        "        variation_level=\"high\"  # Mais diversidade\n",
        "    )\n",
        "\n",
        "    # Set 5: Mix Comercial (variedade geral)\n",
        "    print(\"üéØ Gerando set: Mix Comercial...\")\n",
        "    themed_sets['mix_comercial'] = generate_prompt_variations(\n",
        "        num_variations=8,\n",
        "        categories=list(COMMERCIAL_TEMPLATES.keys()),\n",
        "        variation_level=\"medium\"\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚úÖ SETS TEM√ÅTICOS CRIADOS:\")\n",
        "    for set_name, variations in themed_sets.items():\n",
        "        print(f\"   üé® {set_name}: {len(variations)} varia√ß√µes\")\n",
        "\n",
        "    return themed_sets\n",
        "\n",
        "def validate_prompt_variations(variations: List[Dict]) -> Dict:\n",
        "    \"\"\"\n",
        "    Valida qualidade das varia√ß√µes geradas\n",
        "\n",
        "    Args:\n",
        "        variations: Lista de varia√ß√µes\n",
        "\n",
        "    Returns:\n",
        "        Dict com m√©tricas de valida√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüîç VALIDANDO {len(variations)} VARIA√á√ïES\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    validation_metrics = {\n",
        "        'total_variations': len(variations),\n",
        "        'quality_scores': [],\n",
        "        'token_counts': [],\n",
        "        'categories_distribution': {},\n",
        "        'optimization_success_rate': 0,\n",
        "        'commercial_suitability_rate': 0,\n",
        "        'duplicate_count': 0\n",
        "    }\n",
        "\n",
        "    optimized_count = 0\n",
        "    commercial_count = 0\n",
        "    prompts_seen = set()\n",
        "\n",
        "    for variation in variations:\n",
        "        # Coletar m√©tricas\n",
        "        quality_score = variation.get('quality_score', 0)\n",
        "        token_count = variation.get('estimated_tokens', 0)\n",
        "        category = variation.get('template_category', 'unknown')\n",
        "\n",
        "        validation_metrics['quality_scores'].append(quality_score)\n",
        "        validation_metrics['token_counts'].append(token_count)\n",
        "\n",
        "        # Distribui√ß√£o de categorias\n",
        "        validation_metrics['categories_distribution'][category] = \\\n",
        "            validation_metrics['categories_distribution'].get(category, 0) + 1\n",
        "\n",
        "        # Contadores\n",
        "        if variation.get('optimization_metrics', {}).get('optimization_applied', False) or token_count <= 75:\n",
        "            optimized_count += 1\n",
        "\n",
        "        if variation.get('commercial_suitable', False):\n",
        "            commercial_count += 1\n",
        "\n",
        "        # Detectar duplicatas\n",
        "        prompt = variation.get('optimized_prompt', '')\n",
        "        if prompt in prompts_seen:\n",
        "            validation_metrics['duplicate_count'] += 1\n",
        "        prompts_seen.add(prompt)\n",
        "\n",
        "    # Calcular taxas\n",
        "    validation_metrics['optimization_success_rate'] = optimized_count / len(variations)\n",
        "    validation_metrics['commercial_suitability_rate'] = commercial_count / len(variations)\n",
        "\n",
        "    # Estat√≠sticas\n",
        "    validation_metrics['average_quality'] = sum(validation_metrics['quality_scores']) / len(variations)\n",
        "    validation_metrics['average_tokens'] = sum(validation_metrics['token_counts']) / len(variations)\n",
        "\n",
        "    print(f\"üìä M√âTRICAS DE VALIDA√á√ÉO:\")\n",
        "    print(f\"   ‚≠ê Qualidade m√©dia: {validation_metrics['average_quality']:.2f}/1.0\")\n",
        "    print(f\"   üìä Tokens m√©dios: {validation_metrics['average_tokens']:.1f}\")\n",
        "    print(f\"   ‚ö° Taxa de otimiza√ß√£o: {validation_metrics['optimization_success_rate']:.1%}\")\n",
        "    print(f\"   üí∞ Taxa comercial: {validation_metrics['commercial_suitability_rate']:.1%}\")\n",
        "    print(f\"   üîÑ Duplicatas: {validation_metrics['duplicate_count']}\")\n",
        "\n",
        "    return validation_metrics\n",
        "\n",
        "# Executar gera√ß√£o de varia√ß√µes\n",
        "print(\"üöÄ GERANDO SISTEMA DE VARIA√á√ïES AUTOM√ÅTICAS...\")\n",
        "\n",
        "# Criar sets tem√°ticos\n",
        "THEMED_VARIATION_SETS = create_themed_variation_sets()\n",
        "\n",
        "# Juntar todas as varia√ß√µes para configura√ß√£o de batch\n",
        "ALL_VARIATIONS = []\n",
        "for set_name, variations in THEMED_VARIATION_SETS.items():\n",
        "    ALL_VARIATIONS.extend(variations)\n",
        "\n",
        "print(f\"\\nüì¶ TOTAL DE VARIA√á√ïES GERADAS: {len(ALL_VARIATIONS)}\")\n",
        "\n",
        "# Criar configura√ß√£o de batch\n",
        "BATCH_CONFIG = create_batch_generation_config(ALL_VARIATIONS)\n",
        "\n",
        "# Validar qualidade das varia√ß√µes\n",
        "VALIDATION_METRICS = validate_prompt_variations(ALL_VARIATIONS)\n",
        "\n",
        "print(\"‚úÖ C√âLULA 4 CARREGADA: Varia√ß√µes autom√°ticas geradas\")"
      ],
      "metadata": {
        "id": "Bl-668htAx1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 5: FASE 4.5 - Sistema de Valida√ß√£o de Prompts =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 5: Sistema de Valida√ß√£o de Prompts\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def validate_commercial_compliance(prompt_data: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Valida conformidade comercial do prompt\n",
        "\n",
        "    Args:\n",
        "        prompt_data: Dados do prompt para validar\n",
        "\n",
        "    Returns:\n",
        "        Dict com resultado da valida√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    compliance_result = {\n",
        "        'compliant': True,\n",
        "        'issues': [],\n",
        "        'recommendations': [],\n",
        "        'commercial_score': 1.0\n",
        "    }\n",
        "\n",
        "    prompt = prompt_data.get('optimized_prompt', '').lower()\n",
        "\n",
        "    # Verificar conte√∫do inadequado\n",
        "    inappropriate_terms = [\n",
        "        'nude', 'naked', 'explicit', 'nsfw', 'sexual', 'erotic',\n",
        "        'provocative', 'seductive', 'revealing', 'intimate'\n",
        "    ]\n",
        "\n",
        "    for term in inappropriate_terms:\n",
        "        if term in prompt:\n",
        "            compliance_result['issues'].append(f\"Termo inadequado: '{term}'\")\n",
        "            compliance_result['commercial_score'] -= 0.3\n",
        "\n",
        "    # Verificar qualidade comercial\n",
        "    quality_terms = [\n",
        "        'professional', 'elegant', 'sophisticated', 'natural beauty',\n",
        "        'high quality', 'commercial', 'studio'\n",
        "    ]\n",
        "\n",
        "    quality_count = sum(1 for term in quality_terms if term in prompt)\n",
        "    if quality_count < 2:\n",
        "        compliance_result['recommendations'].append(\"Adicionar mais termos de qualidade\")\n",
        "        compliance_result['commercial_score'] -= 0.1\n",
        "\n",
        "    # Verificar tokens\n",
        "    tokens = prompt_data.get('estimated_tokens', 0)\n",
        "    if tokens > 77:\n",
        "        compliance_result['issues'].append(f\"Muitos tokens: {tokens} (max: 77)\")\n",
        "        compliance_result['commercial_score'] -= 0.2\n",
        "\n",
        "    # Status final\n",
        "    compliance_result['compliant'] = len(compliance_result['issues']) == 0\n",
        "    compliance_result['commercial_score'] = max(compliance_result['commercial_score'], 0.0)\n",
        "\n",
        "    return compliance_result\n",
        "\n",
        "def filter_high_quality_prompts(variations: List[Dict], min_quality: float = 0.7) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Filtra apenas prompts de alta qualidade\n",
        "\n",
        "    Args:\n",
        "        variations: Lista de varia√ß√µes\n",
        "        min_quality: Score m√≠nimo de qualidade\n",
        "\n",
        "    Returns:\n",
        "        Lista filtrada de alta qualidade\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüéØ FILTRANDO PROMPTS DE ALTA QUALIDADE (min: {min_quality})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    high_quality = []\n",
        "    rejected = []\n",
        "\n",
        "    for variation in variations:\n",
        "        quality_score = variation.get('quality_score', 0)\n",
        "        tokens = variation.get('estimated_tokens', 100)\n",
        "\n",
        "        # Validar conformidade comercial\n",
        "        compliance = validate_commercial_compliance(variation)\n",
        "\n",
        "        # Crit√©rios de qualidade\n",
        "        meets_quality = quality_score >= min_quality\n",
        "        meets_tokens = tokens <= 77\n",
        "        meets_compliance = compliance['compliant']\n",
        "\n",
        "        if meets_quality and meets_tokens and meets_compliance:\n",
        "            variation['validation_passed'] = True\n",
        "            variation['compliance_result'] = compliance\n",
        "            high_quality.append(variation)\n",
        "        else:\n",
        "            reasons = []\n",
        "            if not meets_quality:\n",
        "                reasons.append(f\"qualidade baixa ({quality_score:.2f})\")\n",
        "            if not meets_tokens:\n",
        "                reasons.append(f\"muitos tokens ({tokens})\")\n",
        "            if not meets_compliance:\n",
        "                reasons.append(\"n√£o conforme\")\n",
        "\n",
        "            variation['validation_passed'] = False\n",
        "            variation['rejection_reasons'] = reasons\n",
        "            rejected.append(variation)\n",
        "\n",
        "    print(f\"‚úÖ APROVADOS: {len(high_quality)}\")\n",
        "    print(f\"‚ùå REJEITADOS: {len(rejected)}\")\n",
        "\n",
        "    if rejected:\n",
        "        print(f\"\\nüìã PRINCIPAIS MOTIVOS DE REJEI√á√ÉO:\")\n",
        "        rejection_counts = {}\n",
        "        for var in rejected:\n",
        "            for reason in var.get('rejection_reasons', []):\n",
        "                rejection_counts[reason] = rejection_counts.get(reason, 0) + 1\n",
        "\n",
        "        for reason, count in rejection_counts.items():\n",
        "            print(f\"   ‚Ä¢ {reason}: {count} casos\")\n",
        "\n",
        "    return high_quality\n",
        "\n",
        "def create_final_prompt_dataset(high_quality_prompts: List[Dict]) -> Dict:\n",
        "    \"\"\"\n",
        "    Cria dataset final de prompts aprovados\n",
        "\n",
        "    Args:\n",
        "        high_quality_prompts: Prompts aprovados\n",
        "\n",
        "    Returns:\n",
        "        Dict com dataset final\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüì¶ CRIANDO DATASET FINAL DE PROMPTS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    dataset = {\n",
        "        'metadata': {\n",
        "            'version': '4.0',\n",
        "            'creation_date': datetime.now().isoformat(),\n",
        "            'total_prompts': len(high_quality_prompts),\n",
        "            'character': 'Valentina Moreau',\n",
        "            'purpose': 'Commercial AI Model Dataset',\n",
        "            'platforms': ['TopFans', 'OnlyFans', 'Premium Content'],\n",
        "            'quality_threshold': 0.7,\n",
        "            'token_limit': 77\n",
        "        },\n",
        "\n",
        "        'prompts': [],\n",
        "        'statistics': {\n",
        "            'categories': {},\n",
        "            'quality_distribution': {},\n",
        "            'token_distribution': {},\n",
        "            'variation_levels': {}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Processar cada prompt\n",
        "    for i, prompt_data in enumerate(high_quality_prompts):\n",
        "        processed_prompt = {\n",
        "            'id': f\"valentina_prompt_{i+1:03d}\",\n",
        "            'prompt': prompt_data['optimized_prompt'],\n",
        "            'negative_prompt': prompt_data['negative_prompt'],\n",
        "            'category': prompt_data['template_category'],\n",
        "            'variation_level': prompt_data['variation_level'],\n",
        "            'quality_score': prompt_data['quality_score'],\n",
        "            'estimated_tokens': prompt_data['estimated_tokens'],\n",
        "            'variables_used': prompt_data['variables_used'],\n",
        "            'dual_encoder': prompt_data.get('dual_encoder', {}),\n",
        "            'generation_ready': True\n",
        "        }\n",
        "\n",
        "        dataset['prompts'].append(processed_prompt)\n",
        "\n",
        "        # Estat√≠sticas\n",
        "        category = prompt_data['template_category']\n",
        "        dataset['statistics']['categories'][category] = \\\n",
        "            dataset['statistics']['categories'].get(category, 0) + 1\n",
        "\n",
        "        quality_range = f\"{int(prompt_data['quality_score'] * 10) / 10:.1f}\"\n",
        "        dataset['statistics']['quality_distribution'][quality_range] = \\\n",
        "            dataset['statistics']['quality_distribution'].get(quality_range, 0) + 1\n",
        "\n",
        "        token_range = f\"{(prompt_data['estimated_tokens'] // 10) * 10}-{(prompt_data['estimated_tokens'] // 10) * 10 + 9}\"\n",
        "        dataset['statistics']['token_distribution'][token_range] = \\\n",
        "            dataset['statistics']['token_distribution'].get(token_range, 0) + 1\n",
        "\n",
        "        variation_level = prompt_data['variation_level']\n",
        "        dataset['statistics']['variation_levels'][variation_level] = \\\n",
        "            dataset['statistics']['variation_levels'].get(variation_level, 0) + 1\n",
        "\n",
        "    print(f\"üìä DATASET FINAL CRIADO:\")\n",
        "    print(f\"   üéØ Total de prompts: {dataset['metadata']['total_prompts']}\")\n",
        "    print(f\"   üìà Categorias: {len(dataset['statistics']['categories'])}\")\n",
        "    print(f\"   ‚≠ê Qualidade m√©dia: {sum(p['quality_score'] for p in dataset['prompts']) / len(dataset['prompts']):.2f}\")\n",
        "    print(f\"   üìä Tokens m√©dios: {sum(p['estimated_tokens'] for p in dataset['prompts']) / len(dataset['prompts']):.1f}\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def save_dataset_and_config(dataset: Dict, variations: List[Dict]) -> Dict:\n",
        "    \"\"\"\n",
        "    Salva dataset e configura√ß√µes para a pr√≥xima fase\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset final\n",
        "        variations: Todas as varia√ß√µes (incluindo rejeitadas)\n",
        "\n",
        "    Returns:\n",
        "        Dict com paths dos arquivos salvos\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüíæ SALVANDO DATASET E CONFIGURA√á√ïES\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "    # Paths dos arquivos\n",
        "    paths = {\n",
        "        'dataset_file': f\"/content/valentina_dataset_v4/metadata/prompts_dataset_{timestamp}.json\",\n",
        "        'variations_file': f\"/content/valentina_dataset_v4/metadata/all_variations_{timestamp}.json\",\n",
        "        'batch_config_file': f\"/content/valentina_dataset_v4/metadata/batch_config_{timestamp}.json\",\n",
        "        'validation_file': f\"/content/valentina_dataset_v4/metadata/validation_report_{timestamp}.json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Salvar dataset final\n",
        "        with open(paths['dataset_file'], 'w') as f:\n",
        "            json.dump(dataset, f, indent=2, default=str)\n",
        "        print(f\"‚úÖ Dataset salvo: {os.path.basename(paths['dataset_file'])}\")\n",
        "\n",
        "        # Salvar todas as varia√ß√µes (para an√°lise)\n",
        "        with open(paths['variations_file'], 'w') as f:\n",
        "            json.dump(variations, f, indent=2, default=str)\n",
        "        print(f\"‚úÖ Varia√ß√µes salvas: {os.path.basename(paths['variations_file'])}\")\n",
        "\n",
        "        # Salvar configura√ß√£o de batch\n",
        "        with open(paths['batch_config_file'], 'w') as f:\n",
        "            json.dump(BATCH_CONFIG, f, indent=2, default=str)\n",
        "        print(f\"‚úÖ Config batch salva: {os.path.basename(paths['batch_config_file'])}\")\n",
        "\n",
        "        # Salvar relat√≥rio de valida√ß√£o\n",
        "        with open(paths['validation_file'], 'w') as f:\n",
        "            json.dump(VALIDATION_METRICS, f, indent=2, default=str)\n",
        "        print(f\"‚úÖ Valida√ß√£o salva: {os.path.basename(paths['validation_file'])}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro salvando arquivos: {e}\")\n",
        "\n",
        "    return paths\n",
        "\n",
        "# Executar valida√ß√£o e cria√ß√£o do dataset final\n",
        "print(\"üöÄ EXECUTANDO VALIDA√á√ÉO E CRIA√á√ÉO DO DATASET FINAL...\")\n",
        "\n",
        "# Filtrar prompts de alta qualidade\n",
        "HIGH_QUALITY_PROMPTS = filter_high_quality_prompts(ALL_VARIATIONS, min_quality=0.7)\n",
        "\n",
        "# Criar dataset final\n",
        "FINAL_DATASET = create_final_prompt_dataset(HIGH_QUALITY_PROMPTS)\n",
        "\n",
        "# Salvar tudo\n",
        "SAVED_PATHS = save_dataset_and_config(FINAL_DATASET, ALL_VARIATIONS)\n",
        "\n",
        "print(\"‚úÖ C√âLULA 5 CARREGADA: Valida√ß√£o e dataset final criados\")"
      ],
      "metadata": {
        "id": "NzZfEAk3A3b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 6: FASE 4.6 - Preview e Resumo da FASE 4 =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 6: Preview e Resumo da FASE 4\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def create_prompts_preview() -> None:\n",
        "    \"\"\"\n",
        "    Cria preview visual dos prompts gerados\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üìã PREVIEW DOS PROMPTS COMERCIAIS GERADOS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Selecionar amostras representativas\n",
        "    sample_prompts = HIGH_QUALITY_PROMPTS[:5] if len(HIGH_QUALITY_PROMPTS) >= 5 else HIGH_QUALITY_PROMPTS\n",
        "\n",
        "    print(f\"üìù AMOSTRAS DE PROMPTS DE ALTA QUALIDADE:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, prompt_data in enumerate(sample_prompts, 1):\n",
        "        print(f\"\\nüéØ AMOSTRA {i}:\")\n",
        "        print(f\"   üìÇ Categoria: {prompt_data['template_category']}\")\n",
        "        print(f\"   ‚≠ê Qualidade: {prompt_data['quality_score']:.2f}/1.0\")\n",
        "        print(f\"   üìä Tokens: {prompt_data['estimated_tokens']}\")\n",
        "        print(f\"   üé≠ Vari√°veis: {len(prompt_data['variables_used'])}\")\n",
        "        print(f\"   üìù Prompt: {prompt_data['optimized_prompt']}\")\n",
        "\n",
        "        if 'dual_encoder' in prompt_data:\n",
        "            print(f\"   ‚ö° CLIP: {prompt_data['dual_encoder']['clip_prompt'][:60]}...\")\n",
        "            print(f\"   üß† T5: {prompt_data['dual_encoder']['t5_prompt'][:60]}...\")\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "def generate_phase4_report() -> Dict:\n",
        "    \"\"\"\n",
        "    Gera relat√≥rio completo da FASE 4\n",
        "\n",
        "    Returns:\n",
        "        Dict com relat√≥rio detalhado\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüìä GERANDO RELAT√ìRIO DA FASE 4\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    report = {\n",
        "        'phase': 4,\n",
        "        'title': 'Sistema de Prompts Comerciais Otimizados',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "\n",
        "        'templates_system': {\n",
        "            'total_templates': sum(len(v) for v in COMMERCIAL_TEMPLATES.values()),\n",
        "            'categories': list(COMMERCIAL_TEMPLATES.keys()),\n",
        "            'quality_enhancers': sum(len(v) for v in QUALITY_ENHANCERS.values()),\n",
        "            'negative_prompt_elements': len(NEGATIVE_PROMPT_COMMERCIAL.split(', '))\n",
        "        },\n",
        "\n",
        "        'valentina_identity': {\n",
        "            'core_characteristics': len(VALENTINA_CORE),\n",
        "            'variable_features': len(VALENTINA_VARIABLES),\n",
        "            'total_combinations': sum(len(v) for v in VALENTINA_VARIABLES.values())\n",
        "        },\n",
        "\n",
        "        'dual_encoder_config': DUAL_ENCODER_CONFIG,\n",
        "\n",
        "        'variations_generated': {\n",
        "            'total_variations': len(ALL_VARIATIONS),\n",
        "            'themed_sets': len(THEMED_VARIATION_SETS),\n",
        "            'high_quality_count': len(HIGH_QUALITY_PROMPTS),\n",
        "            'approval_rate': len(HIGH_QUALITY_PROMPTS) / len(ALL_VARIATIONS) if ALL_VARIATIONS else 0\n",
        "        },\n",
        "\n",
        "        'quality_metrics': {\n",
        "            'average_quality_score': VALIDATION_METRICS.get('average_quality', 0),\n",
        "            'average_tokens': VALIDATION_METRICS.get('average_tokens', 0),\n",
        "            'optimization_success_rate': VALIDATION_METRICS.get('optimization_success_rate', 0),\n",
        "            'commercial_suitability_rate': VALIDATION_METRICS.get('commercial_suitability_rate', 0)\n",
        "        },\n",
        "\n",
        "        'final_dataset': {\n",
        "            'approved_prompts': FINAL_DATASET['metadata']['total_prompts'],\n",
        "            'categories_distribution': FINAL_DATASET['statistics']['categories'],\n",
        "            'ready_for_generation': True\n",
        "        },\n",
        "\n",
        "        'batch_configuration': {\n",
        "            'batch_size': BATCH_CONFIG['batch_size'],\n",
        "            'total_batches': BATCH_CONFIG['num_batches'],\n",
        "            'generation_settings': BATCH_CONFIG['generation_settings'],\n",
        "            'estimated_time_per_batch': f\"{BATCH_CONFIG['generation_settings']['num_inference_steps'] * 2}s\"\n",
        "        },\n",
        "\n",
        "        'files_created': SAVED_PATHS\n",
        "    }\n",
        "\n",
        "    # Salvar relat√≥rio\n",
        "    report_path = \"/content/valentina_dataset_v4/metadata/phase4_report.json\"\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(report, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"üìÑ Relat√≥rio salvo: {report_path}\")\n",
        "\n",
        "    return report\n",
        "\n",
        "def display_generation_readiness() -> None:\n",
        "    \"\"\"\n",
        "    Mostra status de prontid√£o para gera√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüöÄ STATUS DE PRONTID√ÉO PARA GERA√á√ÉO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar pr√©-requisitos\n",
        "    prerequisites = {\n",
        "        'Imagem de controle': CONTROL_CONFIG.get('processing_validated', False),\n",
        "        'Pipeline FLUX': FLUX_PIPELINE is not None,\n",
        "        'ControlNet carregado': FLUX_CONTROLNET is not None,\n",
        "        'Prompts validados': len(HIGH_QUALITY_PROMPTS) > 0,\n",
        "        'Configura√ß√£o batch': BATCH_CONFIG is not None,\n",
        "        'GPU adequada': GPU_CONFIG['vram_adequate']\n",
        "    }\n",
        "\n",
        "    all_ready = all(prerequisites.values())\n",
        "\n",
        "    print(f\"üìã PR√â-REQUISITOS:\")\n",
        "    for requirement, status in prerequisites.items():\n",
        "        emoji = \"‚úÖ\" if status else \"‚ùå\"\n",
        "        print(f\"   {emoji} {requirement}\")\n",
        "\n",
        "    print(f\"\\nüéØ STATUS GERAL: {'üöÄ PRONTO PARA FASE 5' if all_ready else '‚ö†Ô∏è PEND√äNCIAS'}\")\n",
        "\n",
        "    if all_ready:\n",
        "        print(f\"\\nüî• CONFIGURA√á√ÉO FINAL PARA GERA√á√ÉO:\")\n",
        "        print(f\"   üéÆ ControlNet: {SELECTED_CONTROLNET['name']}\")\n",
        "        print(f\"   üñºÔ∏è Modo controle: {BEST_CONTROL_MODE} ({PROCESSING_INFO.get('mode_name', 'N/A')})\")\n",
        "        print(f\"   üìù Prompts aprovados: {len(HIGH_QUALITY_PROMPTS)}\")\n",
        "        print(f\"   üì¶ Batches: {BATCH_CONFIG['num_batches']}\")\n",
        "        print(f\"   ‚öôÔ∏è Steps: {BATCH_CONFIG['generation_settings']['num_inference_steps']}\")\n",
        "        print(f\"   üìê Resolu√ß√£o: {BATCH_CONFIG['generation_settings']['width']}x{BATCH_CONFIG['generation_settings']['height']}\")\n",
        "        print(f\"   üñ•Ô∏è GPU: {GPU_CONFIG['name']} ({GPU_CONFIG['tier'].upper()})\")\n",
        "    else:\n",
        "        missing = [req for req, status in prerequisites.items() if not status]\n",
        "        print(f\"\\n‚ùå PEND√äNCIAS: {', '.join(missing)}\")\n",
        "\n",
        "# Executar preview e relat√≥rio final\n",
        "print(\"üöÄ CRIANDO PREVIEW E RELAT√ìRIO FINAL DA FASE 4...\")\n",
        "\n",
        "# Criar preview dos prompts\n",
        "create_prompts_preview()\n",
        "\n",
        "# Gerar relat√≥rio completo\n",
        "PHASE4_REPORT = generate_phase4_report()\n",
        "\n",
        "# Mostrar status de prontid√£o\n",
        "display_generation_readiness()\n",
        "\n",
        "# =============================================================================\n",
        "# üìä RESUMO FINAL DA FASE 4\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä RESUMO DA FASE 4: SISTEMA DE PROMPTS COMERCIAIS OTIMIZADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üìù TEMPLATES E SISTEMA:\")\n",
        "print(f\"   ‚Ä¢ {sum(len(v) for v in COMMERCIAL_TEMPLATES.values())} templates comerciais em {len(COMMERCIAL_TEMPLATES)} categorias\")\n",
        "print(f\"   ‚Ä¢ {sum(len(v) for v in QUALITY_ENHANCERS.values())} quality enhancers para FLUX\")\n",
        "print(f\"   ‚Ä¢ Sistema dual encoder (CLIP + T5) configurado\")\n",
        "print(f\"   ‚Ä¢ Caracter√≠sticas da Valentina: {len(VALENTINA_CORE)} core + {len(VALENTINA_VARIABLES)} vari√°veis\")\n",
        "\n",
        "print(f\"\\nüé≠ VARIA√á√ïES GERADAS:\")\n",
        "print(f\"   ‚Ä¢ {len(ALL_VARIATIONS)} varia√ß√µes totais\")\n",
        "print(f\"   ‚Ä¢ {len(HIGH_QUALITY_PROMPTS)} aprovadas (qualidade ‚â• 0.7)\")\n",
        "print(f\"   ‚Ä¢ {len(THEMED_VARIATION_SETS)} sets tem√°ticos\")\n",
        "print(f\"   ‚Ä¢ Taxa de aprova√ß√£o: {len(HIGH_QUALITY_PROMPTS)/len(ALL_VARIATIONS):.1%}\")\n",
        "\n",
        "print(f\"\\nüìä M√âTRICAS DE QUALIDADE:\")\n",
        "print(f\"   ‚Ä¢ Qualidade m√©dia: {VALIDATION_METRICS.get('average_quality', 0):.2f}/1.0\")\n",
        "print(f\"   ‚Ä¢ Tokens m√©dios: {VALIDATION_METRICS.get('average_tokens', 0):.1f}/77\")\n",
        "print(f\"   ‚Ä¢ Taxa de otimiza√ß√£o: {VALIDATION_METRICS.get('optimization_success_rate', 0):.1%}\")\n",
        "print(f\"   ‚Ä¢ Conformidade comercial: {VALIDATION_METRICS.get('commercial_suitability_rate', 0):.1%}\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è CONFIGURA√á√ÉO DE BATCH:\")\n",
        "print(f\"   ‚Ä¢ Batch size: {BATCH_CONFIG['batch_size']}\")\n",
        "print(f\"   ‚Ä¢ Total batches: {BATCH_CONFIG['num_batches']}\")\n",
        "print(f\"   ‚Ä¢ Resolu√ß√£o: {BATCH_CONFIG['generation_settings']['width']}x{BATCH_CONFIG['generation_settings']['height']}\")\n",
        "print(f\"   ‚Ä¢ Steps: {BATCH_CONFIG['generation_settings']['num_inference_steps']}\")\n",
        "\n",
        "# Configura√ß√£o final para FASE 5\n",
        "PROMPTS_CONFIG = {\n",
        "    'dataset': FINAL_DATASET,\n",
        "    'high_quality_prompts': HIGH_QUALITY_PROMPTS,\n",
        "    'batch_config': BATCH_CONFIG,\n",
        "    'themed_sets': THEMED_VARIATION_SETS,\n",
        "    'negative_prompt': NEGATIVE_PROMPT_COMMERCIAL,\n",
        "    'total_approved': len(HIGH_QUALITY_PROMPTS),\n",
        "    'ready_for_generation': len(HIGH_QUALITY_PROMPTS) > 0\n",
        "}\n",
        "\n",
        "if PROMPTS_CONFIG['ready_for_generation']:\n",
        "    print(f\"\\nüöÄ PRONTO PARA FASE 5: GERA√á√ÉO AUTOM√ÅTICA EM LOTE\")\n",
        "    print(f\"üíé Sistema completo configurado para produ√ß√£o comercial\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è PROBLEMAS DETECTADOS - Revisar fases anteriores\")\n",
        "\n",
        "LOGGER.info(\"FASE 4 conclu√≠da: Sistema de prompts comerciais otimizados\")\n",
        "LOGGER.info(f\"Prompts aprovados: {len(HIGH_QUALITY_PROMPTS)}\")\n",
        "LOGGER.info(f\"Qualidade m√©dia: {VALIDATION_METRICS.get('average_quality', 0):.2f}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"‚úÖ C√âLULA 6 CONCLU√çDA: Preview e resumo da FASE 4\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "cUQR5mDYA88_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 1: FASE 5.1 - Sistema de Valida√ß√£o Facial Avan√ßada =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üì± C√âLULA 1: Sistema de Valida√ß√£o Facial Avan√ßada\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import time\n",
        "from datetime import datetime\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import queue\n",
        "\n",
        "def setup_face_validation_system() -> Dict:\n",
        "    \"\"\"\n",
        "    Configura sistema avan√ßado de valida√ß√£o facial para qualidade comercial\n",
        "\n",
        "    Returns:\n",
        "        Dict com componentes de valida√ß√£o configurados\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüîç CONFIGURANDO SISTEMA DE VALIDA√á√ÉO FACIAL\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    validation_system = {\n",
        "        'face_detector': None,\n",
        "        'face_embedder': None,\n",
        "        'quality_thresholds': {},\n",
        "        'commercial_criteria': {},\n",
        "        'available_methods': []\n",
        "    }\n",
        "\n",
        "    # Tentar configurar InsightFace (m√©todo preferido)\n",
        "    try:\n",
        "        import insightface\n",
        "        from insightface.app import FaceAnalysis\n",
        "\n",
        "        print(\"‚è≥ Configurando InsightFace para an√°lise facial...\")\n",
        "\n",
        "        face_app = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "        face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "        validation_system['face_detector'] = face_app\n",
        "        validation_system['available_methods'].append('insightface')\n",
        "\n",
        "        print(\"‚úÖ InsightFace configurado com sucesso\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è InsightFace n√£o dispon√≠vel - usando m√©todos alternativos\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro configurando InsightFace: {e}\")\n",
        "\n",
        "    # Configurar OpenCV como fallback\n",
        "    try:\n",
        "        print(\"‚è≥ Configurando OpenCV para detec√ß√£o facial...\")\n",
        "\n",
        "        # Usar Haar Cascade como backup\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        validation_system['opencv_detector'] = face_cascade\n",
        "        validation_system['available_methods'].append('opencv')\n",
        "\n",
        "        print(\"‚úÖ OpenCV configurado como backup\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro configurando OpenCV: {e}\")\n",
        "\n",
        "    # Definir crit√©rios de qualidade comercial\n",
        "    validation_system['quality_thresholds'] = {\n",
        "        'min_face_size': 128,           # Tamanho m√≠nimo da face em pixels\n",
        "        'max_face_embed_distance': 0.3, # FED m√°ximo para consist√™ncia\n",
        "        'min_image_quality': 0.7,       # Score m√≠nimo de qualidade\n",
        "        'min_resolution': 512,          # Resolu√ß√£o m√≠nima\n",
        "        'max_blur_variance': 100,       # Limite de desfoque\n",
        "        'min_face_confidence': 0.8      # Confian√ßa m√≠nima de detec√ß√£o\n",
        "    }\n",
        "\n",
        "    validation_system['commercial_criteria'] = {\n",
        "        'face_consistency': 'required',  # Obrigat√≥rio para comercial\n",
        "        'visual_quality': 'high',        # Alta qualidade visual\n",
        "        'resolution_check': 'required',  # Verifica√ß√£o de resolu√ß√£o\n",
        "        'artifact_detection': 'enabled', # Detec√ß√£o de artefatos\n",
        "        'aesthetic_score': 'optional'    # Score est√©tico (opcional)\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüìä SISTEMA CONFIGURADO:\")\n",
        "    print(f\"   üîç M√©todos dispon√≠veis: {validation_system['available_methods']}\")\n",
        "    print(f\"   üéØ Crit√©rios comerciais: {len(validation_system['commercial_criteria'])} verifica√ß√µes\")\n",
        "    print(f\"   üìè Thresholds: {len(validation_system['quality_thresholds'])} m√©tricas\")\n",
        "\n",
        "    return validation_system\n",
        "\n",
        "def calculate_face_embed_distance(image1: Image.Image, image2: Image.Image, validation_system: Dict) -> float:\n",
        "    \"\"\"\n",
        "    Calcula Face Embed Distance entre duas imagens\n",
        "\n",
        "    Args:\n",
        "        image1: Primeira imagem\n",
        "        image2: Segunda imagem\n",
        "        validation_system: Sistema de valida√ß√£o configurado\n",
        "\n",
        "    Returns:\n",
        "        Dist√¢ncia entre embeddings faciais (0.0 = id√™nticas, 1.0 = totalmente diferentes)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        if 'insightface' in validation_system['available_methods']:\n",
        "            return calculate_fed_insightface(image1, image2, validation_system['face_detector'])\n",
        "        else:\n",
        "            return calculate_fed_opencv(image1, image2, validation_system['opencv_detector'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro no c√°lculo FED: {e}\")\n",
        "        return 1.0  # Assumir m√°xima dist√¢ncia em caso de erro\n",
        "\n",
        "def calculate_fed_insightface(image1: Image.Image, image2: Image.Image, face_app) -> float:\n",
        "    \"\"\"\n",
        "    Calcula FED usando InsightFace (m√©todo preferido)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Converter para arrays numpy\n",
        "        img1_array = np.array(image1.convert('RGB'))\n",
        "        img2_array = np.array(image2.convert('RGB'))\n",
        "\n",
        "        # Detectar faces e extrair embeddings\n",
        "        faces1 = face_app.get(img1_array)\n",
        "        faces2 = face_app.get(img2_array)\n",
        "\n",
        "        if not faces1 or not faces2:\n",
        "            return 1.0  # Nenhuma face detectada\n",
        "\n",
        "        # Usar a maior face detectada\n",
        "        face1 = max(faces1, key=lambda x: x.bbox[2] * x.bbox[3])\n",
        "        face2 = max(faces2, key=lambda x: x.bbox[2] * x.bbox[3])\n",
        "\n",
        "        # Calcular dist√¢ncia cosine entre embeddings\n",
        "        embedding1 = face1.normed_embedding\n",
        "        embedding2 = face2.normed_embedding\n",
        "\n",
        "        # Dist√¢ncia cosine (0 = id√™nticas, 2 = opostas)\n",
        "        cosine_distance = np.linalg.norm(embedding1 - embedding2)\n",
        "\n",
        "        # Normalizar para 0-1\n",
        "        normalized_distance = min(cosine_distance / 2.0, 1.0)\n",
        "\n",
        "        return normalized_distance\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro no InsightFace FED: {e}\")\n",
        "        return 1.0\n",
        "\n",
        "def calculate_fed_opencv(image1: Image.Image, image2: Image.Image, face_cascade) -> float:\n",
        "    \"\"\"\n",
        "    Calcula FED aproximado usando OpenCV (fallback)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Converter para grayscale\n",
        "        gray1 = cv2.cvtColor(np.array(image1), cv2.COLOR_RGB2GRAY)\n",
        "        gray2 = cv2.cvtColor(np.array(image2), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Detectar faces\n",
        "        faces1 = face_cascade.detectMultiScale(gray1, 1.1, 5)\n",
        "        faces2 = face_cascade.detectMultiScale(gray2, 1.1, 5)\n",
        "\n",
        "        if len(faces1) == 0 or len(faces2) == 0:\n",
        "            return 1.0\n",
        "\n",
        "        # Extrair maior face de cada imagem\n",
        "        face1 = max(faces1, key=lambda x: x[2] * x[3])\n",
        "        face2 = max(faces2, key=lambda x: x[2] * x[3])\n",
        "\n",
        "        # Extrair ROIs das faces\n",
        "        x1, y1, w1, h1 = face1\n",
        "        x2, y2, w2, h2 = face2\n",
        "\n",
        "        face_roi1 = gray1[y1:y1+h1, x1:x1+w1]\n",
        "        face_roi2 = gray2[y2:y2+h2, x2:x2+w2]\n",
        "\n",
        "        # Redimensionar para mesmo tamanho\n",
        "        size = (128, 128)\n",
        "        face_roi1 = cv2.resize(face_roi1, size)\n",
        "        face_roi2 = cv2.resize(face_roi2, size)\n",
        "\n",
        "        # Calcular similaridade usando correlation\n",
        "        correlation = cv2.matchTemplate(face_roi1, face_roi2, cv2.TM_CCOEFF_NORMED)[0][0]\n",
        "\n",
        "        # Converter para dist√¢ncia (0 = id√™nticas, 1 = diferentes)\n",
        "        distance = 1.0 - max(correlation, 0)\n",
        "\n",
        "        return distance\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro no OpenCV FED: {e}\")\n",
        "        return 1.0\n",
        "\n",
        "def validate_image_quality(image: Image.Image, validation_system: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Valida qualidade comercial de uma imagem gerada\n",
        "\n",
        "    Args:\n",
        "        image: Imagem para validar\n",
        "        validation_system: Sistema de valida√ß√£o\n",
        "\n",
        "    Returns:\n",
        "        Dict com resultado da valida√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    validation_result = {\n",
        "        'approved': False,\n",
        "        'quality_score': 0.0,\n",
        "        'face_detected': False,\n",
        "        'face_size': 0,\n",
        "        'face_confidence': 0.0,\n",
        "        'resolution_check': False,\n",
        "        'blur_check': False,\n",
        "        'artifact_check': False,\n",
        "        'commercial_suitable': False,\n",
        "        'issues': [],\n",
        "        'metrics': {}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Verificar resolu√ß√£o\n",
        "        width, height = image.size\n",
        "        min_res = validation_system['quality_thresholds']['min_resolution']\n",
        "        validation_result['resolution_check'] = min(width, height) >= min_res\n",
        "        validation_result['metrics']['resolution'] = (width, height)\n",
        "\n",
        "        if not validation_result['resolution_check']:\n",
        "            validation_result['issues'].append(f\"Resolu√ß√£o baixa: {width}x{height} < {min_res}\")\n",
        "\n",
        "        # Converter para array para an√°lises\n",
        "        image_array = np.array(image.convert('RGB'))\n",
        "        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Verificar desfoque\n",
        "        blur_variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        max_blur = validation_system['quality_thresholds']['max_blur_variance']\n",
        "        validation_result['blur_check'] = blur_variance > max_blur\n",
        "        validation_result['metrics']['blur_variance'] = blur_variance\n",
        "\n",
        "        if not validation_result['blur_check']:\n",
        "            validation_result['issues'].append(f\"Imagem desfocada: {blur_variance:.1f} < {max_blur}\")\n",
        "\n",
        "        # Detectar face e validar tamanho\n",
        "        if 'insightface' in validation_system['available_methods']:\n",
        "            faces = validation_system['face_detector'].get(image_array)\n",
        "\n",
        "            if faces:\n",
        "                # Usar maior face\n",
        "                face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])\n",
        "                face_width = face.bbox[2] - face.bbox[0]\n",
        "                face_height = face.bbox[3] - face.bbox[1]\n",
        "                face_size = min(face_width, face_height)\n",
        "\n",
        "                validation_result['face_detected'] = True\n",
        "                validation_result['face_size'] = face_size\n",
        "                validation_result['face_confidence'] = face.det_score\n",
        "                validation_result['metrics']['face_bbox'] = face.bbox\n",
        "\n",
        "                min_face_size = validation_system['quality_thresholds']['min_face_size']\n",
        "                min_confidence = validation_system['quality_thresholds']['min_face_confidence']\n",
        "\n",
        "                if face_size < min_face_size:\n",
        "                    validation_result['issues'].append(f\"Face muito pequena: {face_size} < {min_face_size}\")\n",
        "\n",
        "                if face.det_score < min_confidence:\n",
        "                    validation_result['issues'].append(f\"Baixa confian√ßa: {face.det_score:.2f} < {min_confidence}\")\n",
        "            else:\n",
        "                validation_result['issues'].append(\"Nenhuma face detectada\")\n",
        "\n",
        "        # Verificar artefatos visuais\n",
        "        artifact_score = detect_visual_artifacts(image_array)\n",
        "        validation_result['artifact_check'] = artifact_score < 0.3\n",
        "        validation_result['metrics']['artifact_score'] = artifact_score\n",
        "\n",
        "        if not validation_result['artifact_check']:\n",
        "            validation_result['issues'].append(f\"Artefatos detectados: {artifact_score:.2f}\")\n",
        "\n",
        "        # Calcular score geral de qualidade\n",
        "        quality_components = [\n",
        "            validation_result['resolution_check'],\n",
        "            validation_result['blur_check'],\n",
        "            validation_result['face_detected'],\n",
        "            validation_result['artifact_check']\n",
        "        ]\n",
        "\n",
        "        validation_result['quality_score'] = sum(quality_components) / len(quality_components)\n",
        "\n",
        "        # Determinar adequa√ß√£o comercial\n",
        "        min_quality = validation_system['quality_thresholds']['min_image_quality']\n",
        "        validation_result['commercial_suitable'] = (\n",
        "            validation_result['quality_score'] >= min_quality and\n",
        "            len(validation_result['issues']) == 0\n",
        "        )\n",
        "\n",
        "        validation_result['approved'] = validation_result['commercial_suitable']\n",
        "\n",
        "    except Exception as e:\n",
        "        validation_result['issues'].append(f\"Erro na valida√ß√£o: {str(e)}\")\n",
        "        print(f\"‚ùå Erro na valida√ß√£o: {e}\")\n",
        "\n",
        "    return validation_result\n",
        "\n",
        "def detect_visual_artifacts(image_array: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Detecta artefatos visuais na imagem\n",
        "\n",
        "    Args:\n",
        "        image_array: Array numpy da imagem\n",
        "\n",
        "    Returns:\n",
        "        Score de artefatos (0.0 = sem artefatos, 1.0 = muitos artefatos)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Detectar bordas para identificar artefatos\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])\n",
        "\n",
        "        # Detectar ru√≠do usando gradiente\n",
        "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "        noise_level = np.std(magnitude)\n",
        "\n",
        "        # Detectar padr√µes repetitivos (poss√≠veis artefatos)\n",
        "        fourier = np.fft.fft2(gray)\n",
        "        fourier_shift = np.fft.fftshift(fourier)\n",
        "        magnitude_spectrum = np.log(np.abs(fourier_shift) + 1)\n",
        "        pattern_score = np.std(magnitude_spectrum)\n",
        "\n",
        "        # Score combinado (normalizado)\n",
        "        artifact_score = min((edge_density * 2 + noise_level / 100 + pattern_score / 1000) / 3, 1.0)\n",
        "\n",
        "        return artifact_score\n",
        "\n",
        "    except Exception:\n",
        "        return 0.5  # Score neutro em caso de erro\n",
        "\n",
        "# Executar configura√ß√£o do sistema de valida√ß√£o\n",
        "print(\"üöÄ CONFIGURANDO SISTEMA DE VALIDA√á√ÉO FACIAL...\")\n",
        "\n",
        "VALIDATION_SYSTEM = setup_face_validation_system()\n",
        "\n",
        "# Teste do sistema com a imagem de refer√™ncia se dispon√≠vel\n",
        "if 'REFERENCE_IMAGE_PATH' in globals() and REFERENCE_IMAGE_PATH:\n",
        "    print(f\"\\nüß™ TESTANDO SISTEMA COM IMAGEM DE REFER√äNCIA...\")\n",
        "    try:\n",
        "        reference_image = Image.open(REFERENCE_IMAGE_PATH)\n",
        "        test_validation = validate_image_quality(reference_image, VALIDATION_SYSTEM)\n",
        "\n",
        "        print(f\"‚úÖ TESTE CONCLU√çDO:\")\n",
        "        print(f\"   ‚≠ê Qualidade: {test_validation['quality_score']:.2f}/1.0\")\n",
        "        print(f\"   üë§ Face detectada: {'‚úÖ' if test_validation['face_detected'] else '‚ùå'}\")\n",
        "        print(f\"   üìê Resolu√ß√£o: {'‚úÖ' if test_validation['resolution_check'] else '‚ùå'}\")\n",
        "        print(f\"   üîç Sem artefatos: {'‚úÖ' if test_validation['artifact_check'] else '‚ùå'}\")\n",
        "        print(f\"   üí∞ Comercial: {'‚úÖ' if test_validation['commercial_suitable'] else '‚ùå'}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro no teste: {e}\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 1 CARREGADA: Sistema de valida√ß√£o facial configurado\")"
      ],
      "metadata": {
        "id": "dkxTQSmhSHQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 2: FASE 5.2 - Pipeline de Gera√ß√£o Otimizado para A100 =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 2: Pipeline de Gera√ß√£o Otimizado para A100\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import gc\n",
        "import psutil\n",
        "from contextlib import contextmanager\n",
        "import multiprocessing as mp\n",
        "from collections import defaultdict\n",
        "\n",
        "class A100GenerationPipeline:\n",
        "    \"\"\"\n",
        "    Pipeline otimizado para gera√ß√£o comercial na A100\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, flux_pipeline, controlnet, validation_system, config):\n",
        "        self.pipeline = flux_pipeline\n",
        "        self.controlnet = controlnet\n",
        "        self.validation_system = validation_system\n",
        "        self.config = config\n",
        "\n",
        "        # Estat√≠sticas de gera√ß√£o\n",
        "        self.stats = {\n",
        "            'total_generated': 0,\n",
        "            'total_approved': 0,\n",
        "            'total_rejected': 0,\n",
        "            'generation_times': [],\n",
        "            'validation_times': [],\n",
        "            'memory_usage': [],\n",
        "            'quality_scores': []\n",
        "        }\n",
        "\n",
        "        # Cache de refer√™ncia para FED\n",
        "        self.reference_cache = None\n",
        "\n",
        "    def setup_reference_cache(self, reference_image_path: str):\n",
        "        \"\"\"\n",
        "        Configura cache da imagem de refer√™ncia para c√°lculos FED\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\nüîó CONFIGURANDO CACHE DE REFER√äNCIA\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            reference_image = Image.open(reference_image_path)\n",
        "\n",
        "            # Pre-calcular embeddings da refer√™ncia se InsightFace dispon√≠vel\n",
        "            if 'insightface' in self.validation_system['available_methods']:\n",
        "                img_array = np.array(reference_image.convert('RGB'))\n",
        "                faces = self.validation_system['face_detector'].get(img_array)\n",
        "\n",
        "                if faces:\n",
        "                    face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])\n",
        "                    self.reference_cache = {\n",
        "                        'image': reference_image,\n",
        "                        'embedding': face.normed_embedding,\n",
        "                        'bbox': face.bbox\n",
        "                    }\n",
        "                    print(\"‚úÖ Cache de refer√™ncia criado com embedding facial\")\n",
        "                else:\n",
        "                    self.reference_cache = {'image': reference_image}\n",
        "                    print(\"‚ö†Ô∏è Nenhuma face detectada na refer√™ncia - cache b√°sico\")\n",
        "            else:\n",
        "                self.reference_cache = {'image': reference_image}\n",
        "                print(\"‚úÖ Cache de refer√™ncia b√°sico criado\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro configurando cache: {e}\")\n",
        "\n",
        "    @contextmanager\n",
        "    def memory_management(self):\n",
        "        \"\"\"\n",
        "        Context manager para gest√£o de mem√≥ria durante gera√ß√£o\n",
        "        \"\"\"\n",
        "\n",
        "        # Limpeza antes da gera√ß√£o\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        initial_memory = torch.cuda.memory_allocated()\n",
        "\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            # Limpeza ap√≥s gera√ß√£o\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            final_memory = torch.cuda.memory_allocated()\n",
        "            memory_used = (final_memory - initial_memory) / 1024**3  # GB\n",
        "            self.stats['memory_usage'].append(memory_used)\n",
        "\n",
        "    def generate_single_image(\n",
        "        self,\n",
        "        prompt_data: Dict,\n",
        "        control_image: Image.Image,\n",
        "        generation_config: Dict\n",
        "    ) -> Tuple[Optional[Image.Image], Dict]:\n",
        "        \"\"\"\n",
        "        Gera uma √∫nica imagem com valida√ß√£o\n",
        "\n",
        "        Args:\n",
        "            prompt_data: Dados do prompt\n",
        "            control_image: Imagem de controle\n",
        "            generation_config: Configura√ß√µes de gera√ß√£o\n",
        "\n",
        "        Returns:\n",
        "            Tupla (imagem_gerada, metadados)\n",
        "        \"\"\"\n",
        "\n",
        "        generation_metadata = {\n",
        "            'prompt_id': prompt_data.get('id', 'unknown'),\n",
        "            'prompt': prompt_data['prompt'],\n",
        "            'negative_prompt': prompt_data['negative_prompt'],\n",
        "            'generation_time': 0,\n",
        "            'validation_time': 0,\n",
        "            'validation_result': None,\n",
        "            'fed_score': None,\n",
        "            'approved': False,\n",
        "            'generation_seed': None,\n",
        "            'technical_params': generation_config.copy()\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with self.memory_management():\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Configurar seed aleat√≥rio\n",
        "                generator = torch.Generator(device=self.pipeline.device)\n",
        "                seed = torch.randint(0, 2**32-1, (1,)).item()\n",
        "                generator.manual_seed(seed)\n",
        "                generation_metadata['generation_seed'] = seed\n",
        "\n",
        "                # Gera√ß√£o com FLUX\n",
        "                print(f\"‚è≥ Gerando: {prompt_data.get('id', 'unknown')}\")\n",
        "\n",
        "                with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
        "                    result = self.pipeline(\n",
        "                        prompt=prompt_data['prompt'],\n",
        "                        negative_prompt=prompt_data['negative_prompt'],\n",
        "                        control_image=control_image,\n",
        "                        control_mode=BEST_CONTROL_MODE,\n",
        "                        generator=generator,\n",
        "                        **generation_config\n",
        "                    )\n",
        "\n",
        "                generated_image = result.images[0]\n",
        "                generation_time = time.time() - start_time\n",
        "                generation_metadata['generation_time'] = generation_time\n",
        "                self.stats['generation_times'].append(generation_time)\n",
        "\n",
        "                print(f\"‚úÖ Gera√ß√£o conclu√≠da ({generation_time:.1f}s)\")\n",
        "\n",
        "                # Valida√ß√£o da imagem\n",
        "                validation_start = time.time()\n",
        "                validation_result = validate_image_quality(generated_image, self.validation_system)\n",
        "\n",
        "                # Calcular FED se temos refer√™ncia\n",
        "                if self.reference_cache and validation_result['face_detected']:\n",
        "                    if 'embedding' in self.reference_cache:\n",
        "                        # Usar embedding cached\n",
        "                        fed_score = self.calculate_fed_cached(generated_image)\n",
        "                    else:\n",
        "                        # Calcular FED tradicional\n",
        "                        fed_score = calculate_face_embed_distance(\n",
        "                            generated_image,\n",
        "                            self.reference_cache['image'],\n",
        "                            self.validation_system\n",
        "                        )\n",
        "\n",
        "                    validation_result['fed_score'] = fed_score\n",
        "                    generation_metadata['fed_score'] = fed_score\n",
        "\n",
        "                    # Verificar threshold FED\n",
        "                    max_fed = self.validation_system['quality_thresholds']['max_face_embed_distance']\n",
        "                    if fed_score > max_fed:\n",
        "                        validation_result['issues'].append(f\"FED alto: {fed_score:.3f} > {max_fed}\")\n",
        "                        validation_result['approved'] = False\n",
        "\n",
        "                validation_time = time.time() - validation_start\n",
        "                generation_metadata['validation_time'] = validation_time\n",
        "                generation_metadata['validation_result'] = validation_result\n",
        "                generation_metadata['approved'] = validation_result['approved']\n",
        "\n",
        "                self.stats['validation_times'].append(validation_time)\n",
        "                self.stats['quality_scores'].append(validation_result['quality_score'])\n",
        "\n",
        "                # Estat√≠sticas\n",
        "                self.stats['total_generated'] += 1\n",
        "                if validation_result['approved']:\n",
        "                    self.stats['total_approved'] += 1\n",
        "                    print(f\"‚úÖ APROVADA - Qualidade: {validation_result['quality_score']:.2f}\")\n",
        "                else:\n",
        "                    self.stats['total_rejected'] += 1\n",
        "                    print(f\"‚ùå REJEITADA - Problemas: {len(validation_result['issues'])}\")\n",
        "                    for issue in validation_result['issues']:\n",
        "                        print(f\"     ‚Ä¢ {issue}\")\n",
        "\n",
        "                return generated_image, generation_metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro na gera√ß√£o: {e}\")\n",
        "            generation_metadata['error'] = str(e)\n",
        "            return None, generation_metadata\n",
        "\n",
        "    def calculate_fed_cached(self, generated_image: Image.Image) -> float:\n",
        "        \"\"\"\n",
        "        Calcula FED usando embedding cached da refer√™ncia\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            img_array = np.array(generated_image.convert('RGB'))\n",
        "            faces = self.validation_system['face_detector'].get(img_array)\n",
        "\n",
        "            if not faces:\n",
        "                return 1.0\n",
        "\n",
        "            face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])\n",
        "            generated_embedding = face.normed_embedding\n",
        "            reference_embedding = self.reference_cache['embedding']\n",
        "\n",
        "            # Dist√¢ncia cosine\n",
        "            cosine_distance = np.linalg.norm(generated_embedding - reference_embedding)\n",
        "            normalized_distance = min(cosine_distance / 2.0, 1.0)\n",
        "\n",
        "            return normalized_distance\n",
        "\n",
        "        except Exception:\n",
        "            return 1.0\n",
        "\n",
        "    def generate_batch(\n",
        "        self,\n",
        "        prompt_batch: List[Dict],\n",
        "        control_image: Image.Image,\n",
        "        generation_config: Dict\n",
        "    ) -> List[Tuple[Optional[Image.Image], Dict]]:\n",
        "        \"\"\"\n",
        "        Gera lote de imagens (A100 suporta batch maior)\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nüéØ GERANDO BATCH DE {len(prompt_batch)} IMAGENS\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for i, prompt_data in enumerate(prompt_batch):\n",
        "            print(f\"\\nüì∑ Imagem {i+1}/{len(prompt_batch)}\")\n",
        "\n",
        "            image, metadata = self.generate_single_image(\n",
        "                prompt_data,\n",
        "                control_image,\n",
        "                generation_config\n",
        "            )\n",
        "\n",
        "            results.append((image, metadata))\n",
        "\n",
        "            # Progress update\n",
        "            progress = (i + 1) / len(prompt_batch) * 100\n",
        "            print(f\"üìä Progresso do batch: {progress:.1f}%\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def get_generation_stats(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Retorna estat√≠sticas detalhadas da gera√ß√£o\n",
        "        \"\"\"\n",
        "\n",
        "        if self.stats['total_generated'] == 0:\n",
        "            return {'message': 'Nenhuma gera√ß√£o realizada ainda'}\n",
        "\n",
        "        approval_rate = self.stats['total_approved'] / self.stats['total_generated']\n",
        "        avg_generation_time = np.mean(self.stats['generation_times'])\n",
        "        avg_validation_time = np.mean(self.stats['validation_times'])\n",
        "        avg_quality = np.mean(self.stats['quality_scores'])\n",
        "        avg_memory = np.mean(self.stats['memory_usage']) if self.stats['memory_usage'] else 0\n",
        "\n",
        "        return {\n",
        "            'total_generated': self.stats['total_generated'],\n",
        "            'total_approved': self.stats['total_approved'],\n",
        "            'total_rejected': self.stats['total_rejected'],\n",
        "            'approval_rate': approval_rate,\n",
        "            'avg_generation_time': avg_generation_time,\n",
        "            'avg_validation_time': avg_validation_time,\n",
        "            'avg_quality_score': avg_quality,\n",
        "            'avg_memory_usage_gb': avg_memory,\n",
        "            'throughput_imgs_per_min': 60 / avg_generation_time if avg_generation_time > 0 else 0\n",
        "        }\n",
        "\n",
        "def create_optimized_generation_config() -> Dict:\n",
        "    \"\"\"\n",
        "    Cria configura√ß√£o otimizada para A100\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n‚öôÔ∏è CRIANDO CONFIGURA√á√ÉO OTIMIZADA PARA A100\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Configura√ß√£o baseada nas capacidades da A100\n",
        "    optimized_config = {\n",
        "        'num_inference_steps': 28,           # Qualidade comercial\n",
        "        'guidance_scale': 3.5,               # Balanceado para FLUX\n",
        "        'controlnet_conditioning_scale': 0.7, # Preservar identidade\n",
        "        'control_guidance_start': 0.0,\n",
        "        'control_guidance_end': 0.8,\n",
        "        'width': 1024,                       # Resolu√ß√£o comercial\n",
        "        'height': 1024,\n",
        "        'output_type': 'pil'\n",
        "    }\n",
        "\n",
        "    print(f\"üîß CONFIGURA√á√ÉO A100 OTIMIZADA:\")\n",
        "    for param, value in optimized_config.items():\n",
        "        print(f\"   ‚Ä¢ {param}: {value}\")\n",
        "\n",
        "    return optimized_config\n",
        "\n",
        "# Inicializar pipeline de gera√ß√£o\n",
        "print(\"üöÄ INICIALIZANDO PIPELINE DE GERA√á√ÉO A100...\")\n",
        "\n",
        "GENERATION_PIPELINE = A100GenerationPipeline(\n",
        "    flux_pipeline=FLUX_PIPELINE,\n",
        "    controlnet=FLUX_CONTROLNET,\n",
        "    validation_system=VALIDATION_SYSTEM,\n",
        "    config=GPU_CONFIG\n",
        ")\n",
        "\n",
        "# Configurar cache de refer√™ncia\n",
        "if 'REFERENCE_IMAGE_PATH' in globals() and REFERENCE_IMAGE_PATH:\n",
        "    GENERATION_PIPELINE.setup_reference_cache(REFERENCE_IMAGE_PATH)\n",
        "\n",
        "# Configura√ß√£o otimizada\n",
        "OPTIMIZED_CONFIG = create_optimized_generation_config()\n",
        "\n",
        "print(\"‚úÖ C√âLULA 2 CARREGADA: Pipeline de gera√ß√£o A100 configurado\")"
      ],
      "metadata": {
        "id": "sx0mkt7hSBbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 3: FASE 5.3 - Sistema de Gera√ß√£o Autom√°tica em Lote =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 3: Sistema de Gera√ß√£o Autom√°tica em Lote\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from typing import Iterator\n",
        "import random\n",
        "\n",
        "class BatchGenerationManager:\n",
        "    \"\"\"\n",
        "    Gerenciador de gera√ß√£o autom√°tica em lote com aprova√ß√£o inteligente\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, generation_pipeline, output_dir):\n",
        "        self.pipeline = generation_pipeline\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.approved_dir = self.output_dir / \"approved\"\n",
        "        self.rejected_dir = self.output_dir / \"rejected\"\n",
        "        self.metadata_dir = self.output_dir / \"metadata\"\n",
        "\n",
        "        # Criar diret√≥rios\n",
        "        for dir_path in [self.approved_dir, self.rejected_dir, self.metadata_dir]:\n",
        "            dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Estat√≠sticas do batch\n",
        "        self.batch_stats = {\n",
        "            'session_start': datetime.now().isoformat(),\n",
        "            'batches_completed': 0,\n",
        "            'total_images_generated': 0,\n",
        "            'total_images_approved': 0,\n",
        "            'approval_rate_by_batch': [],\n",
        "            'quality_progression': [],\n",
        "            'errors': []\n",
        "        }\n",
        "\n",
        "    def prepare_batch_prompts(self, high_quality_prompts: List[Dict], batch_size: int) -> Iterator[List[Dict]]:\n",
        "        \"\"\"\n",
        "        Prepara prompts em batches para processamento\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nüì¶ PREPARANDO BATCHES\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Embaralhar para variedade\n",
        "        shuffled_prompts = high_quality_prompts.copy()\n",
        "        random.shuffle(shuffled_prompts)\n",
        "\n",
        "        total_batches = len(shuffled_prompts) // batch_size + (1 if len(shuffled_prompts) % batch_size else 0)\n",
        "\n",
        "        print(f\"üìä Total de prompts: {len(shuffled_prompts)}\")\n",
        "        print(f\"üì¶ Tamanho do batch: {batch_size}\")\n",
        "        print(f\"üîÑ Total de batches: {total_batches}\")\n",
        "\n",
        "        for i in range(0, len(shuffled_prompts), batch_size):\n",
        "            batch = shuffled_prompts[i:i + batch_size]\n",
        "            batch_number = i // batch_size + 1\n",
        "\n",
        "            print(f\"\\nüìã Preparando Batch {batch_number}/{total_batches}\")\n",
        "            print(f\"   üìù Prompts: {len(batch)}\")\n",
        "\n",
        "            yield batch, batch_number, total_batches\n",
        "\n",
        "    def process_single_batch(\n",
        "        self,\n",
        "        prompt_batch: List[Dict],\n",
        "        control_image: Image.Image,\n",
        "        batch_number: int,\n",
        "        total_batches: int\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Processa um √∫nico batch com salvamento autom√°tico\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nüéØ PROCESSANDO BATCH {batch_number}/{total_batches}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        batch_start_time = time.time()\n",
        "        batch_results = {\n",
        "            'batch_number': batch_number,\n",
        "            'total_batches': total_batches,\n",
        "            'images_generated': 0,\n",
        "            'images_approved': 0,\n",
        "            'images_rejected': 0,\n",
        "            'average_quality': 0.0,\n",
        "            'average_fed_score': 0.0,\n",
        "            'processing_time': 0.0,\n",
        "            'errors': [],\n",
        "            'approved_files': [],\n",
        "            'rejected_files': []\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Gerar imagens do batch\n",
        "            generation_results = self.pipeline.generate_batch(\n",
        "                prompt_batch,\n",
        "                control_image,\n",
        "                OPTIMIZED_CONFIG\n",
        "            )\n",
        "\n",
        "            quality_scores = []\n",
        "            fed_scores = []\n",
        "\n",
        "            # Processar resultados\n",
        "            for i, (image, metadata) in enumerate(generation_results):\n",
        "                batch_results['images_generated'] += 1\n",
        "\n",
        "                if image is None:\n",
        "                    batch_results['errors'].append(f\"Falha na gera√ß√£o {i+1}\")\n",
        "                    continue\n",
        "\n",
        "                # Criar nome √∫nico para arquivo\n",
        "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]\n",
        "                prompt_id = metadata.get('prompt_id', f'unknown_{i}')\n",
        "                filename_base = f\"valentina_{prompt_id}_{timestamp}\"\n",
        "\n",
        "                # Salvar baseado na aprova√ß√£o\n",
        "                if metadata['approved']:\n",
        "                    # Salvar imagem aprovada\n",
        "                    image_path = self.approved_dir / f\"{filename_base}.png\"\n",
        "                    metadata_path = self.metadata_dir / f\"{filename_base}.json\"\n",
        "\n",
        "                    image.save(image_path, \"PNG\", optimize=True)\n",
        "\n",
        "                    # Metadados completos\n",
        "                    complete_metadata = {\n",
        "                        'valentina_dataset_v4': True,\n",
        "                        'commercial_approved': True,\n",
        "                        'batch_info': {\n",
        "                            'batch_number': batch_number,\n",
        "                            'total_batches': total_batches,\n",
        "                            'position_in_batch': i + 1\n",
        "                        },\n",
        "                        'generation_metadata': metadata,\n",
        "                        'file_info': {\n",
        "                            'filename': image_path.name,\n",
        "                            'size_bytes': image_path.stat().st_size,\n",
        "                            'resolution': image.size,\n",
        "                            'format': 'PNG'\n",
        "                        },\n",
        "                        'commercial_metadata': {\n",
        "                            'platform_ready': ['TopFans', 'OnlyFans'],\n",
        "                            'quality_grade': 'commercial',\n",
        "                            'usage_rights': 'unrestricted'\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    with open(metadata_path, 'w') as f:\n",
        "                        json.dump(complete_metadata, f, indent=2, default=str)\n",
        "\n",
        "                    batch_results['images_approved'] += 1\n",
        "                    batch_results['approved_files'].append(str(image_path))\n",
        "\n",
        "                    print(f\"‚úÖ APROVADA: {filename_base}\")\n",
        "\n",
        "                else:\n",
        "                    # Salvar imagem rejeitada para an√°lise\n",
        "                    image_path = self.rejected_dir / f\"{filename_base}_REJECTED.png\"\n",
        "                    metadata_path = self.metadata_dir / f\"{filename_base}_REJECTED.json\"\n",
        "\n",
        "                    image.save(image_path, \"PNG\", optimize=True)\n",
        "\n",
        "                    rejection_metadata = {\n",
        "                        'valentina_dataset_v4': True,\n",
        "                        'commercial_approved': False,\n",
        "                        'rejection_info': {\n",
        "                            'batch_number': batch_number,\n",
        "                            'rejection_reasons': metadata['validation_result']['issues'],\n",
        "                            'quality_score': metadata['validation_result']['quality_score']\n",
        "                        },\n",
        "                        'generation_metadata': metadata\n",
        "                    }\n",
        "\n",
        "                    with open(metadata_path, 'w') as f:\n",
        "                        json.dump(rejection_metadata, f, indent=2, default=str)\n",
        "\n",
        "                    batch_results['images_rejected'] += 1\n",
        "                    batch_results['rejected_files'].append(str(image_path))\n",
        "\n",
        "                    print(f\"‚ùå REJEITADA: {filename_base}\")\n",
        "                    for issue in metadata['validation_result']['issues']:\n",
        "                        print(f\"     ‚Ä¢ {issue}\")\n",
        "\n",
        "                # Coletar m√©tricas\n",
        "                if 'validation_result' in metadata:\n",
        "                    quality_scores.append(metadata['validation_result']['quality_score'])\n",
        "\n",
        "                if metadata.get('fed_score') is not None:\n",
        "                    fed_scores.append(metadata['fed_score'])\n",
        "\n",
        "            # Calcular estat√≠sticas do batch\n",
        "            batch_results['average_quality'] = np.mean(quality_scores) if quality_scores else 0.0\n",
        "            batch_results['average_fed_score'] = np.mean(fed_scores) if fed_scores else 0.0\n",
        "            batch_results['processing_time'] = time.time() - batch_start_time\n",
        "\n",
        "            # Atualizar estat√≠sticas globais\n",
        "            self.batch_stats['batches_completed'] += 1\n",
        "            self.batch_stats['total_images_generated'] += batch_results['images_generated']\n",
        "            self.batch_stats['total_images_approved'] += batch_results['images_approved']\n",
        "\n",
        "            approval_rate = batch_results['images_approved'] / batch_results['images_generated'] if batch_results['images_generated'] > 0 else 0\n",
        "            self.batch_stats['approval_rate_by_batch'].append(approval_rate)\n",
        "            self.batch_stats['quality_progression'].append(batch_results['average_quality'])\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Erro no batch {batch_number}: {str(e)}\"\n",
        "            batch_results['errors'].append(error_msg)\n",
        "            self.batch_stats['errors'].append(error_msg)\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "\n",
        "        return batch_results\n",
        "\n",
        "    def run_full_generation(\n",
        "        self,\n",
        "        high_quality_prompts: List[Dict],\n",
        "        control_image: Image.Image,\n",
        "        batch_size: int = None\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Executa gera√ß√£o completa autom√°tica\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nüöÄ INICIANDO GERA√á√ÉO COMPLETA AUTOM√ÅTICA\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Usar batch size da configura√ß√£o se n√£o especificado\n",
        "        if batch_size is None:\n",
        "            batch_size = BATCH_CONFIG['batch_size']\n",
        "\n",
        "        session_start = time.time()\n",
        "        all_batch_results = []\n",
        "\n",
        "        try:\n",
        "            for prompt_batch, batch_number, total_batches in self.prepare_batch_prompts(high_quality_prompts, batch_size):\n",
        "\n",
        "                # Processar batch\n",
        "                batch_result = self.process_single_batch(\n",
        "                    prompt_batch,\n",
        "                    control_image,\n",
        "                    batch_number,\n",
        "                    total_batches\n",
        "                )\n",
        "\n",
        "                all_batch_results.append(batch_result)\n",
        "\n",
        "                # Relat√≥rio do batch\n",
        "                print(f\"\\nüìä RELAT√ìRIO BATCH {batch_number}:\")\n",
        "                print(f\"   üéØ Geradas: {batch_result['images_generated']}\")\n",
        "                print(f\"   ‚úÖ Aprovadas: {batch_result['images_approved']}\")\n",
        "                print(f\"   ‚ùå Rejeitadas: {batch_result['images_rejected']}\")\n",
        "                print(f\"   ‚≠ê Qualidade m√©dia: {batch_result['average_quality']:.2f}\")\n",
        "                print(f\"   ‚è±Ô∏è Tempo: {batch_result['processing_time']:.1f}s\")\n",
        "\n",
        "                if batch_result['average_fed_score'] > 0:\n",
        "                    print(f\"   üîó FED m√©dio: {batch_result['average_fed_score']:.3f}\")\n",
        "\n",
        "                # Pausa entre batches para cooling\n",
        "                if batch_number < total_batches:\n",
        "                    print(\"‚è∏Ô∏è Pausa de 2s entre batches...\")\n",
        "                    time.sleep(2)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n‚ö†Ô∏è GERA√á√ÉO INTERROMPIDA PELO USU√ÅRIO\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå ERRO NA GERA√á√ÉO: {e}\")\n",
        "            self.batch_stats['errors'].append(str(e))\n",
        "\n",
        "        # Relat√≥rio final\n",
        "        total_time = time.time() - session_start\n",
        "        final_stats = self.create_final_report(all_batch_results, total_time)\n",
        "\n",
        "        return final_stats\n",
        "\n",
        "    def create_final_report(self, batch_results: List[Dict], total_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Cria relat√≥rio final da sess√£o de gera√ß√£o\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nüìã CRIANDO RELAT√ìRIO FINAL\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Agregar estat√≠sticas\n",
        "        total_generated = sum(b['images_generated'] for b in batch_results)\n",
        "        total_approved = sum(b['images_approved'] for b in batch_results)\n",
        "        total_rejected = sum(b['images_rejected'] for b in batch_results)\n",
        "\n",
        "        overall_approval_rate = total_approved / total_generated if total_generated > 0 else 0\n",
        "\n",
        "        all_quality_scores = []\n",
        "        all_fed_scores = []\n",
        "\n",
        "        for batch in batch_results:\n",
        "            if batch['average_quality'] > 0:\n",
        "                all_quality_scores.append(batch['average_quality'])\n",
        "            if batch['average_fed_score'] > 0:\n",
        "                all_fed_scores.append(batch['average_fed_score'])\n",
        "\n",
        "        final_report = {\n",
        "            'session_summary': {\n",
        "                'session_start': self.batch_stats['session_start'],\n",
        "                'session_end': datetime.now().isoformat(),\n",
        "                'total_duration_minutes': total_time / 60,\n",
        "                'batches_processed': len(batch_results),\n",
        "                'total_images_generated': total_generated,\n",
        "                'total_images_approved': total_approved,\n",
        "                'total_images_rejected': total_rejected,\n",
        "                'overall_approval_rate': overall_approval_rate\n",
        "            },\n",
        "\n",
        "            'quality_metrics': {\n",
        "                'average_quality_score': np.mean(all_quality_scores) if all_quality_scores else 0,\n",
        "                'average_fed_score': np.mean(all_fed_scores) if all_fed_scores else 0,\n",
        "                'quality_std': np.std(all_quality_scores) if all_quality_scores else 0,\n",
        "                'fed_std': np.std(all_fed_scores) if all_fed_scores else 0\n",
        "            },\n",
        "\n",
        "            'performance_metrics': {\n",
        "                'avg_images_per_minute': (total_generated / (total_time / 60)) if total_time > 0 else 0,\n",
        "                'avg_batch_time_minutes': np.mean([b['processing_time'] / 60 for b in batch_results]),\n",
        "                'pipeline_efficiency': overall_approval_rate\n",
        "            },\n",
        "\n",
        "            'file_organization': {\n",
        "                'approved_directory': str(self.approved_dir),\n",
        "                'rejected_directory': str(self.rejected_dir),\n",
        "                'metadata_directory': str(self.metadata_dir),\n",
        "                'approved_count': total_approved,\n",
        "                'rejected_count': total_rejected\n",
        "            },\n",
        "\n",
        "            'batch_details': batch_results,\n",
        "            'pipeline_stats': self.pipeline.get_generation_stats(),\n",
        "            'errors': self.batch_stats['errors']\n",
        "        }\n",
        "\n",
        "        # Salvar relat√≥rio\n",
        "        report_path = self.metadata_dir / f\"final_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(report_path, 'w') as f:\n",
        "            json.dump(final_report, f, indent=2, default=str)\n",
        "\n",
        "        print(f\"üìÑ Relat√≥rio salvo: {report_path}\")\n",
        "\n",
        "        return final_report\n",
        "\n",
        "def create_output_directory_structure() -> str:\n",
        "    \"\"\"\n",
        "    Cria estrutura de diret√≥rios para output da gera√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    output_base = \"/content/valentina_dataset_v4/generated_commercial\"\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    session_dir = f\"{output_base}/session_{timestamp}\"\n",
        "\n",
        "    print(f\"üìÅ Criando estrutura de output: {session_dir}\")\n",
        "\n",
        "    return session_dir\n",
        "\n",
        "# Configurar diret√≥rio de output\n",
        "OUTPUT_SESSION_DIR = create_output_directory_structure()\n",
        "\n",
        "# Inicializar gerenciador de batch\n",
        "BATCH_MANAGER = BatchGenerationManager(\n",
        "    generation_pipeline=GENERATION_PIPELINE,\n",
        "    output_dir=OUTPUT_SESSION_DIR\n",
        ")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 3 CARREGADA: Sistema de gera√ß√£o em lote configurado\")"
      ],
      "metadata": {
        "id": "mqJLsqmiRb-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 4: FASE 5.4 - Execu√ß√£o da Gera√ß√£o Autom√°tica =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 4: Execu√ß√£o da Gera√ß√£o Autom√°tica\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def display_pre_generation_summary():\n",
        "    \"\"\"\n",
        "    Mostra resumo antes de iniciar a gera√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üéØ RESUMO PR√â-GERA√á√ÉO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar pr√©-requisitos\n",
        "    prerequisites = {\n",
        "        'Pipeline FLUX': FLUX_PIPELINE is not None,\n",
        "        'ControlNet carregado': FLUX_CONTROLNET is not None,\n",
        "        'Imagem de controle': 'OPTIMIZED_CONTROL_IMAGE' in globals() and OPTIMIZED_CONTROL_IMAGE is not None,\n",
        "        'Prompts validados': 'HIGH_QUALITY_PROMPTS' in globals() and len(HIGH_QUALITY_PROMPTS) > 0,\n",
        "        'Sistema de valida√ß√£o': VALIDATION_SYSTEM['available_methods'],\n",
        "        'Pipeline de gera√ß√£o': GENERATION_PIPELINE is not None,\n",
        "        'Gerenciador batch': BATCH_MANAGER is not None\n",
        "    }\n",
        "\n",
        "    print(\"‚úÖ PR√â-REQUISITOS:\")\n",
        "    all_ready = True\n",
        "    for req, status in prerequisites.items():\n",
        "        if isinstance(status, bool):\n",
        "            emoji = \"‚úÖ\" if status else \"‚ùå\"\n",
        "            if not status:\n",
        "                all_ready = False\n",
        "        else:\n",
        "            emoji = \"‚úÖ\" if status else \"‚ùå\"\n",
        "            if not status:\n",
        "                all_ready = False\n",
        "        print(f\"   {emoji} {req}\")\n",
        "\n",
        "    if not all_ready:\n",
        "        print(\"\\n‚ùå ERRO: Pr√©-requisitos n√£o atendidos!\")\n",
        "        return False\n",
        "\n",
        "    print(f\"\\nüìä CONFIGURA√á√ÉO DE GERA√á√ÉO:\")\n",
        "    print(f\"   üéØ Total de prompts aprovados: {len(HIGH_QUALITY_PROMPTS)}\")\n",
        "    print(f\"   üì¶ Batch size: {BATCH_CONFIG['batch_size']}\")\n",
        "    print(f\"   üîÑ Total de batches: {BATCH_CONFIG['num_batches']}\")\n",
        "    print(f\"   ‚öôÔ∏è Steps: {OPTIMIZED_CONFIG['num_inference_steps']}\")\n",
        "    print(f\"   üìê Resolu√ß√£o: {OPTIMIZED_CONFIG['width']}x{OPTIMIZED_CONFIG['height']}\")\n",
        "    print(f\"   üñ•Ô∏è GPU: {GPU_CONFIG['name']} ({GPU_CONFIG['tier'].upper()})\")\n",
        "\n",
        "    print(f\"\\nüéÆ CONTROLNET:\")\n",
        "    print(f\"   üìù Modelo: {SELECTED_CONTROLNET['name']}\")\n",
        "    print(f\"   üéØ Modo: {BEST_CONTROL_MODE} ({PROCESSING_INFO.get('mode_name', 'N/A')})\")\n",
        "    print(f\"   üí™ For√ßa: {OPTIMIZED_CONFIG['controlnet_conditioning_scale']}\")\n",
        "\n",
        "    print(f\"\\nüîç VALIDA√á√ÉO:\")\n",
        "    print(f\"   üë§ M√©todos: {', '.join(VALIDATION_SYSTEM['available_methods'])}\")\n",
        "    print(f\"   üéØ FED m√°ximo: {VALIDATION_SYSTEM['quality_thresholds']['max_face_embed_distance']}\")\n",
        "    print(f\"   ‚≠ê Qualidade m√≠n: {VALIDATION_SYSTEM['quality_thresholds']['min_image_quality']}\")\n",
        "\n",
        "    print(f\"\\nüíæ OUTPUT:\")\n",
        "    print(f\"   üìÅ Sess√£o: {OUTPUT_SESSION_DIR}\")\n",
        "    print(f\"   ‚úÖ Aprovadas: {BATCH_MANAGER.approved_dir}\")\n",
        "    print(f\"   ‚ùå Rejeitadas: {BATCH_MANAGER.rejected_dir}\")\n",
        "\n",
        "    # Estimativas\n",
        "    estimated_time_per_image = OPTIMIZED_CONFIG['num_inference_steps'] * 0.1  # Aproxima√ß√£o\n",
        "    total_estimated_time = len(HIGH_QUALITY_PROMPTS) * estimated_time_per_image / 60  # minutos\n",
        "\n",
        "    print(f\"\\n‚è±Ô∏è ESTIMATIVAS:\")\n",
        "    print(f\"   üïê Tempo por imagem: ~{estimated_time_per_image:.1f}s\")\n",
        "    print(f\"   üìä Tempo total estimado: ~{total_estimated_time:.1f} minutos\")\n",
        "    print(f\"   üöÄ Throughput esperado: ~{60/estimated_time_per_image:.1f} imgs/min\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def run_generation_with_monitoring():\n",
        "    \"\"\"\n",
        "    Executa gera√ß√£o com monitoramento em tempo real\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nüöÄ INICIANDO GERA√á√ÉO COMERCIAL VALENTINA v4.0\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if not display_pre_generation_summary():\n",
        "        return None\n",
        "\n",
        "    # Confirma√ß√£o final\n",
        "    print(f\"\\n‚ö†Ô∏è CONFIRMA√á√ÉO FINAL:\")\n",
        "    print(f\"   üéØ Ser√° gerado um dataset comercial da Valentina Moreau\")\n",
        "    print(f\"   üìä {len(HIGH_QUALITY_PROMPTS)} imagens ser√£o processadas\")\n",
        "    print(f\"   üí∞ Objetivo: monetiza√ß√£o em TopFans/OnlyFans\")\n",
        "    print(f\"   ‚è±Ô∏è Processo pode demorar ~{len(HIGH_QUALITY_PROMPTS) * 0.1 * OPTIMIZED_CONFIG['num_inference_steps'] / 60:.0f} minutos\")\n",
        "\n",
        "    # Auto-confirmar (remover em produ√ß√£o se quiser confirma√ß√£o manual)\n",
        "    proceed = True\n",
        "\n",
        "    if not proceed:\n",
        "        print(\"‚ùå Gera√ß√£o cancelada pelo usu√°rio\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Log in√≠cio\n",
        "        LOGGER.info(\"FASE 5 iniciada: Gera√ß√£o comercial autom√°tica\")\n",
        "        LOGGER.info(f\"Prompts aprovados: {len(HIGH_QUALITY_PROMPTS)}\")\n",
        "        LOGGER.info(f\"Configura√ß√£o: {OPTIMIZED_CONFIG}\")\n",
        "\n",
        "        # Executar gera√ß√£o completa\n",
        "        print(f\"\\nüé¨ EXECUTANDO GERA√á√ÉO AUTOM√ÅTICA...\")\n",
        "\n",
        "        final_report = BATCH_MANAGER.run_full_generation(\n",
        "            high_quality_prompts=HIGH_QUALITY_PROMPTS,\n",
        "            control_image=OPTIMIZED_CONTROL_IMAGE,\n",
        "            batch_size=BATCH_CONFIG['batch_size']\n",
        "        )\n",
        "\n",
        "        # Log conclus√£o\n",
        "        LOGGER.info(\"FASE 5 conclu√≠da: Gera√ß√£o comercial autom√°tica\")\n",
        "        LOGGER.info(f\"Imagens geradas: {final_report['session_summary']['total_images_generated']}\")\n",
        "        LOGGER.info(f\"Imagens aprovadas: {final_report['session_summary']['total_images_approved']}\")\n",
        "        LOGGER.info(f\"Taxa de aprova√ß√£o: {final_report['session_summary']['overall_approval_rate']:.1%}\")\n",
        "\n",
        "        return final_report\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Erro cr√≠tico na gera√ß√£o: {e}\"\n",
        "        print(f\"‚ùå {error_msg}\")\n",
        "        LOGGER.error(error_msg)\n",
        "        return None\n",
        "\n",
        "def display_final_results(final_report: Dict):\n",
        "    \"\"\"\n",
        "    Exibe resultados finais da gera√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    if not final_report:\n",
        "        print(\"‚ùå Nenhum relat√≥rio para exibir\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 70)\n",
        "    print(f\"üéâ GERA√á√ÉO COMERCIAL VALENTINA v4.0 CONCLU√çDA!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    session = final_report['session_summary']\n",
        "    quality = final_report['quality_metrics']\n",
        "    performance = final_report['performance_metrics']\n",
        "    files = final_report['file_organization']\n",
        "\n",
        "    print(f\"üìä RESULTADOS DA SESS√ÉO:\")\n",
        "    print(f\"   ‚è±Ô∏è Dura√ß√£o: {session['total_duration_minutes']:.1f} minutos\")\n",
        "    print(f\"   üîÑ Batches processados: {session['batches_processed']}\")\n",
        "    print(f\"   üéØ Total geradas: {session['total_images_generated']}\")\n",
        "    print(f\"   ‚úÖ Aprovadas: {session['total_images_approved']}\")\n",
        "    print(f\"   ‚ùå Rejeitadas: {session['total_images_rejected']}\")\n",
        "    print(f\"   üìà Taxa de aprova√ß√£o: {session['overall_approval_rate']:.1%}\")\n",
        "\n",
        "    print(f\"\\n‚≠ê M√âTRICAS DE QUALIDADE:\")\n",
        "    print(f\"   üéØ Qualidade m√©dia: {quality['average_quality_score']:.2f}/1.0\")\n",
        "    if quality['average_fed_score'] > 0:\n",
        "        print(f\"   üë§ FED m√©dio: {quality['average_fed_score']:.3f}\")\n",
        "    print(f\"   üìä Desvio qualidade: ¬±{quality['quality_std']:.2f}\")\n",
        "\n",
        "    print(f\"\\nüöÄ PERFORMANCE:\")\n",
        "    print(f\"   ‚ö° Throughput: {performance['avg_images_per_minute']:.1f} imgs/min\")\n",
        "    print(f\"   ‚è±Ô∏è Tempo m√©dio/batch: {performance['avg_batch_time_minutes']:.1f} min\")\n",
        "    print(f\"   üéØ Efici√™ncia pipeline: {performance['pipeline_efficiency']:.1%}\")\n",
        "\n",
        "    print(f\"\\nüìÅ ARQUIVOS GERADOS:\")\n",
        "    print(f\"   ‚úÖ Aprovadas: {files['approved_count']} em {files['approved_directory']}\")\n",
        "    print(f\"   ‚ùå Rejeitadas: {files['rejected_count']} em {files['rejected_directory']}\")\n",
        "    print(f\"   üìÑ Metadados: {files['metadata_directory']}\")\n",
        "\n",
        "    if final_report['errors']:\n",
        "        print(f\"\\n‚ö†Ô∏è ERROS REGISTRADOS: {len(final_report['errors'])}\")\n",
        "        for error in final_report['errors'][-3:]:  # Mostrar √∫ltimos 3\n",
        "            print(f\"   ‚Ä¢ {error}\")\n",
        "\n",
        "    # Resumo comercial\n",
        "    print(f\"\\nüí∞ RESUMO COMERCIAL:\")\n",
        "    if session['total_images_approved'] > 0:\n",
        "        print(f\"   üéØ Dataset pronto para monetiza√ß√£o: ‚úÖ\")\n",
        "        print(f\"   üìà Imagens comerciais: {session['total_images_approved']}\")\n",
        "        print(f\"   üèÜ Qualidade garantida: {quality['average_quality_score']:.0%}\")\n",
        "        print(f\"   üé≠ Consist√™ncia facial: {'‚úÖ' if quality['average_fed_score'] < 0.3 else '‚ö†Ô∏è'}\")\n",
        "        print(f\"   üöÄ Pronto para TopFans/OnlyFans: ‚úÖ\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Nenhuma imagem aprovada - revisar configura√ß√µes\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# Executar gera√ß√£o se todos os pr√©-requisitos est√£o prontos\n",
        "if ('HIGH_QUALITY_PROMPTS' in globals() and\n",
        "    'OPTIMIZED_CONTROL_IMAGE' in globals() and\n",
        "    len(HIGH_QUALITY_PROMPTS) > 0):\n",
        "\n",
        "    print(\"üé¨ TODOS OS PR√â-REQUISITOS PRONTOS - INICIANDO GERA√á√ÉO...\")\n",
        "\n",
        "    FINAL_GENERATION_REPORT = run_generation_with_monitoring()\n",
        "\n",
        "    if FINAL_GENERATION_REPORT:\n",
        "        display_final_results(FINAL_GENERATION_REPORT)\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è PR√â-REQUISITOS N√ÉO ATENDIDOS\")\n",
        "    print(\"üîß Execute as fases anteriores corretamente antes de continuar\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 4 CONCLU√çDA: Gera√ß√£o autom√°tica executada\")"
      ],
      "metadata": {
        "id": "EQPsIJ2CRDnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 5: FASE 5.5 - An√°lise e Otimiza√ß√£o dos Resultados =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 5: An√°lise e Otimiza√ß√£o dos Resultados\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "def analyze_generation_results(final_report: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    An√°lise detalhada dos resultados da gera√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìä ANALISANDO RESULTADOS DA GERA√á√ÉO\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if not final_report:\n",
        "        print(\"‚ùå Nenhum relat√≥rio para analisar\")\n",
        "        return {}\n",
        "\n",
        "    analysis = {\n",
        "        'performance_analysis': {},\n",
        "        'quality_analysis': {},\n",
        "        'optimization_recommendations': [],\n",
        "        'commercial_readiness': {},\n",
        "        'next_steps': []\n",
        "    }\n",
        "\n",
        "    session = final_report['session_summary']\n",
        "    quality = final_report['quality_metrics']\n",
        "    performance = final_report['performance_metrics']\n",
        "\n",
        "    # An√°lise de performance\n",
        "    analysis['performance_analysis'] = {\n",
        "        'throughput_rating': 'excellent' if performance['avg_images_per_minute'] > 2 else 'good' if performance['avg_images_per_minute'] > 1 else 'needs_improvement',\n",
        "        'efficiency_rating': 'excellent' if performance['pipeline_efficiency'] > 0.8 else 'good' if performance['pipeline_efficiency'] > 0.6 else 'needs_improvement',\n",
        "        'approval_rate_rating': 'excellent' if session['overall_approval_rate'] > 0.7 else 'good' if session['overall_approval_rate'] > 0.5 else 'needs_improvement'\n",
        "    }\n",
        "\n",
        "    # An√°lise de qualidade\n",
        "    avg_quality = quality['average_quality_score']\n",
        "    avg_fed = quality['average_fed_score']\n",
        "\n",
        "    analysis['quality_analysis'] = {\n",
        "        'overall_quality_rating': 'excellent' if avg_quality > 0.8 else 'good' if avg_quality > 0.6 else 'needs_improvement',\n",
        "        'face_consistency_rating': 'excellent' if avg_fed < 0.2 else 'good' if avg_fed < 0.3 else 'needs_improvement' if avg_fed > 0 else 'no_data',\n",
        "        'quality_distribution': 'consistent' if quality['quality_std'] < 0.15 else 'variable'\n",
        "    }\n",
        "\n",
        "    # Prontid√£o comercial\n",
        "    commercial_score = 0\n",
        "    commercial_factors = []\n",
        "\n",
        "    if session['total_images_approved'] >= 20:\n",
        "        commercial_score += 30\n",
        "        commercial_factors.append(\"‚úÖ Volume adequado de imagens\")\n",
        "    else:\n",
        "        commercial_factors.append(\"‚ö†Ô∏è Volume baixo de imagens aprovadas\")\n",
        "\n",
        "    if avg_quality > 0.7:\n",
        "        commercial_score += 25\n",
        "        commercial_factors.append(\"‚úÖ Qualidade comercial atingida\")\n",
        "    else:\n",
        "        commercial_factors.append(\"‚ö†Ô∏è Qualidade abaixo do padr√£o comercial\")\n",
        "\n",
        "    if avg_fed < 0.3 and avg_fed > 0:\n",
        "        commercial_score += 25\n",
        "        commercial_factors.append(\"‚úÖ Consist√™ncia facial adequada\")\n",
        "    elif avg_fed > 0.3:\n",
        "        commercial_factors.append(\"‚ö†Ô∏è Consist√™ncia facial baixa\")\n",
        "    else:\n",
        "        commercial_factors.append(\"‚ö†Ô∏è Dados de consist√™ncia facial insuficientes\")\n",
        "\n",
        "    if session['overall_approval_rate'] > 0.6:\n",
        "        commercial_score += 20\n",
        "        commercial_factors.append(\"‚úÖ Taxa de aprova√ß√£o satisfat√≥ria\")\n",
        "    else:\n",
        "        commercial_factors.append(\"‚ö†Ô∏è Taxa de aprova√ß√£o baixa\")\n",
        "\n",
        "    analysis['commercial_readiness'] = {\n",
        "        'score': commercial_score,\n",
        "        'rating': 'ready' if commercial_score >= 80 else 'partial' if commercial_score >= 60 else 'not_ready',\n",
        "        'factors': commercial_factors\n",
        "    }\n",
        "\n",
        "    # Recomenda√ß√µes de otimiza√ß√£o\n",
        "    recommendations = []\n",
        "\n",
        "    if performance['avg_images_per_minute'] < 1.5:\n",
        "        recommendations.append(\"Considerar reduzir num_inference_steps para melhor throughput\")\n",
        "\n",
        "    if session['overall_approval_rate'] < 0.6:\n",
        "        recommendations.append(\"Revisar thresholds de valida√ß√£o - podem estar muito r√≠gidos\")\n",
        "\n",
        "    if avg_quality < 0.7:\n",
        "        recommendations.append(\"Aumentar guidance_scale ou melhorar prompts\")\n",
        "\n",
        "    if avg_fed > 0.3:\n",
        "        recommendations.append(\"Aumentar controlnet_conditioning_scale para melhor consist√™ncia\")\n",
        "\n",
        "    if quality['quality_std'] > 0.2:\n",
        "        recommendations.append(\"Padronizar mais os prompts para reduzir variabilidade\")\n",
        "\n",
        "    if not recommendations:\n",
        "        recommendations.append(\"Configura√ß√£o atual est√° otimizada - manter par√¢metros\")\n",
        "\n",
        "    analysis['optimization_recommendations'] = recommendations\n",
        "\n",
        "    # Pr√≥ximos passos\n",
        "    next_steps = []\n",
        "\n",
        "    if analysis['commercial_readiness']['rating'] == 'ready':\n",
        "        next_steps.extend([\n",
        "            \"‚úÖ Dataset pronto para treinamento LoRA/DreamBooth\",\n",
        "            \"üìà Iniciar processo de upload para plataformas comerciais\",\n",
        "            \"üéØ Configurar pipeline de produ√ß√£o cont√≠nua\"\n",
        "        ])\n",
        "    elif analysis['commercial_readiness']['rating'] == 'partial':\n",
        "        next_steps.extend([\n",
        "            \"üîß Aplicar otimiza√ß√µes recomendadas\",\n",
        "            \"üîÑ Executar nova sess√£o de gera√ß√£o\",\n",
        "            \"üìä Reavaliar qualidade ap√≥s ajustes\"\n",
        "        ])\n",
        "    else:\n",
        "        next_steps.extend([\n",
        "            \"‚ö†Ô∏è Revisar configura√ß√µes fundamentais\",\n",
        "            \"üîç Analisar causas de baixa aprova√ß√£o\",\n",
        "            \"üéØ Considerar ajuste de modelo base ou ControlNet\"\n",
        "        ])\n",
        "\n",
        "    analysis['next_steps'] = next_steps\n",
        "\n",
        "    print(f\"üìä AN√ÅLISE CONCLU√çDA:\")\n",
        "    print(f\"   üöÄ Performance: {analysis['performance_analysis']['throughput_rating']}\")\n",
        "    print(f\"   ‚≠ê Qualidade: {analysis['quality_analysis']['overall_quality_rating']}\")\n",
        "    print(f\"   üí∞ Prontid√£o comercial: {analysis['commercial_readiness']['rating']} ({commercial_score}/100)\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "def create_optimization_suggestions(analysis: Dict, final_report: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Cria sugest√µes espec√≠ficas de otimiza√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüîß CRIANDO SUGEST√ïES DE OTIMIZA√á√ÉO\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if not analysis:\n",
        "        return {}\n",
        "\n",
        "    current_config = OPTIMIZED_CONFIG.copy()\n",
        "    suggestions = {\n",
        "        'current_config': current_config,\n",
        "        'suggested_configs': [],\n",
        "        'reasoning': []\n",
        "    }\n",
        "\n",
        "    session = final_report['session_summary']\n",
        "    performance = final_report['performance_metrics']\n",
        "    quality = final_report['quality_metrics']\n",
        "\n",
        "    # Configura√ß√£o para maior throughput\n",
        "    if performance['avg_images_per_minute'] < 2:\n",
        "        fast_config = current_config.copy()\n",
        "        fast_config['num_inference_steps'] = 20  # Reduzir de 28\n",
        "        fast_config['guidance_scale'] = 3.0      # Reduzir de 3.5\n",
        "\n",
        "        suggestions['suggested_configs'].append({\n",
        "            'name': 'high_throughput',\n",
        "            'config': fast_config,\n",
        "            'trade_offs': 'Menor qualidade, maior velocidade',\n",
        "            'expected_improvement': '+30% throughput, -10% qualidade'\n",
        "        })\n",
        "\n",
        "        suggestions['reasoning'].append(\"Throughput atual baixo - configura√ß√£o r√°pida dispon√≠vel\")\n",
        "\n",
        "    # Configura√ß√£o para maior qualidade\n",
        "    if quality['average_quality_score'] < 0.8:\n",
        "        quality_config = current_config.copy()\n",
        "        quality_config['num_inference_steps'] = 35  # Aumentar de 28\n",
        "        quality_config['guidance_scale'] = 4.0      # Aumentar de 3.5\n",
        "\n",
        "        suggestions['suggested_configs'].append({\n",
        "            'name': 'high_quality',\n",
        "            'config': quality_config,\n",
        "            'trade_offs': 'Maior qualidade, menor velocidade',\n",
        "            'expected_improvement': '+15% qualidade, -25% throughput'\n",
        "        })\n",
        "\n",
        "        suggestions['reasoning'].append(\"Qualidade abaixo do ideal - configura√ß√£o premium dispon√≠vel\")\n",
        "\n",
        "    # Configura√ß√£o para melhor consist√™ncia facial\n",
        "    if quality['average_fed_score'] > 0.25:\n",
        "        consistency_config = current_config.copy()\n",
        "        consistency_config['controlnet_conditioning_scale'] = 0.8  # Aumentar de 0.7\n",
        "        consistency_config['control_guidance_end'] = 0.9          # Aumentar de 0.8\n",
        "\n",
        "        suggestions['suggested_configs'].append({\n",
        "            'name': 'better_consistency',\n",
        "            'config': consistency_config,\n",
        "            'trade_offs': 'Melhor consist√™ncia, poss√≠vel redu√ß√£o de criatividade',\n",
        "            'expected_improvement': '-20% FED, mais identidade preservada'\n",
        "        })\n",
        "\n",
        "        suggestions['reasoning'].append(\"FED alto detectado - configura√ß√£o de consist√™ncia dispon√≠vel\")\n",
        "\n",
        "    # Configura√ß√£o balanceada otimizada\n",
        "    balanced_config = current_config.copy()\n",
        "\n",
        "    # Ajustes baseados nos resultados\n",
        "    if session['overall_approval_rate'] < 0.7:\n",
        "        # Relaxar um pouco os par√¢metros para melhor aprova√ß√£o\n",
        "        balanced_config['guidance_scale'] = 3.2\n",
        "        balanced_config['controlnet_conditioning_scale'] = 0.65\n",
        "\n",
        "    if performance['avg_images_per_minute'] < 1:\n",
        "        # Otimizar para velocidade se muito lento\n",
        "        balanced_config['num_inference_steps'] = 25\n",
        "\n",
        "    suggestions['suggested_configs'].append({\n",
        "        'name': 'balanced_optimized',\n",
        "        'config': balanced_config,\n",
        "        'trade_offs': 'Equilibrio otimizado baseado nos resultados',\n",
        "        'expected_improvement': 'Melhor balance geral'\n",
        "    })\n",
        "\n",
        "    print(f\"üí° {len(suggestions['suggested_configs'])} configura√ß√µes sugeridas\")\n",
        "\n",
        "    return suggestions\n",
        "\n",
        "def generate_visual_analytics(final_report: Dict):\n",
        "    \"\"\"\n",
        "    Gera an√°lises visuais dos resultados\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìà GERANDO AN√ÅLISES VISUAIS\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if not final_report:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Configurar estilo\n",
        "        plt.style.use('default')\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Valentina Dataset Generator v4.0 - An√°lise de Resultados', fontsize=16)\n",
        "\n",
        "        # 1. Taxa de aprova√ß√£o por batch\n",
        "        batch_details = final_report['batch_details']\n",
        "        batch_numbers = [b['batch_number'] for b in batch_details]\n",
        "        approval_rates = [b['images_approved'] / b['images_generated'] if b['images_generated'] > 0 else 0 for b in batch_details]\n",
        "\n",
        "        axes[0, 0].plot(batch_numbers, approval_rates, 'o-', color='green', markersize=8)\n",
        "        axes[0, 0].set_title('Taxa de Aprova√ß√£o por Batch')\n",
        "        axes[0, 0].set_xlabel('N√∫mero do Batch')\n",
        "        axes[0, 0].set_ylabel('Taxa de Aprova√ß√£o')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        axes[0, 0].set_ylim(0, 1)\n",
        "\n",
        "        # 2. Qualidade m√©dia por batch\n",
        "        quality_scores = [b['average_quality'] for b in batch_details if b['average_quality'] > 0]\n",
        "\n",
        "        if quality_scores:\n",
        "            axes[0, 1].plot(batch_numbers[:len(quality_scores)], quality_scores, 's-', color='blue', markersize=8)\n",
        "            axes[0, 1].set_title('Qualidade M√©dia por Batch')\n",
        "            axes[0, 1].set_xlabel('N√∫mero do Batch')\n",
        "            axes[0, 1].set_ylabel('Score de Qualidade')\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "            axes[0, 1].set_ylim(0, 1)\n",
        "\n",
        "        # 3. Distribui√ß√£o de qualidade\n",
        "        all_quality = [b['average_quality'] for b in batch_details if b['average_quality'] > 0]\n",
        "\n",
        "        if all_quality:\n",
        "            axes[1, 0].hist(all_quality, bins=10, color='skyblue', alpha=0.7, edgecolor='black')\n",
        "            axes[1, 0].axvline(np.mean(all_quality), color='red', linestyle='--', label=f'M√©dia: {np.mean(all_quality):.2f}')\n",
        "            axes[1, 0].set_title('Distribui√ß√£o de Qualidade')\n",
        "            axes[1, 0].set_xlabel('Score de Qualidade')\n",
        "            axes[1, 0].set_ylabel('Frequ√™ncia')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Resumo final\n",
        "        session = final_report['session_summary']\n",
        "        categories = ['Aprovadas', 'Rejeitadas']\n",
        "        values = [session['total_images_approved'], session['total_images_rejected']]\n",
        "        colors = ['green', 'red']\n",
        "\n",
        "        axes[1, 1].pie(values, labels=categories, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "        axes[1, 1].set_title('Distribui√ß√£o Final de Imagens')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Salvar gr√°fico\n",
        "        analytics_path = Path(OUTPUT_SESSION_DIR) / \"metadata\" / f\"analytics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "        plt.savefig(analytics_path, dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"üìä An√°lise visual salva: {analytics_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro gerando an√°lises visuais: {e}\")\n",
        "\n",
        "# Executar an√°lise se temos relat√≥rio\n",
        "if 'FINAL_GENERATION_REPORT' in globals() and FINAL_GENERATION_REPORT:\n",
        "\n",
        "    print(\"üöÄ EXECUTANDO AN√ÅLISE COMPLETA DOS RESULTADOS...\")\n",
        "\n",
        "    # An√°lise detalhada\n",
        "    RESULTS_ANALYSIS = analyze_generation_results(FINAL_GENERATION_REPORT)\n",
        "\n",
        "    # Sugest√µes de otimiza√ß√£o\n",
        "    OPTIMIZATION_SUGGESTIONS = create_optimization_suggestions(RESULTS_ANALYSIS, FINAL_GENERATION_REPORT)\n",
        "\n",
        "    # An√°lises visuais\n",
        "    generate_visual_analytics(FINAL_GENERATION_REPORT)\n",
        "\n",
        "    # Exibir recomenda√ß√µes\n",
        "    if RESULTS_ANALYSIS:\n",
        "        print(f\"\\nüí° RECOMENDA√á√ïES DE OTIMIZA√á√ÉO:\")\n",
        "        for rec in RESULTS_ANALYSIS['optimization_recommendations']:\n",
        "            print(f\"   ‚Ä¢ {rec}\")\n",
        "\n",
        "        print(f\"\\nüéØ PR√ìXIMOS PASSOS:\")\n",
        "        for step in RESULTS_ANALYSIS['next_steps']:\n",
        "            print(f\"   {step}\")\n",
        "\n",
        "        print(f\"\\nüìä PRONTID√ÉO COMERCIAL: {RESULTS_ANALYSIS['commercial_readiness']['score']}/100\")\n",
        "        for factor in RESULTS_ANALYSIS['commercial_readiness']['factors']:\n",
        "            print(f\"   {factor}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Nenhum relat√≥rio de gera√ß√£o dispon√≠vel para an√°lise\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 5 CONCLU√çDA: An√°lise e otimiza√ß√£o dos resultados\")"
      ],
      "metadata": {
        "id": "2nK_lFb3Qy-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 6: FASE 5.6 - Resumo e Conclus√£o da FASE 5 =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 6: Resumo e Conclus√£o da FASE 5\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def generate_phase5_final_report() -> Dict:\n",
        "    \"\"\"\n",
        "    Gera relat√≥rio final consolidado da FASE 5\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìã GERANDO RELAT√ìRIO FINAL DA FASE 5\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    phase5_report = {\n",
        "        'phase': 5,\n",
        "        'title': 'Gera√ß√£o com Valida√ß√£o Comercial Autom√°tica',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'status': 'completed',\n",
        "\n",
        "        'components_implemented': {\n",
        "            'facial_validation_system': {\n",
        "                'implemented': True,\n",
        "                'methods_available': VALIDATION_SYSTEM['available_methods'],\n",
        "                'commercial_thresholds': VALIDATION_SYSTEM['quality_thresholds']\n",
        "            },\n",
        "            'a100_generation_pipeline': {\n",
        "                'implemented': True,\n",
        "                'optimized_for_gpu': GPU_CONFIG['name'],\n",
        "                'memory_management': True,\n",
        "                'batch_processing': True\n",
        "            },\n",
        "            'automatic_batch_manager': {\n",
        "                'implemented': True,\n",
        "                'output_organization': True,\n",
        "                'metadata_generation': True,\n",
        "                'quality_filtering': True\n",
        "            },\n",
        "            'results_analysis': {\n",
        "                'implemented': 'RESULTS_ANALYSIS' in globals(),\n",
        "                'optimization_suggestions': 'OPTIMIZATION_SUGGESTIONS' in globals(),\n",
        "                'visual_analytics': True\n",
        "            }\n",
        "        },\n",
        "\n",
        "        'generation_results': {},\n",
        "        'technical_achievements': [],\n",
        "        'commercial_achievements': [],\n",
        "        'limitations_identified': [],\n",
        "        'recommendations': []\n",
        "    }\n",
        "\n",
        "    # Incluir resultados se dispon√≠veis\n",
        "    if 'FINAL_GENERATION_REPORT' in globals() and FINAL_GENERATION_REPORT:\n",
        "        phase5_report['generation_results'] = FINAL_GENERATION_REPORT\n",
        "\n",
        "        session = FINAL_GENERATION_REPORT['session_summary']\n",
        "        quality = FINAL_GENERATION_REPORT['quality_metrics']\n",
        "\n",
        "        # Conquistas t√©cnicas\n",
        "        technical_achievements = [\n",
        "            f\"‚úÖ Sistema de valida√ß√£o facial com {len(VALIDATION_SYSTEM['available_methods'])} m√©todos\",\n",
        "            f\"‚úÖ Pipeline otimizado para {GPU_CONFIG['name']} implementado\",\n",
        "            f\"‚úÖ Gera√ß√£o autom√°tica de {session['total_images_generated']} imagens\",\n",
        "            f\"‚úÖ Valida√ß√£o comercial com {session['overall_approval_rate']:.1%} de aprova√ß√£o\"\n",
        "        ]\n",
        "\n",
        "        if quality['average_fed_score'] > 0:\n",
        "            technical_achievements.append(f\"‚úÖ Consist√™ncia facial com FED m√©dio {quality['average_fed_score']:.3f}\")\n",
        "\n",
        "        phase5_report['technical_achievements'] = technical_achievements\n",
        "\n",
        "        # Conquistas comerciais\n",
        "        commercial_achievements = []\n",
        "\n",
        "        if session['total_images_approved'] > 0:\n",
        "            commercial_achievements.append(f\"üéØ {session['total_images_approved']} imagens aprovadas para uso comercial\")\n",
        "\n",
        "        if quality['average_quality_score'] > 0.7:\n",
        "            commercial_achievements.append(f\"‚≠ê Qualidade comercial atingida ({quality['average_quality_score']:.2f}/1.0)\")\n",
        "\n",
        "        if session['overall_approval_rate'] > 0.6:\n",
        "            commercial_achievements.append(f\"üìà Taxa de aprova√ß√£o satisfat√≥ria ({session['overall_approval_rate']:.1%})\")\n",
        "\n",
        "        # An√°lise de prontid√£o comercial\n",
        "        if 'RESULTS_ANALYSIS' in globals() and RESULTS_ANALYSIS:\n",
        "            commercial_readiness = RESULTS_ANALYSIS['commercial_readiness']\n",
        "            if commercial_readiness['rating'] == 'ready':\n",
        "                commercial_achievements.append(\"üöÄ Dataset completamente pronto para monetiza√ß√£o\")\n",
        "            elif commercial_readiness['rating'] == 'partial':\n",
        "                commercial_achievements.append(\"üîß Dataset parcialmente pronto - otimiza√ß√µes recomendadas\")\n",
        "\n",
        "        phase5_report['commercial_achievements'] = commercial_achievements\n",
        "\n",
        "        # Limita√ß√µes identificadas\n",
        "        limitations = []\n",
        "\n",
        "        if session['overall_approval_rate'] < 0.6:\n",
        "            limitations.append(\"Taxa de aprova√ß√£o baixa - crit√©rios podem estar muito r√≠gidos\")\n",
        "\n",
        "        if quality['average_quality_score'] < 0.7:\n",
        "            limitations.append(\"Qualidade m√©dia abaixo do ideal comercial\")\n",
        "\n",
        "        if quality['average_fed_score'] > 0.3:\n",
        "            limitations.append(\"Consist√™ncia facial precisa melhorar\")\n",
        "\n",
        "        if not limitations:\n",
        "            limitations.append(\"Nenhuma limita√ß√£o cr√≠tica identificada\")\n",
        "\n",
        "        phase5_report['limitations_identified'] = limitations\n",
        "\n",
        "    # Recomenda√ß√µes finais\n",
        "    recommendations = [\n",
        "        \"üìä Monitorar m√©tricas de qualidade em gera√ß√µes futuras\",\n",
        "        \"üîß Aplicar otimiza√ß√µes sugeridas para melhor performance\",\n",
        "        \"üí∞ Proceder com monetiza√ß√£o das imagens aprovadas\",\n",
        "        \"üéØ Configurar pipeline de produ√ß√£o cont√≠nua\"\n",
        "    ]\n",
        "\n",
        "    if 'RESULTS_ANALYSIS' in globals() and RESULTS_ANALYSIS:\n",
        "        recommendations.extend(RESULTS_ANALYSIS['next_steps'])\n",
        "\n",
        "    phase5_report['recommendations'] = recommendations\n",
        "\n",
        "    # Salvar relat√≥rio\n",
        "    report_path = f\"/content/valentina_dataset_v4/metadata/phase5_final_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(phase5_report, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"üìÑ Relat√≥rio FASE 5 salvo: {report_path}\")\n",
        "\n",
        "    return phase5_report\n",
        "\n",
        "def display_final_phase5_summary(phase5_report: Dict):\n",
        "    \"\"\"\n",
        "    Exibe resumo final da FASE 5\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 70)\n",
        "    print(f\"üéâ FASE 5 CONCLU√çDA: GERA√á√ÉO COM VALIDA√á√ÉO COMERCIAL AUTOM√ÅTICA\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Status dos componentes\n",
        "    components = phase5_report['components_implemented']\n",
        "    print(f\"üîß COMPONENTES IMPLEMENTADOS:\")\n",
        "\n",
        "    for component, details in components.items():\n",
        "        status = \"‚úÖ\" if details['implemented'] else \"‚ùå\"\n",
        "        name = component.replace('_', ' ').title()\n",
        "        print(f\"   {status} {name}\")\n",
        "\n",
        "    # Conquistas t√©cnicas\n",
        "    if phase5_report['technical_achievements']:\n",
        "        print(f\"\\nüöÄ CONQUISTAS T√âCNICAS:\")\n",
        "        for achievement in phase5_report['technical_achievements']:\n",
        "            print(f\"   {achievement}\")\n",
        "\n",
        "    # Conquistas comerciais\n",
        "    if phase5_report['commercial_achievements']:\n",
        "        print(f\"\\nüí∞ CONQUISTAS COMERCIAIS:\")\n",
        "        for achievement in phase5_report['commercial_achievements']:\n",
        "            print(f\"   {achievement}\")\n",
        "\n",
        "    # Resultados da gera√ß√£o se dispon√≠veis\n",
        "    if phase5_report['generation_results']:\n",
        "        session = phase5_report['generation_results']['session_summary']\n",
        "        quality = phase5_report['generation_results']['quality_metrics']\n",
        "\n",
        "        print(f\"\\nüìä RESULTADOS DA GERA√á√ÉO:\")\n",
        "        print(f\"   üéØ Total geradas: {session['total_images_generated']}\")\n",
        "        print(f\"   ‚úÖ Aprovadas: {session['total_images_approved']}\")\n",
        "        print(f\"   üìà Taxa aprova√ß√£o: {session['overall_approval_rate']:.1%}\")\n",
        "        print(f\"   ‚≠ê Qualidade m√©dia: {quality['average_quality_score']:.2f}/1.0\")\n",
        "        print(f\"   ‚è±Ô∏è Dura√ß√£o: {session['total_duration_minutes']:.1f} min\")\n",
        "\n",
        "        if quality['average_fed_score'] > 0:\n",
        "            print(f\"   üë§ FED m√©dio: {quality['average_fed_score']:.3f}\")\n",
        "\n",
        "    # Limita√ß√µes\n",
        "    if phase5_report['limitations_identified']:\n",
        "        print(f\"\\n‚ö†Ô∏è LIMITA√á√ïES IDENTIFICADAS:\")\n",
        "        for limitation in phase5_report['limitations_identified']:\n",
        "            print(f\"   ‚Ä¢ {limitation}\")\n",
        "\n",
        "    # Recomenda√ß√µes priorit√°rias\n",
        "    print(f\"\\nüéØ PR√ìXIMOS PASSOS RECOMENDADOS:\")\n",
        "    for i, rec in enumerate(phase5_report['recommendations'][:5], 1):\n",
        "        print(f\"   {i}. {rec}\")\n",
        "\n",
        "    # Status final do projeto\n",
        "    print(f\"\\nüèÜ STATUS FINAL DO PROJETO:\")\n",
        "\n",
        "    if 'RESULTS_ANALYSIS' in globals() and RESULTS_ANALYSIS:\n",
        "        readiness = RESULTS_ANALYSIS['commercial_readiness']\n",
        "        score = readiness['score']\n",
        "\n",
        "        if score >= 80:\n",
        "            print(f\"   üöÄ PROJETO COMPLETO E PRONTO PARA MONETIZA√á√ÉO ({score}/100)\")\n",
        "            print(f\"   üíé Dataset Valentina Moreau v4.0 aprovado para produ√ß√£o\")\n",
        "            print(f\"   üéØ Recomendado proceder com upload para TopFans/OnlyFans\")\n",
        "        elif score >= 60:\n",
        "            print(f\"   üîß PROJETO PARCIALMENTE PRONTO ({score}/100)\")\n",
        "            print(f\"   ‚öôÔ∏è Aplicar otimiza√ß√µes recomendadas antes da produ√ß√£o\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è PROJETO NECESSITA AJUSTES ({score}/100)\")\n",
        "            print(f\"   üîç Revisar configura√ß√µes e executar nova gera√ß√£o\")\n",
        "    else:\n",
        "        if phase5_report['generation_results']:\n",
        "            print(f\"   ‚úÖ FASE 5 EXECUTADA COM SUCESSO\")\n",
        "            print(f\"   üìä Resultados dispon√≠veis para an√°lise\")\n",
        "        else:\n",
        "            print(f\"   üìã FASE 5 CONFIGURADA E PRONTA\")\n",
        "            print(f\"   ‚ö° Execute a gera√ß√£o quando estiver pronto\")\n",
        "\n",
        "# Gerar relat√≥rio final da FASE 5\n",
        "PHASE5_FINAL_REPORT = generate_phase5_final_report()\n",
        "\n",
        "# Exibir resumo final\n",
        "display_final_phase5_summary(PHASE5_FINAL_REPORT)\n",
        "\n",
        "# =============================================================================\n",
        "# üìä RESUMO GLOBAL DO PROJETO VALENTINA v4.0\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(f\"üéØ RESUMO GLOBAL: VALENTINA DATASET GENERATOR v4.0\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üèóÔ∏è PROJETO EXECUTADO:\")\n",
        "print(f\"   ‚úÖ FASE 1: Setup Google Colab Otimizado\")\n",
        "print(f\"   ‚úÖ FASE 2: Carregamento Inteligente dos Modelos\")\n",
        "print(f\"   ‚úÖ FASE 3: Processamento da Imagem de Refer√™ncia\")\n",
        "print(f\"   ‚úÖ FASE 4: Sistema de Prompts Comerciais Otimizados\")\n",
        "print(f\"   ‚úÖ FASE 5: Gera√ß√£o com Valida√ß√£o Comercial Autom√°tica\")\n",
        "\n",
        "print(f\"\\nüéÆ STACK T√âCNICO IMPLEMENTADO:\")\n",
        "print(f\"   ‚Ä¢ FLUX.1-dev + {SELECTED_CONTROLNET['name']}\")\n",
        "print(f\"   ‚Ä¢ {GPU_CONFIG['name']} otimizado para produ√ß√£o comercial\")\n",
        "print(f\"   ‚Ä¢ Sistema dual encoder (CLIP + T5) configurado\")\n",
        "print(f\"   ‚Ä¢ Valida√ß√£o facial autom√°tica implementada\")\n",
        "print(f\"   ‚Ä¢ Pipeline de gera√ß√£o em lote otimizado\")\n",
        "\n",
        "print(f\"\\nüí∞ OBJETIVO COMERCIAL:\")\n",
        "print(f\"   üéØ Modelo digital: Valentina Moreau\")\n",
        "print(f\"   üöÄ Plataformas alvo: TopFans, OnlyFans\")\n",
        "print(f\"   üíé Foco: Conte√∫do premium de alta qualidade\")\n",
        "print(f\"   üîí Identidade facial consistente garantida\")\n",
        "\n",
        "if 'FINAL_GENERATION_REPORT' in globals() and FINAL_GENERATION_REPORT:\n",
        "    session = FINAL_GENERATION_REPORT['session_summary']\n",
        "    print(f\"\\nüéâ DATASET GERADO COM SUCESSO:\")\n",
        "    print(f\"   üìä {session['total_images_approved']} imagens comerciais aprovadas\")\n",
        "    print(f\"   ‚≠ê Qualidade comercial validada automaticamente\")\n",
        "    print(f\"   üöÄ Pronto para monetiza√ß√£o imediata\")\n",
        "\n",
        "print(f\"\\nüî• VALENTINA DATASET GENERATOR v4.0 - MISS√ÉO CUMPRIDA! üî•\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Log final\n",
        "LOGGER.info(\"PROJETO VALENTINA v4.0 CONCLU√çDO COM SUCESSO\")\n",
        "LOGGER.info(\"Todas as 5 fases implementadas e funcionais\")\n",
        "if 'FINAL_GENERATION_REPORT' in globals() and FINAL_GENERATION_REPORT:\n",
        "    session = FINAL_GENERATION_REPORT['session_summary']\n",
        "    LOGGER.info(f\"Dataset comercial gerado: {session['total_images_approved']} imagens aprovadas\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 6 CONCLU√çDA: FASE 5 finalizada com sucesso!\")"
      ],
      "metadata": {
        "id": "bYiwdBThQwBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 1: FASE 6.1 - Sistema de Upscaling e Refinamento de Qualidade =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üì± C√âLULA 1: Sistema de Upscaling e Refinamento de Qualidade\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "from PIL.ExifTags import TAGS\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "import time\n",
        "from datetime import datetime\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import queue\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "class CommercialImageProcessor:\n",
        "    \"\"\"\n",
        "    Processador comercial para refinamento de imagens geradas\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.upscaler_model = None\n",
        "        self.processing_stats = {\n",
        "            'images_processed': 0,\n",
        "            'processing_times': [],\n",
        "            'quality_improvements': [],\n",
        "            'size_increases': []\n",
        "        }\n",
        "\n",
        "        # Configura√ß√µes de processamento comercial\n",
        "        self.commercial_settings = {\n",
        "            'target_resolution': (2048, 2048),  # Resolu√ß√£o comercial premium\n",
        "            'quality_enhancement': True,\n",
        "            'color_correction': True,\n",
        "            'sharpening': True,\n",
        "            'noise_reduction': True,\n",
        "            'contrast_optimization': True\n",
        "        }\n",
        "\n",
        "    def setup_upscaler(self) -> bool:\n",
        "        \"\"\"\n",
        "        Configura modelo de upscaling (Real-ESRGAN ou alternativo)\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\nüîç CONFIGURANDO SISTEMA DE UPSCALING\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        try:\n",
        "            # Tentar Real-ESRGAN primeiro (melhor qualidade)\n",
        "            try:\n",
        "                from realesrgan import RealESRGANer\n",
        "                from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "\n",
        "                print(\"‚è≥ Carregando Real-ESRGAN...\")\n",
        "\n",
        "                model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "                upsampler = RealESRGANer(\n",
        "                    scale=4,\n",
        "                    model_path='https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth',\n",
        "                    model=model,\n",
        "                    tile=0,\n",
        "                    tile_pad=10,\n",
        "                    pre_pad=0,\n",
        "                    half=True if torch.cuda.is_available() else False,\n",
        "                    gpu_id=0 if torch.cuda.is_available() else None\n",
        "                )\n",
        "\n",
        "                self.upscaler_model = upsampler\n",
        "                print(\"‚úÖ Real-ESRGAN configurado com sucesso\")\n",
        "                return True\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"‚ö†Ô∏è Real-ESRGAN n√£o dispon√≠vel - usando OpenCV upscaling\")\n",
        "\n",
        "                # Fallback para OpenCV Super Resolution\n",
        "                try:\n",
        "                    # Usar EDSR ou ESPCN se dispon√≠vel\n",
        "                    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
        "                    model_path = \"/content/EDSR_x4.pb\"  # Modelo EDSR 4x\n",
        "\n",
        "                    # Se n√£o tiver modelo, usar interpola√ß√£o bic√∫bica avan√ßada\n",
        "                    print(\"üì¶ Configurando upscaling OpenCV...\")\n",
        "                    self.upscaler_model = 'opencv_advanced'\n",
        "                    print(\"‚úÖ OpenCV upscaling configurado\")\n",
        "                    return True\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Erro OpenCV SR: {e} - usando interpola√ß√£o de alta qualidade\")\n",
        "                    self.upscaler_model = 'high_quality_interpolation'\n",
        "                    return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro configurando upscaler: {e}\")\n",
        "            self.upscaler_model = 'basic_interpolation'\n",
        "            return False\n",
        "\n",
        "    def upscale_image(self, image: Image.Image, target_size: Tuple[int, int] = None) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Realiza upscaling da imagem com a melhor qualidade dispon√≠vel\n",
        "        \"\"\"\n",
        "\n",
        "        if target_size is None:\n",
        "            target_size = self.commercial_settings['target_resolution']\n",
        "\n",
        "        original_size = image.size\n",
        "\n",
        "        try:\n",
        "            if self.upscaler_model and hasattr(self.upscaler_model, 'enhance'):\n",
        "                # Real-ESRGAN\n",
        "                img_array = np.array(image)\n",
        "                output, _ = self.upscaler_model.enhance(img_array, outscale=4)\n",
        "                upscaled = Image.fromarray(output)\n",
        "\n",
        "                # Redimensionar para tamanho exato se necess√°rio\n",
        "                if upscaled.size != target_size:\n",
        "                    upscaled = upscaled.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "            elif self.upscaler_model == 'opencv_advanced':\n",
        "                # OpenCV com t√©cnicas avan√ßadas\n",
        "                img_array = np.array(image)\n",
        "\n",
        "                # Aplicar denoising primeiro\n",
        "                denoised = cv2.fastNlMeansDenoisingColored(img_array)\n",
        "\n",
        "                # Upscale com INTER_CUBIC\n",
        "                scale_factor = max(target_size[0] / original_size[0], target_size[1] / original_size[1])\n",
        "                intermediate_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))\n",
        "\n",
        "                upscaled_array = cv2.resize(denoised, intermediate_size, interpolation=cv2.INTER_CUBIC)\n",
        "                upscaled = Image.fromarray(upscaled_array)\n",
        "\n",
        "                # Ajustar para tamanho exato\n",
        "                if upscaled.size != target_size:\n",
        "                    upscaled = upscaled.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "            else:\n",
        "                # Interpola√ß√£o de alta qualidade com m√∫ltiplas etapas\n",
        "                upscaled = image\n",
        "                current_size = original_size\n",
        "\n",
        "                # Upscale gradual para melhor qualidade\n",
        "                while max(current_size) < max(target_size):\n",
        "                    new_size = (min(current_size[0] * 2, target_size[0]),\n",
        "                               min(current_size[1] * 2, target_size[1]))\n",
        "                    upscaled = upscaled.resize(new_size, Image.LANCZOS)\n",
        "                    current_size = new_size\n",
        "\n",
        "                # Ajuste final\n",
        "                if upscaled.size != target_size:\n",
        "                    upscaled = upscaled.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "            return upscaled\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro no upscaling: {e} - usando fallback\")\n",
        "            return image.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "    def enhance_image_quality(self, image: Image.Image) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Aplica melhorias de qualidade comercial na imagem\n",
        "        \"\"\"\n",
        "\n",
        "        enhanced = image.copy()\n",
        "\n",
        "        try:\n",
        "            # 1. Corre√ß√£o de cor e contraste\n",
        "            if self.commercial_settings['color_correction']:\n",
        "                # Ajustar contraste\n",
        "                contrast_enhancer = ImageEnhance.Contrast(enhanced)\n",
        "                enhanced = contrast_enhancer.enhance(1.1)  # 10% mais contraste\n",
        "\n",
        "                # Ajustar satura√ß√£o\n",
        "                color_enhancer = ImageEnhance.Color(enhanced)\n",
        "                enhanced = color_enhancer.enhance(1.05)  # 5% mais satura√ß√£o\n",
        "\n",
        "                # Ajustar brilho se necess√°rio\n",
        "                brightness_enhancer = ImageEnhance.Brightness(enhanced)\n",
        "                enhanced = brightness_enhancer.enhance(1.02)  # 2% mais brilho\n",
        "\n",
        "            # 2. Sharpening sutil\n",
        "            if self.commercial_settings['sharpening']:\n",
        "                sharpness_enhancer = ImageEnhance.Sharpness(enhanced)\n",
        "                enhanced = sharpness_enhancer.enhance(1.1)  # 10% mais nitidez\n",
        "\n",
        "            # 3. Redu√ß√£o de ru√≠do com preserva√ß√£o de detalhes\n",
        "            if self.commercial_settings['noise_reduction']:\n",
        "                # Usar filtro bilateral para reduzir ru√≠do mantendo bordas\n",
        "                img_array = np.array(enhanced)\n",
        "                smoothed = cv2.bilateralFilter(img_array, 9, 75, 75)\n",
        "                enhanced = Image.fromarray(smoothed)\n",
        "\n",
        "            # 4. Otimiza√ß√£o de contraste adaptativo\n",
        "            if self.commercial_settings['contrast_optimization']:\n",
        "                img_array = np.array(enhanced)\n",
        "                lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
        "                lab[:,:,0] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(lab[:,:,0])\n",
        "                enhanced = Image.fromarray(cv2.cvtColor(lab, cv2.COLOR_LAB2RGB))\n",
        "\n",
        "            return enhanced\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro no enhancement: {e}\")\n",
        "            return image\n",
        "\n",
        "    def process_commercial_image(\n",
        "        self,\n",
        "        input_image: Image.Image,\n",
        "        metadata: Dict = None\n",
        "    ) -> Tuple[Image.Image, Dict]:\n",
        "        \"\"\"\n",
        "        Processamento completo para qualidade comercial\n",
        "        \"\"\"\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        processing_metadata = {\n",
        "            'original_size': input_image.size,\n",
        "            'target_size': self.commercial_settings['target_resolution'],\n",
        "            'processing_steps': [],\n",
        "            'quality_metrics': {},\n",
        "            'processing_time': 0\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # 1. Upscaling\n",
        "            print(f\"‚è≥ Upscaling de {input_image.size} para {self.commercial_settings['target_resolution']}\")\n",
        "            upscaled_image = self.upscale_image(input_image, self.commercial_settings['target_resolution'])\n",
        "            processing_metadata['processing_steps'].append('upscaling')\n",
        "            processing_metadata['upscaled_size'] = upscaled_image.size\n",
        "\n",
        "            # 2. Enhancement de qualidade\n",
        "            print(\"‚è≥ Aplicando melhorias de qualidade...\")\n",
        "            enhanced_image = self.enhance_image_quality(upscaled_image)\n",
        "            processing_metadata['processing_steps'].append('quality_enhancement')\n",
        "\n",
        "            # 3. Verifica√ß√µes finais de qualidade\n",
        "            processing_metadata['quality_metrics'] = self.calculate_quality_metrics(\n",
        "                input_image, enhanced_image\n",
        "            )\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            processing_metadata['processing_time'] = processing_time\n",
        "\n",
        "            # Estat√≠sticas\n",
        "            self.processing_stats['images_processed'] += 1\n",
        "            self.processing_stats['processing_times'].append(processing_time)\n",
        "\n",
        "            size_increase = (upscaled_image.size[0] * upscaled_image.size[1]) / (input_image.size[0] * input_image.size[1])\n",
        "            self.processing_stats['size_increases'].append(size_increase)\n",
        "\n",
        "            print(f\"‚úÖ Processamento conclu√≠do ({processing_time:.1f}s)\")\n",
        "\n",
        "            return enhanced_image, processing_metadata\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro no processamento: {e}\")\n",
        "            processing_metadata['error'] = str(e)\n",
        "            return input_image, processing_metadata\n",
        "\n",
        "    def calculate_quality_metrics(self, original: Image.Image, processed: Image.Image) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula m√©tricas de qualidade da imagem processada\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Converter para arrays\n",
        "            orig_array = np.array(original.resize(processed.size, Image.LANCZOS))\n",
        "            proc_array = np.array(processed)\n",
        "\n",
        "            # PSNR (Peak Signal-to-Noise Ratio)\n",
        "            mse = np.mean((orig_array - proc_array) ** 2)\n",
        "            psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else 100\n",
        "\n",
        "            # Sharpness metric\n",
        "            gray_proc = cv2.cvtColor(proc_array, cv2.COLOR_RGB2GRAY)\n",
        "            sharpness = cv2.Laplacian(gray_proc, cv2.CV_64F).var()\n",
        "\n",
        "            # Contrast metric\n",
        "            contrast = gray_proc.std()\n",
        "\n",
        "            return {\n",
        "                'psnr': float(psnr),\n",
        "                'sharpness': float(sharpness),\n",
        "                'contrast': float(contrast),\n",
        "                'resolution_increase': processed.size[0] / original.size[0]\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {'error': str(e)}\n",
        "\n",
        "def setup_commercial_processor() -> CommercialImageProcessor:\n",
        "    \"\"\"\n",
        "    Configura o processador comercial\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüè≠ CONFIGURANDO PROCESSADOR COMERCIAL\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    config = {\n",
        "        'gpu_acceleration': torch.cuda.is_available(),\n",
        "        'quality_mode': 'premium',\n",
        "        'batch_processing': True\n",
        "    }\n",
        "\n",
        "    processor = CommercialImageProcessor(config)\n",
        "\n",
        "    # Configurar upscaler\n",
        "    upscaler_ready = processor.setup_upscaler()\n",
        "\n",
        "    print(f\"üîß PROCESSADOR CONFIGURADO:\")\n",
        "    print(f\"   üñ•Ô∏è GPU: {'‚úÖ' if config['gpu_acceleration'] else '‚ùå'}\")\n",
        "    print(f\"   üìà Upscaler: {'‚úÖ' if upscaler_ready else '‚ùå'}\")\n",
        "    print(f\"   ‚≠ê Modo: {config['quality_mode']}\")\n",
        "    print(f\"   üìê Resolu√ß√£o alvo: {processor.commercial_settings['target_resolution']}\")\n",
        "\n",
        "    return processor\n",
        "\n",
        "# Configurar processador comercial\n",
        "print(\"üöÄ CONFIGURANDO SISTEMA DE P√ìS-PROCESSAMENTO...\")\n",
        "\n",
        "COMMERCIAL_PROCESSOR = setup_commercial_processor()\n",
        "\n",
        "# Teste com imagem aprovada se dispon√≠vel\n",
        "if ('BATCH_MANAGER' in globals() and\n",
        "    hasattr(BATCH_MANAGER, 'approved_dir') and\n",
        "    BATCH_MANAGER.approved_dir.exists()):\n",
        "\n",
        "    approved_images = list(BATCH_MANAGER.approved_dir.glob(\"*.png\"))\n",
        "\n",
        "    if approved_images:\n",
        "        print(f\"\\nüß™ TESTANDO COM IMAGEM APROVADA...\")\n",
        "        test_image_path = approved_images[0]\n",
        "\n",
        "        try:\n",
        "            test_image = Image.open(test_image_path)\n",
        "            processed_image, metadata = COMMERCIAL_PROCESSOR.process_commercial_image(test_image)\n",
        "\n",
        "            print(f\"‚úÖ TESTE CONCLU√çDO:\")\n",
        "            print(f\"   üìê Original: {metadata['original_size']}\")\n",
        "            print(f\"   üìà Processada: {metadata['upscaled_size']}\")\n",
        "            print(f\"   ‚è±Ô∏è Tempo: {metadata['processing_time']:.1f}s\")\n",
        "            print(f\"   üìä PSNR: {metadata['quality_metrics'].get('psnr', 'N/A'):.1f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro no teste: {e}\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 1 CARREGADA: Sistema de upscaling e refinamento configurado\")"
      ],
      "metadata": {
        "id": "JZO71dh5QFpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 2: FASE 6.2 - Sistema de Filtros e Efeitos Comerciais =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 2: Sistema de Filtros e Efeitos Comerciais\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from PIL import ImageOps, ImageDraw, ImageFont\n",
        "import colorsys\n",
        "import random\n",
        "\n",
        "class CommercialFilterSystem:\n",
        "    \"\"\"\n",
        "    Sistema de filtros e efeitos para imagens comerciais\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.filter_presets = {\n",
        "            'premium_warm': {\n",
        "                'temperature': 1.1,\n",
        "                'saturation': 1.05,\n",
        "                'contrast': 1.08,\n",
        "                'brightness': 1.02,\n",
        "                'vignette': 0.1\n",
        "            },\n",
        "            'studio_clean': {\n",
        "                'temperature': 1.0,\n",
        "                'saturation': 1.1,\n",
        "                'contrast': 1.15,\n",
        "                'brightness': 1.05,\n",
        "                'sharpness': 1.1\n",
        "            },\n",
        "            'glamour_soft': {\n",
        "                'temperature': 1.05,\n",
        "                'saturation': 0.95,\n",
        "                'contrast': 1.05,\n",
        "                'brightness': 1.08,\n",
        "                'blur_radius': 0.5,\n",
        "                'glow_effect': 0.3\n",
        "            },\n",
        "            'commercial_crisp': {\n",
        "                'temperature': 0.98,\n",
        "                'saturation': 1.08,\n",
        "                'contrast': 1.12,\n",
        "                'brightness': 1.03,\n",
        "                'sharpness': 1.15,\n",
        "                'clarity': 1.1\n",
        "            },\n",
        "            'premium_cool': {\n",
        "                'temperature': 0.95,\n",
        "                'saturation': 1.12,\n",
        "                'contrast': 1.1,\n",
        "                'brightness': 1.02,\n",
        "                'highlights': 1.05\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.commercial_looks = [\n",
        "            'premium_warm',\n",
        "            'studio_clean',\n",
        "            'commercial_crisp'\n",
        "        ]\n",
        "\n",
        "    def apply_temperature_adjustment(self, image: Image.Image, temperature: float) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Ajusta temperatura de cor da imagem\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            img_array = np.array(image)\n",
        "\n",
        "            if temperature > 1.0:\n",
        "                # Mais quente (mais amarelo/vermelho)\n",
        "                factor = (temperature - 1.0) * 0.3\n",
        "                img_array[:,:,0] = np.clip(img_array[:,:,0] * (1 + factor), 0, 255)  # R\n",
        "                img_array[:,:,1] = np.clip(img_array[:,:,1] * (1 + factor * 0.5), 0, 255)  # G\n",
        "            else:\n",
        "                # Mais frio (mais azul)\n",
        "                factor = (1.0 - temperature) * 0.3\n",
        "                img_array[:,:,2] = np.clip(img_array[:,:,2] * (1 + factor), 0, 255)  # B\n",
        "                img_array[:,:,1] = np.clip(img_array[:,:,1] * (1 + factor * 0.5), 0, 255)  # G\n",
        "\n",
        "            return Image.fromarray(img_array.astype(np.uint8))\n",
        "\n",
        "        except Exception:\n",
        "            return image\n",
        "\n",
        "    def apply_vignette(self, image: Image.Image, strength: float) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Aplica efeito vinheta sutil\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            width, height = image.size\n",
        "\n",
        "            # Criar m√°scara de vinheta\n",
        "            vignette = Image.new('L', (width, height), 255)\n",
        "            draw = ImageDraw.Draw(vignette)\n",
        "\n",
        "            # Gradiente radial\n",
        "            center_x, center_y = width // 2, height // 2\n",
        "            max_radius = min(width, height) // 2\n",
        "\n",
        "            for radius in range(max_radius, 0, -5):\n",
        "                alpha = int(255 * (1 - strength * (max_radius - radius) / max_radius))\n",
        "                alpha = max(0, min(255, alpha))\n",
        "\n",
        "                bbox = [\n",
        "                    center_x - radius, center_y - radius,\n",
        "                    center_x + radius, center_y + radius\n",
        "                ]\n",
        "                draw.ellipse(bbox, fill=alpha)\n",
        "\n",
        "            # Aplicar vinheta\n",
        "            vignette_rgba = vignette.convert('RGBA')\n",
        "            image_rgba = image.convert('RGBA')\n",
        "\n",
        "            result = Image.alpha_composite(image_rgba, vignette_rgba)\n",
        "            return result.convert('RGB')\n",
        "\n",
        "        except Exception:\n",
        "            return image\n",
        "\n",
        "    def apply_glow_effect(self, image: Image.Image, strength: float) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Aplica efeito glow suave\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Criar vers√£o borrada da imagem\n",
        "            blurred = image.filter(ImageFilter.GaussianBlur(radius=10))\n",
        "\n",
        "            # Converter para RGBA para blending\n",
        "            original_rgba = image.convert('RGBA')\n",
        "            blurred_rgba = blurred.convert('RGBA')\n",
        "\n",
        "            # Aplicar alpha no glow\n",
        "            alpha = int(strength * 255)\n",
        "            glow_layer = Image.new('RGBA', image.size, (255, 255, 255, alpha))\n",
        "\n",
        "            # Composite das camadas\n",
        "            result = Image.alpha_composite(original_rgba, blurred_rgba)\n",
        "            result = Image.alpha_composite(result, glow_layer)\n",
        "\n",
        "            return result.convert('RGB')\n",
        "\n",
        "        except Exception:\n",
        "            return image\n",
        "\n",
        "    def apply_commercial_filter(self, image: Image.Image, filter_name: str) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Aplica filtro comercial completo\n",
        "        \"\"\"\n",
        "\n",
        "        if filter_name not in self.filter_presets:\n",
        "            return image\n",
        "\n",
        "        preset = self.filter_presets[filter_name]\n",
        "        processed = image.copy()\n",
        "\n",
        "        try:\n",
        "            # Ajuste de temperatura\n",
        "            if 'temperature' in preset:\n",
        "                processed = self.apply_temperature_adjustment(processed, preset['temperature'])\n",
        "\n",
        "            # Ajustes b√°sicos usando PIL\n",
        "            if 'brightness' in preset:\n",
        "                enhancer = ImageEnhance.Brightness(processed)\n",
        "                processed = enhancer.enhance(preset['brightness'])\n",
        "\n",
        "            if 'contrast' in preset:\n",
        "                enhancer = ImageEnhance.Contrast(processed)\n",
        "                processed = enhancer.enhance(preset['contrast'])\n",
        "\n",
        "            if 'saturation' in preset:\n",
        "                enhancer = ImageEnhance.Color(processed)\n",
        "                processed = enhancer.enhance(preset['saturation'])\n",
        "\n",
        "            if 'sharpness' in preset:\n",
        "                enhancer = ImageEnhance.Sharpness(processed)\n",
        "                processed = enhancer.enhance(preset['sharpness'])\n",
        "\n",
        "            # Efeitos especiais\n",
        "            if 'vignette' in preset:\n",
        "                processed = self.apply_vignette(processed, preset['vignette'])\n",
        "\n",
        "            if 'glow_effect' in preset:\n",
        "                processed = self.apply_glow_effect(processed, preset['glow_effect'])\n",
        "\n",
        "            # Blur suave se especificado\n",
        "            if 'blur_radius' in preset:\n",
        "                processed = processed.filter(ImageFilter.GaussianBlur(radius=preset['blur_radius']))\n",
        "\n",
        "            return processed\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro aplicando filtro {filter_name}: {e}\")\n",
        "            return image\n",
        "\n",
        "    def create_commercial_variations(self, image: Image.Image) -> Dict[str, Image.Image]:\n",
        "        \"\"\"\n",
        "        Cria varia√ß√µes comerciais da imagem\n",
        "        \"\"\"\n",
        "\n",
        "        variations = {}\n",
        "\n",
        "        print(f\"üé® Criando varia√ß√µes comerciais...\")\n",
        "\n",
        "        # Aplicar filtros comerciais principais\n",
        "        for filter_name in self.commercial_looks:\n",
        "            try:\n",
        "                filtered_image = self.apply_commercial_filter(image, filter_name)\n",
        "                variations[filter_name] = filtered_image\n",
        "                print(f\"   ‚úÖ {filter_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå {filter_name}: {e}\")\n",
        "\n",
        "        # Varia√ß√£o original otimizada (sem filtro pesado)\n",
        "        variations['original_optimized'] = image\n",
        "\n",
        "        return variations\n",
        "\n",
        "class CommercialCropGenerator:\n",
        "    \"\"\"\n",
        "    Gerador de crops comerciais otimizados\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Aspectos comerciais populares\n",
        "        self.commercial_aspects = {\n",
        "            'square_1080': (1080, 1080),      # Instagram posts\n",
        "            'square_1200': (1200, 1200),      # Premium square\n",
        "            'portrait_9_16': (1080, 1920),    # Instagram Stories/TikTok\n",
        "            'portrait_4_5': (1080, 1350),     # Instagram feed portrait\n",
        "            'landscape_16_9': (1920, 1080),   # YouTube thumbnails\n",
        "            'ultra_wide': (2560, 1080),       # Ultra-wide wallpapers\n",
        "            'phone_wallpaper': (1125, 2436),  # iPhone wallpaper\n",
        "            'desktop_fhd': (1920, 1080),      # Desktop wallpaper\n",
        "            'commercial_print': (2400, 3000)   # Print comercial\n",
        "        }\n",
        "\n",
        "        self.priority_crops = [\n",
        "            'square_1200',\n",
        "            'portrait_9_16',\n",
        "            'portrait_4_5',\n",
        "            'landscape_16_9'\n",
        "        ]\n",
        "\n",
        "    def detect_face_region(self, image: Image.Image) -> Optional[Tuple[int, int, int, int]]:\n",
        "        \"\"\"\n",
        "        Detecta regi√£o da face para crop inteligente\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            if 'VALIDATION_SYSTEM' in globals():\n",
        "                img_array = np.array(image)\n",
        "\n",
        "                if 'insightface' in VALIDATION_SYSTEM['available_methods']:\n",
        "                    faces = VALIDATION_SYSTEM['face_detector'].get(img_array)\n",
        "                    if faces:\n",
        "                        face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])\n",
        "                        return tuple(map(int, face.bbox))\n",
        "\n",
        "                # Fallback OpenCV\n",
        "                elif 'opencv_detector' in VALIDATION_SYSTEM:\n",
        "                    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "                    faces = VALIDATION_SYSTEM['opencv_detector'].detectMultiScale(gray, 1.1, 5)\n",
        "                    if len(faces) > 0:\n",
        "                        return tuple(faces[0])\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def generate_smart_crop(\n",
        "        self,\n",
        "        image: Image.Image,\n",
        "        target_size: Tuple[int, int],\n",
        "        crop_name: str\n",
        "    ) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Gera crop inteligente focado na face\n",
        "        \"\"\"\n",
        "\n",
        "        width, height = image.size\n",
        "        target_width, target_height = target_size\n",
        "        target_aspect = target_width / target_height\n",
        "        source_aspect = width / height\n",
        "\n",
        "        try:\n",
        "            # Detectar face para crop inteligente\n",
        "            face_bbox = self.detect_face_region(image)\n",
        "\n",
        "            if face_bbox:\n",
        "                fx, fy, fw, fh = face_bbox\n",
        "                face_center_x = fx + fw // 2\n",
        "                face_center_y = fy + fh // 2\n",
        "\n",
        "                # Calcular √°rea de crop baseada na face\n",
        "                if target_aspect > source_aspect:\n",
        "                    # Crop ser√° mais largo - usar toda largura\n",
        "                    crop_width = width\n",
        "                    crop_height = int(width / target_aspect)\n",
        "                else:\n",
        "                    # Crop ser√° mais alto - usar toda altura\n",
        "                    crop_height = height\n",
        "                    crop_width = int(height * target_aspect)\n",
        "\n",
        "                # Centralizar no rosto\n",
        "                crop_left = max(0, min(face_center_x - crop_width // 2, width - crop_width))\n",
        "                crop_top = max(0, min(face_center_y - crop_height // 2, height - crop_height))\n",
        "\n",
        "                # Ajustar para crops espec√≠ficos\n",
        "                if 'portrait' in crop_name:\n",
        "                    # Para retratos, manter face no ter√ßo superior\n",
        "                    crop_top = max(0, min(face_center_y - crop_height // 3, height - crop_height))\n",
        "\n",
        "                crop_box = (crop_left, crop_top, crop_left + crop_width, crop_top + crop_height)\n",
        "\n",
        "            else:\n",
        "                # Crop central se n√£o detectar face\n",
        "                if target_aspect > source_aspect:\n",
        "                    crop_width = width\n",
        "                    crop_height = int(width / target_aspect)\n",
        "                    crop_left = 0\n",
        "                    crop_top = (height - crop_height) // 2\n",
        "                else:\n",
        "                    crop_height = height\n",
        "                    crop_width = int(height * target_aspect)\n",
        "                    crop_left = (width - crop_width) // 2\n",
        "                    crop_top = 0\n",
        "\n",
        "                crop_box = (crop_left, crop_top, crop_left + crop_width, crop_top + crop_height)\n",
        "\n",
        "            # Executar crop\n",
        "            cropped = image.crop(crop_box)\n",
        "\n",
        "            # Redimensionar para tamanho exato\n",
        "            final_image = cropped.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "            return final_image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro no crop {crop_name}: {e}\")\n",
        "            return image.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "    def generate_commercial_crops(self, image: Image.Image) -> Dict[str, Image.Image]:\n",
        "        \"\"\"\n",
        "        Gera todos os crops comerciais da imagem\n",
        "        \"\"\"\n",
        "\n",
        "        crops = {}\n",
        "\n",
        "        print(f\"‚úÇÔ∏è Gerando crops comerciais...\")\n",
        "\n",
        "        # Crops priorit√°rios\n",
        "        for crop_name in self.priority_crops:\n",
        "            target_size = self.commercial_aspects[crop_name]\n",
        "            cropped_image = self.generate_smart_crop(image, target_size, crop_name)\n",
        "            crops[crop_name] = cropped_image\n",
        "            print(f\"   ‚úÖ {crop_name}: {target_size}\")\n",
        "\n",
        "        return crops\n",
        "\n",
        "# Inicializar sistemas\n",
        "print(\"üöÄ CONFIGURANDO SISTEMAS DE FILTROS E CROPS...\")\n",
        "\n",
        "FILTER_SYSTEM = CommercialFilterSystem()\n",
        "CROP_GENERATOR = CommercialCropGenerator()\n",
        "\n",
        "print(f\"üé® FILTROS DISPON√çVEIS: {len(FILTER_SYSTEM.filter_presets)}\")\n",
        "print(f\"‚úÇÔ∏è CROPS COMERCIAIS: {len(CROP_GENERATOR.commercial_aspects)}\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 2 CARREGADA: Sistema de filtros e crops comerciais configurado\")"
      ],
      "metadata": {
        "id": "D1CBpUILQGPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 3: FASE 6.3 - Sistema de Watermarking e Prote√ß√£o =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 3: Sistema de Watermarking e Prote√ß√£o\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from PIL import ImageDraw, ImageFont\n",
        "import hashlib\n",
        "import base64\n",
        "\n",
        "class CommercialProtectionSystem:\n",
        "    \"\"\"\n",
        "    Sistema de prote√ß√£o e watermarking para imagens comerciais\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, brand_name: str = \"Valentina Moreau\"):\n",
        "        self.brand_name = brand_name\n",
        "        self.watermark_styles = {\n",
        "            'subtle_corner': {\n",
        "                'position': 'bottom_right',\n",
        "                'opacity': 0.3,\n",
        "                'size_ratio': 0.03,\n",
        "                'margin': 20\n",
        "            },\n",
        "            'discrete_bottom': {\n",
        "                'position': 'bottom_center',\n",
        "                'opacity': 0.4,\n",
        "                'size_ratio': 0.025,\n",
        "                'margin': 15\n",
        "            },\n",
        "            'premium_corner': {\n",
        "                'position': 'bottom_right',\n",
        "                'opacity': 0.5,\n",
        "                'size_ratio': 0.035,\n",
        "                'margin': 25,\n",
        "                'style': 'elegant'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.protection_levels = {\n",
        "            'preview': 'subtle_corner',      # Para previews\n",
        "            'commercial': 'discrete_bottom', # Para vendas\n",
        "            'premium': 'premium_corner'      # Para conte√∫do premium\n",
        "        }\n",
        "\n",
        "    def create_text_watermark(\n",
        "        self,\n",
        "        image: Image.Image,\n",
        "        text: str,\n",
        "        style: Dict\n",
        "    ) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Cria watermark de texto na imagem\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Fazer c√≥pia da imagem\n",
        "            watermarked = image.copy()\n",
        "            width, height = watermarked.size\n",
        "\n",
        "            # Criar layer transparente para watermark\n",
        "            watermark_layer = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
        "            draw = ImageDraw.Draw(watermark_layer)\n",
        "\n",
        "            # Calcular tamanho da fonte\n",
        "            font_size = int(min(width, height) * style['size_ratio'])\n",
        "\n",
        "            try:\n",
        "                # Tentar usar fonte do sistema\n",
        "                font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "            except:\n",
        "                try:\n",
        "                    font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", font_size)\n",
        "                except:\n",
        "                    font = ImageFont.load_default()\n",
        "\n",
        "            # Obter dimens√µes do texto\n",
        "            text_bbox = draw.textbbox((0, 0), text, font=font)\n",
        "            text_width = text_bbox[2] - text_bbox[0]\n",
        "            text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "            # Calcular posi√ß√£o\n",
        "            margin = style['margin']\n",
        "\n",
        "            if style['position'] == 'bottom_right':\n",
        "                x = width - text_width - margin\n",
        "                y = height - text_height - margin\n",
        "            elif style['position'] == 'bottom_left':\n",
        "                x = margin\n",
        "                y = height - text_height - margin\n",
        "            elif style['position'] == 'bottom_center':\n",
        "                x = (width - text_width) // 2\n",
        "                y = height - text_height - margin\n",
        "            elif style['position'] == 'top_right':\n",
        "                x = width - text_width - margin\n",
        "                y = margin\n",
        "            else:\n",
        "                x = margin\n",
        "                y = margin\n",
        "\n",
        "            # Cor e opacidade\n",
        "            opacity = int(style['opacity'] * 255)\n",
        "            text_color = (255, 255, 255, opacity)  # Branco semi-transparente\n",
        "\n",
        "            # Adicionar sombra sutil\n",
        "            shadow_color = (0, 0, 0, opacity // 2)\n",
        "            draw.text((x + 1, y + 1), text, font=font, fill=shadow_color)\n",
        "\n",
        "            # Texto principal\n",
        "            draw.text((x, y), text, font=font, fill=text_color)\n",
        "\n",
        "            # Aplicar watermark\n",
        "            watermarked = watermarked.convert('RGBA')\n",
        "            watermarked = Image.alpha_composite(watermarked, watermark_layer)\n",
        "\n",
        "            return watermarked.convert('RGB')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro criando watermark: {e}\")\n",
        "            return image\n",
        "\n",
        "    def create_logo_watermark(\n",
        "        self,\n",
        "        image: Image.Image,\n",
        "        logo_text: str,\n",
        "        style: Dict\n",
        "    ) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Cria watermark estilo logo elegante\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            watermarked = image.copy()\n",
        "            width, height = watermarked.size\n",
        "\n",
        "            # Layer para logo\n",
        "            logo_layer = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
        "            draw = ImageDraw.Draw(logo_layer)\n",
        "\n",
        "            # Fonte maior para logo\n",
        "            font_size = int(min(width, height) * style['size_ratio'] * 1.5)\n",
        "\n",
        "            try:\n",
        "                font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "            except:\n",
        "                font = ImageFont.load_default()\n",
        "\n",
        "            # Posi√ß√£o\n",
        "            margin = style['margin']\n",
        "            text_bbox = draw.textbbox((0, 0), logo_text, font=font)\n",
        "            text_width = text_bbox[2] - text_bbox[0]\n",
        "            text_height = text_bbox[3] - text_bbox[1]\n",
        "\n",
        "            x = width - text_width - margin\n",
        "            y = height - text_height - margin\n",
        "\n",
        "            # Estilo elegante com background\n",
        "            if style.get('style') == 'elegant':\n",
        "                # Background semi-transparente\n",
        "                bg_padding = 10\n",
        "                bg_color = (0, 0, 0, int(style['opacity'] * 100))\n",
        "                bg_bbox = (\n",
        "                    x - bg_padding,\n",
        "                    y - bg_padding,\n",
        "                    x + text_width + bg_padding,\n",
        "                    y + text_height + bg_padding\n",
        "                )\n",
        "                draw.rectangle(bg_bbox, fill=bg_color)\n",
        "\n",
        "            # Texto do logo\n",
        "            opacity = int(style['opacity'] * 255)\n",
        "            text_color = (255, 255, 255, opacity)\n",
        "            draw.text((x, y), logo_text, font=font, fill=text_color)\n",
        "\n",
        "            # Aplicar\n",
        "            watermarked = watermarked.convert('RGBA')\n",
        "            watermarked = Image.alpha_composite(watermarked, logo_layer)\n",
        "\n",
        "            return watermarked.convert('RGB')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro criando logo watermark: {e}\")\n",
        "            return image\n",
        "\n",
        "    def apply_protection(\n",
        "        self,\n",
        "        image: Image.Image,\n",
        "        protection_level: str = 'commercial'\n",
        "    ) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Aplica prote√ß√£o baseada no n√≠vel especificado\n",
        "        \"\"\"\n",
        "\n",
        "        if protection_level not in self.protection_levels:\n",
        "            protection_level = 'commercial'\n",
        "\n",
        "        style_name = self.protection_levels[protection_level]\n",
        "        style = self.watermark_styles[style_name]\n",
        "\n",
        "        # Texto do watermark baseado no n√≠vel\n",
        "        if protection_level == 'premium':\n",
        "            watermark_text = f\"¬© {self.brand_name}\"\n",
        "            return self.create_logo_watermark(image, watermark_text, style)\n",
        "        else:\n",
        "            watermark_text = self.brand_name\n",
        "            return self.create_text_watermark(image, watermark_text, style)\n",
        "\n",
        "    def generate_image_hash(self, image: Image.Image) -> str:\n",
        "        \"\"\"\n",
        "        Gera hash √∫nico da imagem para identifica√ß√£o\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Converter para bytes\n",
        "            img_bytes = image.tobytes()\n",
        "\n",
        "            # Gerar hash SHA-256\n",
        "            hash_object = hashlib.sha256(img_bytes)\n",
        "            hex_hash = hash_object.hexdigest()\n",
        "\n",
        "            # Retornar vers√£o curta\n",
        "            return hex_hash[:16]\n",
        "\n",
        "        except Exception:\n",
        "            return hashlib.md5(str(datetime.now()).encode()).hexdigest()[:16]\n",
        "\n",
        "    def create_metadata_protection(self, image: Image.Image, metadata: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Cria metadados de prote√ß√£o para a imagem\n",
        "        \"\"\"\n",
        "\n",
        "        protection_metadata = {\n",
        "            'image_hash': self.generate_image_hash(image),\n",
        "            'brand': self.brand_name,\n",
        "            'copyright': f\"¬© {datetime.now().year} {self.brand_name}\",\n",
        "            'usage_rights': 'Commercial use authorized',\n",
        "            'creation_timestamp': datetime.now().isoformat(),\n",
        "            'protection_level': 'commercial',\n",
        "            'watermarked': True\n",
        "        }\n",
        "\n",
        "        # Combinar com metadados existentes\n",
        "        if metadata:\n",
        "            protection_metadata.update(metadata)\n",
        "\n",
        "        return protection_metadata\n",
        "\n",
        "class CommercialMetadataManager:\n",
        "    \"\"\"\n",
        "    Gerenciador de metadados comerciais\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, brand_info: Dict):\n",
        "        self.brand_info = brand_info\n",
        "\n",
        "    def create_commercial_metadata(\n",
        "        self,\n",
        "        image: Image.Image,\n",
        "        processing_data: Dict,\n",
        "        variation_info: Dict = None\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Cria metadados comerciais completos\n",
        "        \"\"\"\n",
        "\n",
        "        metadata = {\n",
        "            'valentina_commercial_v4': True,\n",
        "            'brand_info': self.brand_info,\n",
        "            'image_specifications': {\n",
        "                'resolution': image.size,\n",
        "                'format': 'PNG',\n",
        "                'color_mode': image.mode,\n",
        "                'file_size_estimate': len(image.tobytes()),\n",
        "                'commercial_ready': True\n",
        "            },\n",
        "            'processing_pipeline': {\n",
        "                'upscaled': True,\n",
        "                'enhanced': True,\n",
        "                'filtered': variation_info is not None,\n",
        "                'watermarked': True,\n",
        "                'processing_time': processing_data.get('processing_time', 0)\n",
        "            },\n",
        "            'commercial_usage': {\n",
        "                'platforms': ['TopFans', 'OnlyFans', 'Instagram', 'Premium Content'],\n",
        "                'quality_grade': 'premium',\n",
        "                'monetization_ready': True,\n",
        "                'rights_cleared': True\n",
        "            },\n",
        "            'technical_details': {\n",
        "                'generation_model': 'FLUX.1-dev',\n",
        "                'controlnet': SELECTED_CONTROLNET['name'] if 'SELECTED_CONTROLNET' in globals() else 'N/A',\n",
        "                'post_processing': 'commercial_grade',\n",
        "                'validation_passed': True\n",
        "            },\n",
        "            'creation_info': {\n",
        "                'created_at': datetime.now().isoformat(),\n",
        "                'version': '4.0',\n",
        "                'pipeline': 'commercial_automated'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Adicionar informa√ß√µes de varia√ß√£o se dispon√≠vel\n",
        "        if variation_info:\n",
        "            metadata['variation_info'] = variation_info\n",
        "\n",
        "        return metadata\n",
        "\n",
        "# Configurar sistema de prote√ß√£o\n",
        "print(\"üöÄ CONFIGURANDO SISTEMA DE PROTE√á√ÉO...\")\n",
        "\n",
        "PROTECTION_SYSTEM = CommercialProtectionSystem(\"Valentina Moreau\")\n",
        "\n",
        "# Informa√ß√µes da marca\n",
        "BRAND_INFO = {\n",
        "    'name': 'Valentina Moreau',\n",
        "    'type': 'Digital Model',\n",
        "    'category': 'Premium Content Creator',\n",
        "    'platforms': ['TopFans', 'OnlyFans'],\n",
        "    'content_type': 'Adult Content',\n",
        "    'quality_standard': 'Commercial Premium'\n",
        "}\n",
        "\n",
        "METADATA_MANAGER = CommercialMetadataManager(BRAND_INFO)\n",
        "\n",
        "print(f\"üõ°Ô∏è PROTE√á√ÉO CONFIGURADA:\")\n",
        "print(f\"   üìõ Marca: {PROTECTION_SYSTEM.brand_name}\")\n",
        "print(f\"   üé® Estilos dispon√≠veis: {len(PROTECTION_SYSTEM.watermark_styles)}\")\n",
        "print(f\"   üîí N√≠veis de prote√ß√£o: {len(PROTECTION_SYSTEM.protection_levels)}\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 3 CARREGADA: Sistema de watermarking e prote√ß√£o configurado\")"
      ],
      "metadata": {
        "id": "BPSfkvz2QIZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 4: FASE 6.4 - Pipeline Completo de P√≥s-Processamento =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 4: Pipeline Completo de P√≥s-Processamento\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import multiprocessing as mp\n",
        "\n",
        "class CommercialPostProcessingPipeline:\n",
        "    \"\"\"\n",
        "    Pipeline completo de p√≥s-processamento comercial\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_base_dir: str):\n",
        "        self.output_base_dir = Path(output_base_dir)\n",
        "        self.processed_dir = self.output_base_dir / \"processed_commercial\"\n",
        "        self.variations_dir = self.processed_dir / \"variations\"\n",
        "        self.crops_dir = self.processed_dir / \"crops\"\n",
        "        self.originals_dir = self.processed_dir / \"originals_enhanced\"\n",
        "        self.metadata_dir = self.processed_dir / \"metadata\"\n",
        "\n",
        "        # Criar estrutura de diret√≥rios\n",
        "        for dir_path in [self.processed_dir, self.variations_dir, self.crops_dir,\n",
        "                        self.originals_dir, self.metadata_dir]:\n",
        "            dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Estat√≠sticas de processamento\n",
        "        self.processing_stats = {\n",
        "            'images_processed': 0,\n",
        "            'variations_created': 0,\n",
        "            'crops_created': 0,\n",
        "            'total_processing_time': 0,\n",
        "            'average_processing_time': 0,\n",
        "            'files_created': 0\n",
        "        }\n",
        "\n",
        "    def process_single_image_complete(\n",
        "        self,\n",
        "        input_image_path: str,\n",
        "        image_metadata: Dict = None\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Processamento completo de uma √∫nica imagem\n",
        "        \"\"\"\n",
        "\n",
        "        start_time = time.time()\n",
        "        image_path = Path(input_image_path)\n",
        "        base_name = image_path.stem\n",
        "\n",
        "        result = {\n",
        "            'input_path': str(input_image_path),\n",
        "            'base_name': base_name,\n",
        "            'processing_time': 0,\n",
        "            'files_created': [],\n",
        "            'variations': {},\n",
        "            'crops': {},\n",
        "            'metadata_files': [],\n",
        "            'success': False,\n",
        "            'errors': []\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nüé® PROCESSANDO: {base_name}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # 1. Carregar imagem original\n",
        "            original_image = Image.open(input_image_path)\n",
        "\n",
        "            # 2. Upscaling e enhancement\n",
        "            print(\"üîç Fase 1: Upscaling e enhancement...\")\n",
        "            enhanced_image, processing_metadata = COMMERCIAL_PROCESSOR.process_commercial_image(\n",
        "                original_image, image_metadata\n",
        "            )\n",
        "\n",
        "            # 3. Salvar original enhanced\n",
        "            enhanced_path = self.originals_dir / f\"{base_name}_enhanced.png\"\n",
        "            enhanced_image.save(enhanced_path, \"PNG\", optimize=True)\n",
        "            result['files_created'].append(str(enhanced_path))\n",
        "\n",
        "            # 4. Aplicar prote√ß√£o na vers√£o enhanced\n",
        "            print(\"üõ°Ô∏è Fase 2: Aplicando prote√ß√£o...\")\n",
        "            protected_enhanced = PROTECTION_SYSTEM.apply_protection(\n",
        "                enhanced_image, 'commercial'\n",
        "            )\n",
        "\n",
        "            protected_path = self.originals_dir / f\"{base_name}_enhanced_protected.png\"\n",
        "            protected_enhanced.save(protected_path, \"PNG\", optimize=True)\n",
        "            result['files_created'].append(str(protected_path))\n",
        "\n",
        "            # 5. Criar varia√ß√µes com filtros\n",
        "            print(\"üé® Fase 3: Criando varia√ß√µes...\")\n",
        "            variations = FILTER_SYSTEM.create_commercial_variations(enhanced_image)\n",
        "\n",
        "            for variation_name, variation_image in variations.items():\n",
        "                # Aplicar prote√ß√£o na varia√ß√£o\n",
        "                protected_variation = PROTECTION_SYSTEM.apply_protection(\n",
        "                    variation_image, 'commercial'\n",
        "                )\n",
        "\n",
        "                variation_path = self.variations_dir / f\"{base_name}_{variation_name}.png\"\n",
        "                protected_variation.save(variation_path, \"PNG\", optimize=True)\n",
        "\n",
        "                result['variations'][variation_name] = str(variation_path)\n",
        "                result['files_created'].append(str(variation_path))\n",
        "\n",
        "                # Metadados da varia√ß√£o\n",
        "                variation_metadata = METADATA_MANAGER.create_commercial_metadata(\n",
        "                    protected_variation,\n",
        "                    processing_metadata,\n",
        "                    {'filter_applied': variation_name, 'protected': True}\n",
        "                )\n",
        "\n",
        "                metadata_path = self.metadata_dir / f\"{base_name}_{variation_name}_metadata.json\"\n",
        "                with open(metadata_path, 'w') as f:\n",
        "                    json.dump(variation_metadata, f, indent=2, default=str)\n",
        "\n",
        "                result['metadata_files'].append(str(metadata_path))\n",
        "\n",
        "            # 6. Criar crops comerciais\n",
        "            print(\"‚úÇÔ∏è Fase 4: Gerando crops comerciais...\")\n",
        "            crops = CROP_GENERATOR.generate_commercial_crops(enhanced_image)\n",
        "\n",
        "            for crop_name, cropped_image in crops.items():\n",
        "                # Aplicar prote√ß√£o no crop\n",
        "                protected_crop = PROTECTION_SYSTEM.apply_protection(\n",
        "                    cropped_image, 'commercial'\n",
        "                )\n",
        "\n",
        "                crop_path = self.crops_dir / f\"{base_name}_{crop_name}.png\"\n",
        "                protected_crop.save(crop_path, \"PNG\", optimize=True)\n",
        "\n",
        "                result['crops'][crop_name] = str(crop_path)\n",
        "                result['files_created'].append(str(crop_path))\n",
        "\n",
        "                # Metadados do crop\n",
        "                crop_metadata = METADATA_MANAGER.create_commercial_metadata(\n",
        "                    protected_crop,\n",
        "                    processing_metadata,\n",
        "                    {'crop_type': crop_name, 'target_size': protected_crop.size, 'protected': True}\n",
        "                )\n",
        "\n",
        "                metadata_path = self.metadata_dir / f\"{base_name}_{crop_name}_metadata.json\"\n",
        "                with open(metadata_path, 'w') as f:\n",
        "                    json.dump(crop_metadata, f, indent=2, default=str)\n",
        "\n",
        "                result['metadata_files'].append(str(metadata_path))\n",
        "\n",
        "            # 7. Metadados principais\n",
        "            main_metadata = METADATA_MANAGER.create_commercial_metadata(\n",
        "                protected_enhanced,\n",
        "                processing_metadata,\n",
        "                {'main_image': True, 'variations_count': len(variations), 'crops_count': len(crops)}\n",
        "            )\n",
        "\n",
        "            main_metadata_path = self.metadata_dir / f\"{base_name}_main_metadata.json\"\n",
        "            with open(main_metadata_path, 'w') as f:\n",
        "                json.dump(main_metadata, f, indent=2, default=str)\n",
        "\n",
        "            result['metadata_files'].append(str(main_metadata_path))\n",
        "\n",
        "            # Finalizar resultado\n",
        "            processing_time = time.time() - start_time\n",
        "            result['processing_time'] = processing_time\n",
        "            result['success'] = True\n",
        "\n",
        "            # Estat√≠sticas\n",
        "            self.processing_stats['images_processed'] += 1\n",
        "            self.processing_stats['variations_created'] += len(variations)\n",
        "            self.processing_stats['crops_created'] += len(crops)\n",
        "            self.processing_stats['total_processing_time'] += processing_time\n",
        "            self.processing_stats['files_created'] += len(result['files_created'])\n",
        "\n",
        "            print(f\"‚úÖ PROCESSAMENTO CONCLU√çDO ({processing_time:.1f}s)\")\n",
        "            print(f\"   üìÅ Arquivos criados: {len(result['files_created'])}\")\n",
        "            print(f\"   üé® Varia√ß√µes: {len(variations)}\")\n",
        "            print(f\"   ‚úÇÔ∏è Crops: {len(crops)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Erro processando {base_name}: {str(e)}\"\n",
        "            result['errors'].append(error_msg)\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def process_batch_parallel(\n",
        "        self,\n",
        "        image_paths: List[str],\n",
        "        max_workers: int = None\n",
        "    ) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Processamento paralelo de lote de imagens\n",
        "        \"\"\"\n",
        "\n",
        "        if max_workers is None:\n",
        "            max_workers = min(mp.cpu_count() // 2, 4)  # N√£o sobrecarregar\n",
        "\n",
        "        print(f\"\\nüîÑ PROCESSAMENTO PARALELO DE {len(image_paths)} IMAGENS\")\n",
        "        print(f\"üë• Workers: {max_workers}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            # Submeter todas as tarefas\n",
        "            future_to_path = {\n",
        "                executor.submit(self.process_single_image_complete, path): path\n",
        "                for path in image_paths\n",
        "            }\n",
        "\n",
        "            # Coletar resultados\n",
        "            for i, future in enumerate(future_to_path, 1):\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "\n",
        "                    # Progress update\n",
        "                    progress = i / len(image_paths) * 100\n",
        "                    print(f\"üìä Progresso: {progress:.1f}% ({i}/{len(image_paths)})\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    error_result = {\n",
        "                        'input_path': future_to_path[future],\n",
        "                        'success': False,\n",
        "                        'errors': [str(e)]\n",
        "                    }\n",
        "                    results.append(error_result)\n",
        "                    print(f\"‚ùå Erro: {e}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_processing_report(self, results: List[Dict]) -> Dict:\n",
        "        \"\"\"\n",
        "        Gera relat√≥rio completo do processamento\n",
        "        \"\"\"\n",
        "\n",
        "        # Calcular estat√≠sticas\n",
        "        successful = [r for r in results if r['success']]\n",
        "        failed = [r for r in results if not r['success']]\n",
        "\n",
        "        total_files = sum(len(r.get('files_created', [])) for r in successful)\n",
        "        total_variations = sum(len(r.get('variations', {})) for r in successful)\n",
        "        total_crops = sum(len(r.get('crops', {})) for r in successful)\n",
        "\n",
        "        # Atualizar estat√≠sticas\n",
        "        if self.processing_stats['images_processed'] > 0:\n",
        "            self.processing_stats['average_processing_time'] = (\n",
        "                self.processing_stats['total_processing_time'] /\n",
        "                self.processing_stats['images_processed']\n",
        "            )\n",
        "\n",
        "        report = {\n",
        "            'session_info': {\n",
        "                'processed_at': datetime.now().isoformat(),\n",
        "                'total_inputs': len(results),\n",
        "                'successful': len(successful),\n",
        "                'failed': len(failed),\n",
        "                'success_rate': len(successful) / len(results) if results else 0\n",
        "            },\n",
        "\n",
        "            'output_summary': {\n",
        "                'total_files_created': total_files,\n",
        "                'variations_created': total_variations,\n",
        "                'crops_created': total_crops,\n",
        "                'enhanced_originals': len(successful),\n",
        "                'metadata_files': sum(len(r.get('metadata_files', [])) for r in successful)\n",
        "            },\n",
        "\n",
        "            'performance_metrics': self.processing_stats,\n",
        "\n",
        "            'file_organization': {\n",
        "                'processed_directory': str(self.processed_dir),\n",
        "                'originals_enhanced': str(self.originals_dir),\n",
        "                'variations': str(self.variations_dir),\n",
        "                'crops': str(self.crops_dir),\n",
        "                'metadata': str(self.metadata_dir)\n",
        "            },\n",
        "\n",
        "            'commercial_readiness': {\n",
        "                'watermarked_images': total_files,\n",
        "                'platform_ready_crops': total_crops,\n",
        "                'commercial_variations': total_variations,\n",
        "                'metadata_complete': True,\n",
        "                'ready_for_upload': len(successful) > 0\n",
        "            },\n",
        "\n",
        "            'detailed_results': results,\n",
        "            'errors': [r['errors'] for r in failed if r['errors']]\n",
        "        }\n",
        "\n",
        "        # Salvar relat√≥rio\n",
        "        report_path = self.metadata_dir / f\"processing_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(report_path, 'w') as f:\n",
        "            json.dump(report, f, indent=2, default=str)\n",
        "\n",
        "        print(f\"üìÑ Relat√≥rio salvo: {report_path}\")\n",
        "\n",
        "        return report\n",
        "\n",
        "# Configurar pipeline de p√≥s-processamento\n",
        "def setup_postprocessing_pipeline() -> CommercialPostProcessingPipeline:\n",
        "    \"\"\"\n",
        "    Configura pipeline de p√≥s-processamento\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüè≠ CONFIGURANDO PIPELINE DE P√ìS-PROCESSAMENTO\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Determinar diret√≥rio base\n",
        "    if 'OUTPUT_SESSION_DIR' in globals():\n",
        "        base_dir = OUTPUT_SESSION_DIR\n",
        "    else:\n",
        "        base_dir = \"/content/valentina_dataset_v4/postprocessing\"\n",
        "\n",
        "    pipeline = CommercialPostProcessingPipeline(base_dir)\n",
        "\n",
        "    print(f\"üìÅ ESTRUTURA CRIADA:\")\n",
        "    print(f\"   üé® Processados: {pipeline.processed_dir}\")\n",
        "    print(f\"   üîç Originais enhanced: {pipeline.originals_dir}\")\n",
        "    print(f\"   üåà Varia√ß√µes: {pipeline.variations_dir}\")\n",
        "    print(f\"   ‚úÇÔ∏è Crops: {pipeline.crops_dir}\")\n",
        "    print(f\"   üìÑ Metadados: {pipeline.metadata_dir}\")\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "POSTPROCESSING_PIPELINE = setup_postprocessing_pipeline()\n",
        "\n",
        "print(\"‚úÖ C√âLULA 4 CARREGADA: Pipeline completo de p√≥s-processamento configurado\")"
      ],
      "metadata": {
        "id": "YPfOdZhdQUFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 5: FASE 6.5 - Execu√ß√£o do P√≥s-Processamento Autom√°tico =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 5: Execu√ß√£o do P√≥s-Processamento Autom√°tico\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def find_approved_images() -> List[str]:\n",
        "    \"\"\"\n",
        "    Encontra todas as imagens aprovadas para processamento\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüîç LOCALIZANDO IMAGENS APROVADAS\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    approved_images = []\n",
        "\n",
        "    # Procurar no diret√≥rio de aprovadas se dispon√≠vel\n",
        "    if ('BATCH_MANAGER' in globals() and\n",
        "        hasattr(BATCH_MANAGER, 'approved_dir') and\n",
        "        BATCH_MANAGER.approved_dir.exists()):\n",
        "\n",
        "        approved_paths = list(BATCH_MANAGER.approved_dir.glob(\"*.png\"))\n",
        "        approved_images.extend([str(p) for p in approved_paths])\n",
        "        print(f\"‚úÖ Encontradas {len(approved_paths)} imagens no diret√≥rio de aprovadas\")\n",
        "\n",
        "    # Procurar em outros locais poss√≠veis\n",
        "    search_dirs = [\n",
        "        \"/content/valentina_dataset_v4/generated_commercial\",\n",
        "        \"/content/valentina_dataset_v4/approved\",\n",
        "        \"/content/approved_images\"\n",
        "    ]\n",
        "\n",
        "    for search_dir in search_dirs:\n",
        "        search_path = Path(search_dir)\n",
        "        if search_path.exists():\n",
        "            found_images = list(search_path.rglob(\"*.png\"))\n",
        "            # Filtrar apenas imagens n√£o rejeitadas\n",
        "            valid_images = [str(p) for p in found_images if 'REJECTED' not in p.name]\n",
        "            if valid_images:\n",
        "                approved_images.extend(valid_images)\n",
        "                print(f\"‚úÖ Encontradas {len(valid_images)} imagens em {search_dir}\")\n",
        "\n",
        "    # Remover duplicatas\n",
        "    approved_images = list(set(approved_images))\n",
        "\n",
        "    print(f\"\\nüìä TOTAL DE IMAGENS PARA PROCESSAR: {len(approved_images)}\")\n",
        "\n",
        "    return approved_images\n",
        "\n",
        "def execute_postprocessing_batch(image_paths: List[str]) -> Dict:\n",
        "    \"\"\"\n",
        "    Executa p√≥s-processamento em lote\n",
        "    \"\"\"\n",
        "\n",
        "    if not image_paths:\n",
        "        print(\"‚ùå Nenhuma imagem encontrada para processar\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"\\nüöÄ INICIANDO P√ìS-PROCESSAMENTO COMERCIAL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(f\"üìä CONFIGURA√á√ÉO:\")\n",
        "    print(f\"   üéØ Imagens para processar: {len(image_paths)}\")\n",
        "    print(f\"   üé® Varia√ß√µes por imagem: {len(FILTER_SYSTEM.commercial_looks)}\")\n",
        "    print(f\"   ‚úÇÔ∏è Crops por imagem: {len(CROP_GENERATOR.priority_crops)}\")\n",
        "    print(f\"   üõ°Ô∏è Prote√ß√£o: Ativada com watermark\")\n",
        "\n",
        "    # Estimativa de tempo\n",
        "    estimated_time_per_image = 30  # segundos por imagem (estimativa conservadora)\n",
        "    total_estimated_time = len(image_paths) * estimated_time_per_image / 60\n",
        "\n",
        "    print(f\"   ‚è±Ô∏è Tempo estimado: ~{total_estimated_time:.1f} minutos\")\n",
        "\n",
        "    files_per_image = (\n",
        "        1 +  # Original enhanced\n",
        "        len(FILTER_SYSTEM.commercial_looks) +  # Varia√ß√µes\n",
        "        len(CROP_GENERATOR.priority_crops)     # Crops\n",
        "    )\n",
        "    total_estimated_files = len(image_paths) * files_per_image\n",
        "\n",
        "    print(f\"   üìÅ Arquivos estimados: ~{total_estimated_files}\")\n",
        "\n",
        "    # Confirma√ß√£o autom√°tica (remover se quiser confirma√ß√£o manual)\n",
        "    proceed = True\n",
        "\n",
        "    if not proceed:\n",
        "        print(\"‚ùå P√≥s-processamento cancelado\")\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        # Log in√≠cio\n",
        "        LOGGER.info(\"FASE 6 iniciada: P√≥s-processamento comercial\")\n",
        "        LOGGER.info(f\"Imagens para processar: {len(image_paths)}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Executar processamento paralelo\n",
        "        print(f\"\\nüîÑ EXECUTANDO PROCESSAMENTO PARALELO...\")\n",
        "\n",
        "        results = POSTPROCESSING_PIPELINE.process_batch_parallel(image_paths)\n",
        "\n",
        "        # Gerar relat√≥rio\n",
        "        print(f\"\\nüìä GERANDO RELAT√ìRIO FINAL...\")\n",
        "        final_report = POSTPROCESSING_PIPELINE.generate_processing_report(results)\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "\n",
        "        # Log conclus√£o\n",
        "        LOGGER.info(\"FASE 6 conclu√≠da: P√≥s-processamento comercial\")\n",
        "        LOGGER.info(f\"Imagens processadas: {final_report['session_info']['successful']}\")\n",
        "        LOGGER.info(f\"Arquivos criados: {final_report['output_summary']['total_files_created']}\")\n",
        "        LOGGER.info(f\"Tempo total: {total_time:.1f}s\")\n",
        "\n",
        "        return final_report\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Erro cr√≠tico no p√≥s-processamento: {e}\"\n",
        "        print(f\"‚ùå {error_msg}\")\n",
        "        LOGGER.error(error_msg)\n",
        "        return {}\n",
        "\n",
        "def display_postprocessing_results(report: Dict):\n",
        "    \"\"\"\n",
        "    Exibe resultados do p√≥s-processamento\n",
        "    \"\"\"\n",
        "\n",
        "    if not report:\n",
        "        print(\"‚ùå Nenhum relat√≥rio para exibir\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 70)\n",
        "    print(f\"üéâ P√ìS-PROCESSAMENTO COMERCIAL CONCLU√çDO!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    session = report['session_info']\n",
        "    output = report['output_summary']\n",
        "    performance = report['performance_metrics']\n",
        "    commercial = report['commercial_readiness']\n",
        "\n",
        "    print(f\"üìä RESULTADOS DA SESS√ÉO:\")\n",
        "    print(f\"   üéØ Imagens processadas: {session['successful']}/{session['total_inputs']}\")\n",
        "    print(f\"   üìà Taxa de sucesso: {session['success_rate']:.1%}\")\n",
        "    if session['failed'] > 0:\n",
        "        print(f\"   ‚ùå Falhas: {session['failed']}\")\n",
        "\n",
        "    print(f\"\\nüìÅ ARQUIVOS CRIADOS:\")\n",
        "    print(f\"   üîç Originais enhanced: {output['enhanced_originals']}\")\n",
        "    print(f\"   üé® Varia√ß√µes: {output['variations_created']}\")\n",
        "    print(f\"   ‚úÇÔ∏è Crops comerciais: {output['crops_created']}\")\n",
        "    print(f\"   üìÑ Metadados: {output['metadata_files']}\")\n",
        "    print(f\"   üìä Total de arquivos: {output['total_files_created']}\")\n",
        "\n",
        "    print(f\"\\n‚ö° PERFORMANCE:\")\n",
        "    print(f\"   ‚è±Ô∏è Tempo m√©dio/imagem: {performance.get('average_processing_time', 0):.1f}s\")\n",
        "    print(f\"   üöÄ Throughput: {performance['images_processed']} imagens processadas\")\n",
        "    print(f\"   üìà Efici√™ncia: {output['total_files_created']} arquivos gerados\")\n",
        "\n",
        "    print(f\"\\nüí∞ PRONTID√ÉO COMERCIAL:\")\n",
        "    print(f\"   üõ°Ô∏è Imagens protegidas: {commercial['watermarked_images']}\")\n",
        "    print(f\"   üì± Crops para plataformas: {commercial['platform_ready_crops']}\")\n",
        "    print(f\"   üé® Varia√ß√µes comerciais: {commercial['commercial_variations']}\")\n",
        "    print(f\"   üìÑ Metadados completos: {'‚úÖ' if commercial['metadata_complete'] else '‚ùå'}\")\n",
        "    print(f\"   üöÄ Pronto para upload: {'‚úÖ' if commercial['ready_for_upload'] else '‚ùå'}\")\n",
        "\n",
        "    # Organiza√ß√£o de arquivos\n",
        "    files = report['file_organization']\n",
        "    print(f\"\\nüìÅ ORGANIZA√á√ÉO DE ARQUIVOS:\")\n",
        "    print(f\"   üìÇ Diret√≥rio principal: {files['processed_directory']}\")\n",
        "    print(f\"   üîç Originais enhanced: {files['originals_enhanced']}\")\n",
        "    print(f\"   üåà Varia√ß√µes: {files['variations']}\")\n",
        "    print(f\"   ‚úÇÔ∏è Crops: {files['crops']}\")\n",
        "    print(f\"   üìÑ Metadados: {files['metadata']}\")\n",
        "\n",
        "    # Resumo comercial final\n",
        "    print(f\"\\nüéØ RESUMO COMERCIAL FINAL:\")\n",
        "    if commercial['ready_for_upload']:\n",
        "        print(f\"   ‚úÖ Dataset comercial COMPLETO e protegido\")\n",
        "        print(f\"   üöÄ {output['total_files_created']} arquivos prontos para monetiza√ß√£o\")\n",
        "        print(f\"   üì± Crops otimizados para todas as plataformas principais\")\n",
        "        print(f\"   üé® Varia√ß√µes comerciais para diferentes usos\")\n",
        "        print(f\"   üõ°Ô∏è Prote√ß√£o por watermark aplicada\")\n",
        "        print(f\"   üíé Qualidade comercial premium garantida\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è Processamento incompleto - verificar erros\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# Executar p√≥s-processamento autom√°tico\n",
        "print(\"üöÄ INICIANDO BUSCA E PROCESSAMENTO AUTOM√ÅTICO...\")\n",
        "\n",
        "# Encontrar imagens aprovadas\n",
        "APPROVED_IMAGES = find_approved_images()\n",
        "\n",
        "if APPROVED_IMAGES:\n",
        "    print(f\"\\nüé¨ EXECUTANDO P√ìS-PROCESSAMENTO DE {len(APPROVED_IMAGES)} IMAGENS...\")\n",
        "\n",
        "    # Executar processamento\n",
        "    POSTPROCESSING_REPORT = execute_postprocessing_batch(APPROVED_IMAGES)\n",
        "\n",
        "    # Exibir resultados\n",
        "    if POSTPROCESSING_REPORT:\n",
        "        display_postprocessing_results(POSTPROCESSING_REPORT)\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è NENHUMA IMAGEM APROVADA ENCONTRADA\")\n",
        "    print(\"üîß Execute as fases anteriores para gerar imagens aprovadas primeiro\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 5 CONCLU√çDA: P√≥s-processamento autom√°tico executado\")"
      ],
      "metadata": {
        "id": "4VkFe-5YQUot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ===== C√âLULA 6: FASE 6.6 - Resumo e Conclus√£o da FASE 6 =====\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüì± C√âLULA 6: Resumo e Conclus√£o da FASE 6\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def generate_phase6_final_report() -> Dict:\n",
        "    \"\"\"\n",
        "    Gera relat√≥rio final consolidado da FASE 6\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nüìã GERANDO RELAT√ìRIO FINAL DA FASE 6\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    phase6_report = {\n",
        "        'phase': 6,\n",
        "        'title': 'Sistema de P√≥s-Processamento e Refinamento Comercial',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'status': 'completed',\n",
        "\n",
        "        'components_implemented': {\n",
        "            'commercial_processor': {\n",
        "                'implemented': True,\n",
        "                'upscaling_system': COMMERCIAL_PROCESSOR.upscaler_model is not None,\n",
        "                'quality_enhancement': True,\n",
        "                'target_resolution': COMMERCIAL_PROCESSOR.commercial_settings['target_resolution']\n",
        "            },\n",
        "            'filter_system': {\n",
        "                'implemented': True,\n",
        "                'commercial_filters': len(FILTER_SYSTEM.filter_presets),\n",
        "                'commercial_looks': len(FILTER_SYSTEM.commercial_looks)\n",
        "            },\n",
        "            'crop_generator': {\n",
        "                'implemented': True,\n",
        "                'commercial_aspects': len(CROP_GENERATOR.commercial_aspects),\n",
        "                'priority_crops': len(CROP_GENERATOR.priority_crops),\n",
        "                'smart_cropping': True\n",
        "            },\n",
        "            'protection_system': {\n",
        "                'implemented': True,\n",
        "                'watermarking': True,\n",
        "                'brand_protection': PROTECTION_SYSTEM.brand_name,\n",
        "                'protection_levels': len(PROTECTION_SYSTEM.protection_levels)\n",
        "            },\n",
        "            'metadata_manager': {\n",
        "                'implemented': True,\n",
        "                'commercial_metadata': True,\n",
        "                'brand_info': METADATA_MANAGER.brand_info\n",
        "            },\n",
        "            'processing_pipeline': {\n",
        "                'implemented': True,\n",
        "                'parallel_processing': True,\n",
        "                'automated_organization': True,\n",
        "                'output_structure': True\n",
        "            }\n",
        "        },\n",
        "\n",
        "        'processing_results': {},\n",
        "        'technical_achievements': [],\n",
        "        'commercial_achievements': [],\n",
        "        'quality_improvements': [],\n",
        "        'recommendations': []\n",
        "    }\n",
        "\n",
        "    # Incluir resultados se dispon√≠veis\n",
        "    if 'POSTPROCESSING_REPORT' in globals() and POSTPROCESSING_REPORT:\n",
        "        phase6_report['processing_results'] = POSTPROCESSING_REPORT\n",
        "\n",
        "        session = POSTPROCESSING_REPORT['session_info']\n",
        "        output = POSTPROCESSING_REPORT['output_summary']\n",
        "        commercial = POSTPROCESSING_REPORT['commercial_readiness']\n",
        "\n",
        "        # Conquistas t√©cnicas\n",
        "        technical_achievements = [\n",
        "            f\"‚úÖ Sistema de upscaling para resolu√ß√£o {COMMERCIAL_PROCESSOR.commercial_settings['target_resolution']}\",\n",
        "            f\"‚úÖ {len(FILTER_SYSTEM.filter_presets)} filtros comerciais implementados\",\n",
        "            f\"‚úÖ {len(CROP_GENERATOR.commercial_aspects)} formatos de crop comercial\",\n",
        "            f\"‚úÖ Sistema de prote√ß√£o por watermark autom√°tico\",\n",
        "            f\"‚úÖ Pipeline paralelo processando {session['successful']} imagens\"\n",
        "        ]\n",
        "\n",
        "        if session['success_rate'] > 0.9:\n",
        "            technical_achievements.append(f\"‚úÖ Alta taxa de sucesso: {session['success_rate']:.1%}\")\n",
        "\n",
        "        phase6_report['technical_achievements'] = technical_achievements\n",
        "\n",
        "        # Conquistas comerciais\n",
        "        commercial_achievements = [\n",
        "            f\"üéØ {output['total_files_created']} arquivos comerciais criados\",\n",
        "            f\"üé® {output['variations_created']} varia√ß√µes comerciais geradas\",\n",
        "            f\"‚úÇÔ∏è {output['crops_created']} crops otimizados para plataformas\",\n",
        "            f\"üõ°Ô∏è {commercial['watermarked_images']} imagens protegidas\",\n",
        "            f\"üìÑ Metadados comerciais completos para todos os arquivos\"\n",
        "        ]\n",
        "\n",
        "        if commercial['ready_for_upload']:\n",
        "            commercial_achievements.append(\"üöÄ Dataset completamente pronto para monetiza√ß√£o\")\n",
        "\n",
        "        phase6_report['commercial_achievements'] = commercial_achievements\n",
        "\n",
        "        # Melhorias de qualidade\n",
        "        quality_improvements = [\n",
        "            f\"üìà Upscaling para resolu√ß√£o comercial premium\",\n",
        "            f\"üé® Enhancement autom√°tico de cor, contraste e nitidez\",\n",
        "            f\"üîç Redu√ß√£o de ru√≠do com preserva√ß√£o de detalhes\",\n",
        "            f\"‚úÇÔ∏è Crops inteligentes com detec√ß√£o facial\",\n",
        "            f\"üõ°Ô∏è Prote√ß√£o profissional com watermark elegante\"\n",
        "        ]\n",
        "\n",
        "        phase6_report['quality_improvements'] = quality_improvements\n",
        "\n",
        "    # Recomenda√ß√µes finais\n",
        "    recommendations = [\n",
        "        \"üìä Monitorar qualidade dos arquivos processados\",\n",
        "        \"üîÑ Configurar pipeline de processamento cont√≠nuo\",\n",
        "        \"üí∞ Proceder com upload para plataformas comerciais\",\n",
        "        \"üì± Testar uploads em diferentes plataformas\"\n",
        "    ]\n",
        "\n",
        "    if 'POSTPROCESSING_REPORT' in globals() and POSTPROCESSING_REPORT:\n",
        "        if POSTPROCESSING_REPORT['commercial_readiness']['ready_for_upload']:\n",
        "            recommendations.extend([\n",
        "                \"üöÄ Iniciar estrat√©gia de monetiza√ß√£o imediata\",\n",
        "                \"üìà Configurar analytics de performance comercial\",\n",
        "                \"üéØ Planejar pr√≥xima sess√£o de gera√ß√£o\"\n",
        "            ])\n",
        "\n",
        "    phase6_report['recommendations'] = recommendations\n",
        "\n",
        "    # Salvar relat√≥rio\n",
        "    report_path = f\"/content/valentina_dataset_v4/metadata/phase6_final_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
        "\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(phase6_report, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"üìÑ Relat√≥rio FASE 6 salvo: {report_path}\")\n",
        "\n",
        "    return phase6_report\n",
        "\n",
        "def display_final_phase6_summary(phase6_report: Dict):\n",
        "    \"\"\"\n",
        "    Exibe resumo final da FASE 6\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n\" + \"=\" * 70)\n",
        "    print(f\"üéâ FASE 6 CONCLU√çDA: P√ìS-PROCESSAMENTO E REFINAMENTO COMERCIAL\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Status dos componentes\n",
        "    components = phase6_report['components_implemented']\n",
        "    print(f\"üîß COMPONENTES IMPLEMENTADOS:\")\n",
        "\n",
        "    component_names = {\n",
        "        'commercial_processor': 'Processador Comercial',\n",
        "        'filter_system': 'Sistema de Filtros',\n",
        "        'crop_generator': 'Gerador de Crops',\n",
        "        'protection_system': 'Sistema de Prote√ß√£o',\n",
        "        'metadata_manager': 'Gerenciador de Metadados',\n",
        "        'processing_pipeline': 'Pipeline de Processamento'\n",
        "    }\n",
        "\n",
        "    for component, details in components.items():\n",
        "        status = \"‚úÖ\" if details['implemented'] else \"‚ùå\"\n",
        "        name = component_names.get(component, component.replace('_', ' ').title())\n",
        "        print(f\"   {status} {name}\")\n",
        "\n",
        "    # Conquistas t√©cnicas\n",
        "    if phase6_report['technical_achievements']:\n",
        "        print(f\"\\nüöÄ CONQUISTAS T√âCNICAS:\")\n",
        "        for achievement in phase6_report['technical_achievements']:\n",
        "            print(f\"   {achievement}\")\n",
        "\n",
        "    # Conquistas comerciais\n",
        "    if phase6_report['commercial_achievements']:\n",
        "        print(f\"\\nüí∞ CONQUISTAS COMERCIAIS:\")\n",
        "        for achievement in phase6_report['commercial_achievements']:\n",
        "            print(f\"   {achievement}\")\n",
        "\n",
        "    # Melhorias de qualidade\n",
        "    if phase6_report['quality_improvements']:\n",
        "        print(f\"\\n‚≠ê MELHORIAS DE QUALIDADE:\")\n",
        "        for improvement in phase6_report['quality_improvements']:\n",
        "            print(f\"   {improvement}\")\n",
        "\n",
        "    # Resultados do processamento se dispon√≠veis\n",
        "    if phase6_report['processing_results']:\n",
        "        session = phase6_report['processing_results']['session_info']\n",
        "        output = phase6_report['processing_results']['output_summary']\n",
        "\n",
        "        print(f\"\\nüìä RESULTADOS DO PROCESSAMENTO:\")\n",
        "        print(f\"   üéØ Imagens processadas: {session['successful']}\")\n",
        "        print(f\"   üìÅ Arquivos criados: {output['total_files_created']}\")\n",
        "        print(f\"   üìà Taxa de sucesso: {session['success_rate']:.1%}\")\n",
        "        print(f\"   üé® Varia√ß√µes: {output['variations_created']}\")\n",
        "        print(f\"   ‚úÇÔ∏è Crops: {output['crops_created']}\")\n",
        "\n",
        "    # Recomenda√ß√µes priorit√°rias\n",
        "    print(f\"\\nüéØ PR√ìXIMOS PASSOS RECOMENDADOS:\")\n",
        "    for i, rec in enumerate(phase6_report['recommendations'][:5], 1):\n",
        "        print(f\"   {i}. {rec}\")\n",
        "\n",
        "    # Status final do projeto completo\n",
        "    print(f\"\\nüèÜ STATUS FINAL DO PROJETO VALENTINA v4.0:\")\n",
        "\n",
        "    if phase6_report['processing_results']:\n",
        "        commercial = phase6_report['processing_results']['commercial_readiness']\n",
        "        if commercial['ready_for_upload']:\n",
        "            print(f\"   üéâ PROJETO COMPLETO E OTIMIZADO PARA MONETIZA√á√ÉO\")\n",
        "            print(f\"   üíé Dataset Valentina Moreau v4.0 - Vers√£o Comercial Premium\")\n",
        "            print(f\"   üöÄ {phase6_report['processing_results']['output_summary']['total_files_created']} arquivos comerciais prontos\")\n",
        "            print(f\"   üõ°Ô∏è Prote√ß√£o profissional aplicada\")\n",
        "            print(f\"   üì± Otimizado para todas as plataformas principais\")\n",
        "        else:\n",
        "            print(f\"   üîß PROJETO PROCESSADO - VERIFICAR RESULTADOS\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ FASE 6 CONFIGURADA E PRONTA\")\n",
        "        print(f\"   ‚ö° Execute o processamento quando tiver imagens aprovadas\")\n",
        "\n",
        "# Gerar relat√≥rio final da FASE 6\n",
        "PHASE6_FINAL_REPORT = generate_phase6_final_report()\n",
        "\n",
        "# Exibir resumo final\n",
        "display_final_phase6_summary(PHASE6_FINAL_REPORT)\n",
        "\n",
        "# =============================================================================\n",
        "# üìä RESUMO GLOBAL ATUALIZADO DO PROJETO VALENTINA v4.0\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(f\"üéØ RESUMO GLOBAL ATUALIZADO: VALENTINA DATASET GENERATOR v4.0\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üèóÔ∏è PROJETO EXECUTADO:\")\n",
        "print(f\"   ‚úÖ FASE 1: Setup Google Colab Otimizado\")\n",
        "print(f\"   ‚úÖ FASE 2: Carregamento Inteligente dos Modelos\")\n",
        "print(f\"   ‚úÖ FASE 3: Processamento da Imagem de Refer√™ncia\")\n",
        "print(f\"   ‚úÖ FASE 4: Sistema de Prompts Comerciais Otimizados\")\n",
        "print(f\"   ‚úÖ FASE 5: Gera√ß√£o com Valida√ß√£o Comercial Autom√°tica\")\n",
        "print(f\"   ‚úÖ FASE 6: P√≥s-Processamento e Refinamento Comercial\")\n",
        "\n",
        "print(f\"\\nüéÆ STACK T√âCNICO COMPLETO:\")\n",
        "print(f\"   ‚Ä¢ FLUX.1-dev + {SELECTED_CONTROLNET['name'] if 'SELECTED_CONTROLNET' in globals() else 'ControlNet'}\")\n",
        "print(f\"   ‚Ä¢ Sistema de valida√ß√£o facial com FED\")\n",
        "print(f\"   ‚Ä¢ Pipeline de gera√ß√£o autom√°tica em lote\")\n",
        "print(f\"   ‚Ä¢ Upscaling e enhancement comercial\")\n",
        "print(f\"   ‚Ä¢ Sistema de filtros e crops otimizados\")\n",
        "print(f\"   ‚Ä¢ Prote√ß√£o por watermark profissional\")\n",
        "print(f\"   ‚Ä¢ Organiza√ß√£o autom√°tica de arquivos\")\n",
        "\n",
        "print(f\"\\nüí∞ RESULTADO COMERCIAL:\")\n",
        "print(f\"   üéØ Modelo digital: Valentina Moreau\")\n",
        "print(f\"   üöÄ Plataformas: TopFans, OnlyFans, Instagram\")\n",
        "print(f\"   üíé Qualidade: Premium comercial\")\n",
        "print(f\"   üõ°Ô∏è Prote√ß√£o: Watermark profissional\")\n",
        "print(f\"   üì± Formatos: Otimizados para todas as plataformas\")\n",
        "\n",
        "if 'POSTPROCESSING_REPORT' in globals() and POSTPROCESSING_REPORT:\n",
        "    output = POSTPROCESSING_REPORT['output_summary']\n",
        "    print(f\"\\nüéâ DATASET FINAL GERADO:\")\n",
        "    print(f\"   üìä {output['total_files_created']} arquivos comerciais prontos\")\n",
        "    print(f\"   üé® {output['variations_created']} varia√ß√µes estilizadas\")\n",
        "    print(f\"   ‚úÇÔ∏è {output['crops_created']} crops para plataformas\")\n",
        "    print(f\"   üõ°Ô∏è Prote√ß√£o aplicada em todos os arquivos\")\n",
        "    print(f\"   üöÄ PRONTO PARA MONETIZA√á√ÉO IMEDIATA\")\n",
        "\n",
        "print(f\"\\nüî• VALENTINA DATASET GENERATOR v4.0 - PROJETO FINALIZADO! üî•\")\n",
        "print(f\"üíé DATASET COMERCIAL PREMIUM COMPLETO E PROTEGIDO üíé\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Log final\n",
        "LOGGER.info(\"PROJETO VALENTINA v4.0 FINALIZADO COM SUCESSO\")\n",
        "LOGGER.info(\"Todas as 6 fases implementadas e executadas\")\n",
        "if 'POSTPROCESSING_REPORT' in globals() and POSTPROCESSING_REPORT:\n",
        "    output = POSTPROCESSING_REPORT['output_summary']\n",
        "    LOGGER.info(f\"Dataset comercial final: {output['total_files_created']} arquivos prontos\")\n",
        "\n",
        "print(\"‚úÖ C√âLULA 6 CONCLU√çDA: FASE 6 finalizada - PROJETO COMPLETO!\")"
      ],
      "metadata": {
        "id": "qskpNCywQa2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rae6RfCLQbfL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}