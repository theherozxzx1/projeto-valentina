{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e554695c",
   "metadata": {},
   "source": [
    "# 🎨 Valentina High-Quality Dataset Generator - Google Colab\n",
    "\n",
    "Este notebook gera um dataset de **alta qualidade** para treinar a LoRA facial da Valentina usando a GPU superior do Google Colab.\n",
    "\n",
    "## 🚀 Vantagens do Colab:\n",
    "- **40-50 inference steps** vs 8 no MacBook\n",
    "- **Resolução superior** (1024x1024+)\n",
    "- **Melhor qualidade** de detalhes faciais\n",
    "- **Múltiplas variações** profissionais\n",
    "\n",
    "## 📋 Stack Utilizada:\n",
    "- **Base**: FLUX.1-dev (máxima qualidade)\n",
    "- **1º LoRA**: NSFW_MASTER_FLUX (capacidades NSFW)\n",
    "- **2º LoRA**: Midjourney LoRA (qualidade cinematográfica)\n",
    "- **GPU**: A100 optimized com 50 inference steps\n",
    "- **Output**: 6 imagens de referência premium sequenciais\n",
    "\n",
    "⚠️ **Execute as células em ordem para gerar o dataset otimizado!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d621281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 CONFIGURAÇÕES PARA GERAÇÃO DE ALTA QUALIDADE - FLUX.1-dev + LoRAs Sequenciais\n",
    "\n",
    "# Modelo base e LoRAs sequenciais\n",
    "BASE_MODEL_ID = \"black-forest-labs/FLUX.1-dev\"  # Base model para máxima qualidade\n",
    "NSFW_LORA_ID = \"Keltezaa/NSFW_MASTER_FLUX\"       # Primeiro LoRA: NSFW\n",
    "MIDJOURNEY_LORA_FILENAME = \"midjourney_LORA.safetensors\"  # Segundo LoRA: Midjourney (local)\n",
    "\n",
    "# Configurações de qualidade PREMIUM (A100 Optimized)\n",
    "INFERENCE_STEPS = 50      # Máxima qualidade possível na A100\n",
    "GUIDANCE_SCALE = 7.5      # Balanço ideal qualidade/criatividade  \n",
    "RESOLUTION = 1024         # Resolução máxima para detalhes\n",
    "NSFW_LORA_WEIGHT = 0.8    # Peso do primeiro LoRA (NSFW)\n",
    "MIDJOURNEY_LORA_WEIGHT = 0.7  # Peso do segundo LoRA (Midjourney)\n",
    "\n",
    "# Configurações de diversidade\n",
    "NUM_IMAGES = 6        # 6 variações diversas\n",
    "SEEDS = [42, 7777, 12345, 98765, 55555, 33333]  # Seeds específicas\n",
    "\n",
    "# Prompts especializados para dataset\n",
    "BASE_CHARACTERISTICS = \"\"\"A stunning 23-year-old woman named Valentina Moreau. Oval face with delicately defined jawline and prominent cheekbones, large almond-shaped deep brown expressive eyes with long dark lashes, perfectly arched eyebrows, full plump lips with pronounced cupid's bow in natural pink tone, straight proportional nose with slightly tapered tip. Flawless sun-kissed golden-olive skin with healthy glow. Rich dark brown hair with subtle chocolate and mahogany highlights, long flowing past shoulders with voluminous natural waves, dense and shiny hair. Curvy and toned silhouette, confident posture.\"\"\"\n",
    "\n",
    "# Variações de pose e iluminação para dataset diverso\n",
    "DATASET_PROMPTS = [\n",
    "    f\"{BASE_CHARACTERISTICS} Professional headshot, direct gaze, neutral expression, studio lighting, white background, hyperrealistic portrait photography, 8k resolution, commercial photography\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Three-quarter angle portrait, subtle smile, natural daylight, window lighting, elegant and sophisticated, professional photography, high detail, photorealistic\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Side profile portrait, looking away, dramatic rim lighting, dark background, artistic portrait, professional studio photography, cinematic lighting, ultra detailed\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Looking up perspective, gentle smile, golden hour lighting, outdoor natural light, warm tones, Instagram-worthy, glamour photography, high quality\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Close-up portrait, intense direct gaze, soft box lighting, professional makeup, fashion photography style, magazine quality, hyperrealistic details\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Full face frontal view, serene expression, balanced lighting, neutral background, reference photo style, documentary photography, crystal clear details\"\n",
    "]\n",
    "\n",
    "# Paths no Colab\n",
    "COLAB_MODELS_PATH = \"/content/models\"\n",
    "COLAB_OUTPUT_PATH = \"/content/valentina_hq_dataset\"\n",
    "\n",
    "print(\"🎨 Configurações de ALTA QUALIDADE carregadas:\")\n",
    "print(f\"📊 Inference Steps: {INFERENCE_STEPS} (vs 8 no MacBook)\")\n",
    "print(f\"🎯 Resolução: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"🖼️  Imagens a gerar: {NUM_IMAGES}\")\n",
    "print(f\"🎭 Variações: poses, ângulos e iluminações diversos\")\n",
    "print(f\"⭐ Qualidade: PREMIUM para treinamento superior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03453d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 INSTALAÇÃO OTIMIZADA DE DEPENDÊNCIAS VIA UV\n",
    "print(\"🔧 Instalando dependências usando uv para maior robustez...\")\n",
    "\n",
    "# 1. Instalar uv\n",
    "print(\"⚙️ Instalando uv...\")\n",
    "!pip install -q uv\n",
    "print(\"✅ uv instalado.\")\n",
    "\n",
    "# 2. Definir o conteúdo do requirements.txt baseado no pyproject.toml\n",
    "requirements_content = \"\"\"\\\n",
    "torch>=2.1.0,<2.4.0\n",
    "torchvision>=0.16.0,<0.19.0\n",
    "torchaudio>=2.1.0,<2.4.0\n",
    "diffusers[torch]>=0.27.0,<1.0\n",
    "transformers>=4.44.0,<5.0\n",
    "accelerate>=0.32.0,<1.0\n",
    "safetensors>=0.4.0,<0.5.0\n",
    "xformers>=0.0.27,<0.0.29\n",
    "pillow>=10.0.0,<11.0.0\n",
    "opencv-python>=4.10.0,<5.0\n",
    "huggingface-hub>=0.24.5,<1.0\n",
    "sentencepiece>=0.2.0,<0.3.0\n",
    "tokenizers>=0.19.0,<0.20.0\n",
    "protobuf>=5.27.0,<6.0.0\n",
    "numpy>=2.0.0,<3.0.0\n",
    "requests>=2.32.0,<3.0.0\n",
    "scipy>=1.14.0,<2.0.0\n",
    "matplotlib>=3.9.0,<4.0.0\n",
    "omegaconf>=2.3.0,<3.0.0\n",
    "einops>=0.8.0,<0.9.0\n",
    "invisible-watermark>=0.2.0,<0.3.0\n",
    "compel>=2.0.0,<3.0.0\n",
    "wandb>=0.17.0,<0.18.0\n",
    "peft>=0.12.0,<0.13.0\n",
    "bitsandbytes>=0.43.0,<0.44.0\n",
    "gradio>=4.39.0,<5.0.0\n",
    "albumentations>=1.4.0,<2.0.0\n",
    "imageio>=2.34.0,<3.0.0\n",
    "scikit-image>=0.24.0,<0.25.0\n",
    "tqdm>=4.66.0,<5.0.0\n",
    "ftfy>=6.2.0,<7.0.0\n",
    "tensorboard>=2.16.0,<3.0.0\n",
    "easydict>=1.13.0,<2.0.0\n",
    "clean-fid==0.1.35\n",
    "torchmetrics>=1.4.0,<2.0.0\n",
    "kornia>=0.7.0,<0.8.0\n",
    "lpips>=0.1.4,<0.2.0\n",
    "controlnet_aux>=0.0.7,<0.0.8\n",
    "segment-anything>=1.0.0,<2.0.0\n",
    "rembg[gpu]>=2.0.56,<3.0.0\n",
    "moviepy>=1.0.3,<2.0.0\n",
    "typer>=0.12.0,<0.13.0\n",
    "rich>=13.7.0,<14.0.0\n",
    "shellingham>=1.5.0,<2.0.0\n",
    "\"\"\"\n",
    "\n",
    "# 3. Criar o arquivo requirements.txt no ambiente do Colab\n",
    "requirements_file_path = \"/content/valentina_requirements.txt\"\n",
    "with open(requirements_file_path, \"w\") as f:\n",
    "    f.write(requirements_content)\n",
    "print(f\"📄 {requirements_file_path} criado.\")\n",
    "\n",
    "# 4. Instalar dependências usando uv pip install\n",
    "print(f\"🚀 Instalando dependências de {requirements_file_path} com uv...\")\n",
    "print(\"🕒 Isso pode levar alguns minutos...\")\n",
    "!uv pip install -q -r {requirements_file_path} --extra-index-url https://download.pytorch.org/whl/cu121 --index-strategy unsafe-best-match\n",
    "\n",
    "print(\"✅ Dependências instaladas com sucesso usando uv!\")\n",
    "print(\"🎯 Ambiente otimizado para geração premium\")\n",
    "\n",
    "# Verificação opcional (descomentar para depurar e ver as versões instaladas)\n",
    "# print(\"\\\\nVerificando versões instaladas (amostra):\")\n",
    "# !pip show torch torchvision torchaudio xformers transformers huggingface-hub opencv-python diffusers accelerate bitsandbytes clean-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🖥️ DETECÇÃO E OTIMIZAÇÃO DA GPU\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"🔍 Verificando GPU disponível...\")\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits\n",
    "\n",
    "# Detectar GPU específica\n",
    "gpu_name = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"]).decode().strip()\n",
    "print(f\"\\n🚀 GPU detectada: {gpu_name}\")\n",
    "\n",
    "# Otimizar configurações baseado na GPU\n",
    "if \"T4\" in gpu_name:\n",
    "    print(\"⚡ Configurações Tesla T4 (15GB)\")\n",
    "    DTYPE = torch.float16\n",
    "    ENABLE_CPU_OFFLOAD = True\n",
    "    BATCH_SIZE = 1\n",
    "    INFERENCE_STEPS = 40  # Reduzido para T4\n",
    "elif \"V100\" in gpu_name:\n",
    "    print(\"💎 Configurações V100 (16GB)\")\n",
    "    DTYPE = torch.float16\n",
    "    ENABLE_CPU_OFFLOAD = False\n",
    "    BATCH_SIZE = 1\n",
    "    INFERENCE_STEPS = 45  # Melhor que T4\n",
    "elif \"A100\" in gpu_name:\n",
    "    print(\"🔥 Configurações A100 PREMIUM - Máxima Qualidade\")\n",
    "    DTYPE = torch.bfloat16  # Melhor precisão na A100\n",
    "    ENABLE_CPU_OFFLOAD = False\n",
    "    BATCH_SIZE = 1  # Foco em qualidade, não velocidade\n",
    "    INFERENCE_STEPS = 50  # Máxima qualidade possível\n",
    "    print(\"🎯 A100 detectada: Configurando para máxima qualidade com LoRAs sequenciais\")\n",
    "elif \"H100\" in gpu_name:\n",
    "    print(\"🚀 Configurações H100 ULTRA PREMIUM\")\n",
    "    DTYPE = torch.bfloat16\n",
    "    ENABLE_CPU_OFFLOAD = False\n",
    "    BATCH_SIZE = 2\n",
    "    INFERENCE_STEPS = 50\n",
    "else:\n",
    "    print(\"📱 Configurações padrão\")\n",
    "    DTYPE = torch.float16\n",
    "    ENABLE_CPU_OFFLOAD = True\n",
    "    BATCH_SIZE = 1\n",
    "    INFERENCE_STEPS = 35\n",
    "\n",
    "print(f\"✅ Configurado: {DTYPE}, CPU offload: {ENABLE_CPU_OFFLOAD}\")\n",
    "print(f\"🎯 Steps finais: {INFERENCE_STEPS}\")\n",
    "\n",
    "# Limpeza inicial\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"🧹 Memória GPU limpa\")\n",
    "\n",
    "# 📦 INSTALAÇÃO OTIMIZADA DE DEPENDÊNCIAS VIA UV\n",
    "print(\"🔧 Instalando dependências usando uv para maior robustez...\")\n",
    "\n",
    "# 1. Instalar uv\n",
    "print(\"⚙️ Instalando uv...\")\n",
    "!pip install -q uv\n",
    "print(\"✅ uv instalado.\")\n",
    "\n",
    "# 2. Upload do arquivo uv.lock\n",
    "from google.colab import files\n",
    "print(\"📤 Faça upload do arquivo uv.lock...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# 3. Sincronizar dependências usando uv.lock com estratégia de índice insegura\n",
    "print(\"🚀 Instalando dependências com uv pip sync usando uv.lock...\")\n",
    "!uv pip sync uv.lock --index-strategy unsafe-best-match\n",
    "\n",
    "print(\"✅ Dependências instaladas com sucesso usando uv!\")\n",
    "print(\"🎯 Ambiente otimizado para geração premium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔐 AUTENTICAÇÃO HUGGING FACE\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "print(\"🔑 Faça login na sua conta Hugging Face para acessar modelos premium:\")\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 CRIAÇÃO DA ESTRUTURA DE DIRETÓRIOS\n",
    "import os\n",
    "\n",
    "directories = [\n",
    "    COLAB_MODELS_PATH,\n",
    "    COLAB_OUTPUT_PATH,\n",
    "    f\"{COLAB_OUTPUT_PATH}/metadata\"\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"📂 Criado: {directory}\")\n",
    "\n",
    "print(\"\\n✅ Estrutura preparada para dataset premium!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📤 UPLOAD DA MIDJOURNEY LORA (OPCIONAL - 2º LORA)\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"🎨 Upload da Midjourney LoRA para qualidade cinematográfica:\")\n",
    "print(\"\\n📝 Arquitetura Sequential LoRA:\")\n",
    "print(f\"   1️⃣ Base: {BASE_MODEL_ID}\")\n",
    "print(f\"   2️⃣ NSFW LoRA: {NSFW_LORA_ID} (automático)\")\n",
    "print(f\"   3️⃣ Midjourney LoRA: {MIDJOURNEY_LORA_FILENAME} (upload opcional)\")\n",
    "print(\"\\n⚠️ Arquivo opcional. Se não fornecido, usará apenas NSFW LoRA.\")\n",
    "print(f\"\\n📤 Esperado: {MIDJOURNEY_LORA_FILENAME}\")\n",
    "\n",
    "uploaded_files = files.upload()\n",
    "\n",
    "if MIDJOURNEY_LORA_FILENAME in uploaded_files:\n",
    "    # Mover para pasta de modelos\n",
    "    lora_path = f\"{COLAB_MODELS_PATH}/{MIDJOURNEY_LORA_FILENAME}\"\n",
    "    shutil.move(MIDJOURNEY_LORA_FILENAME, lora_path)\n",
    "    \n",
    "    # Verificar tamanho\n",
    "    size_mb = os.path.getsize(lora_path) / (1024*1024)\n",
    "    print(f\"✅ Midjourney LoRA carregada: {size_mb:.1f}MB\")\n",
    "    print(f\"📁 Localização: {lora_path}\")\n",
    "    \n",
    "    USE_MIDJOURNEY_LORA = True\n",
    "    print(f\"\\n🎯 Configuração Final:\")\n",
    "    print(f\"   • NSFW Weight: {NSFW_LORA_WEIGHT}\")\n",
    "    print(f\"   • Midjourney Weight: {MIDJOURNEY_LORA_WEIGHT}\")\n",
    "else:\n",
    "    print(\"⚠️ Midjourney LoRA não fornecida.\")\n",
    "    print(\"🚀 Continuando com configuração: Base + NSFW LoRA\")\n",
    "    USE_MIDJOURNEY_LORA = False\n",
    "    lora_path = None\n",
    "\n",
    "print(f\"\\n🎨 Usando Midjourney LoRA: {USE_MIDJOURNEY_LORA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 CARREGAMENTO DO PIPELINE OTIMIZADO\n",
    "from diffusers import FluxPipeline\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "print(f\"📦 Carregando modelo base: {BASE_MODEL_ID}\")\n",
    "print(\"⏱️ Isso pode levar alguns minutos...\")\n",
    "\n",
    "try:\n",
    "    # Carregar pipeline FLUX.1-dev base\n",
    "    pipeline = FluxPipeline.from_pretrained(\n",
    "        BASE_MODEL_ID,\n",
    "        torch_dtype=DTYPE,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    \n",
    "    print(\"🔧 Configurando pipeline...\")\n",
    "    \n",
    "    # Otimizações de memória\n",
    "    if ENABLE_CPU_OFFLOAD:\n",
    "        pipeline.enable_model_cpu_offload()\n",
    "        print(\"💾 CPU offload ativado\")\n",
    "    else:\n",
    "        pipeline.to(\"cuda\")\n",
    "        print(\"🚀 Pipeline totalmente na GPU\")\n",
    "    \n",
    "    # SEQUENTIAL LORA APPLICATION\n",
    "    # 1️⃣ Primeiro: Carregar NSFW LoRA do HuggingFace\n",
    "    print(f\"\\n🔥 Aplicando NSFW LoRA: {NSFW_LORA_ID}\")\n",
    "    print(\"📥 Baixando do HuggingFace...\")\n",
    "    pipeline.load_lora_weights(NSFW_LORA_ID, adapter_name=\"nsfw\")\n",
    "    print(f\"✅ NSFW LoRA aplicada com peso {NSFW_LORA_WEIGHT}\")\n",
    "    \n",
    "    # 2️⃣ Segundo: Carregar Midjourney LoRA se disponível\n",
    "    lora_adapters = [\"nsfw\"]\n",
    "    lora_weights = [NSFW_LORA_WEIGHT]\n",
    "    \n",
    "    if USE_MIDJOURNEY_LORA and lora_path:\n",
    "        print(f\"\\n🎨 Aplicando Midjourney LoRA: {lora_path}\")\n",
    "        pipeline.load_lora_weights(lora_path, adapter_name=\"midjourney\")\n",
    "        lora_adapters.append(\"midjourney\")\n",
    "        lora_weights.append(MIDJOURNEY_LORA_WEIGHT)\n",
    "        print(f\"✅ Midjourney LoRA aplicada com peso {MIDJOURNEY_LORA_WEIGHT}\")\n",
    "    \n",
    "    # Configurar adaptadores sequenciais\n",
    "    pipeline.set_adapters(lora_adapters, adapter_weights=lora_weights)\n",
    "    \n",
    "    print(f\"\\n🎯 Pipeline configurado com:\")\n",
    "    print(f\"   • Base: {BASE_MODEL_ID}\")\n",
    "    print(f\"   • LoRAs: {' + '.join(lora_adapters)}\")\n",
    "    print(f\"   • Pesos: {lora_weights}\")\n",
    "    print(\"\\n🚀 Pipeline pronto para geração de máxima qualidade!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao carregar pipeline: {e}\")\n",
    "    raise\n",
    "\n",
    "# Limpeza de memória\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"🧹 Memória otimizada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8450b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎨 GERAÇÃO DO DATASET DE ALTA QUALIDADE\n",
    "import time\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "print(\"🚀 INICIANDO GERAÇÃO DO DATASET PREMIUM\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📊 Configurações:\")\n",
    "print(f\"   • Resolução: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"   • Inference Steps: {INFERENCE_STEPS}\")\n",
    "print(f\"   • Guidance Scale: {GUIDANCE_SCALE}\")\n",
    "print(f\"   • Base Model: {BASE_MODEL_ID}\")\n",
    "print(f\"   • NSFW LoRA: {NSFW_LORA_ID} (peso: {NSFW_LORA_WEIGHT})\")\n",
    "if USE_MIDJOURNEY_LORA:\n",
    "    print(f\"   • Midjourney LoRA: {MIDJOURNEY_LORA_FILENAME} (peso: {MIDJOURNEY_LORA_WEIGHT})\")\n",
    "else:\n",
    "    print(f\"   • Midjourney LoRA: Não usado\")\n",
    "print(f\"   • Imagens: {NUM_IMAGES}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "generated_images = []\n",
    "metadata = []\n",
    "\n",
    "for i, (prompt, seed) in enumerate(zip(DATASET_PROMPTS, SEEDS), 1):\n",
    "    print(f\"\\n🖼️ Gerando imagem {i}/{NUM_IMAGES} (seed: {seed})\")\n",
    "    print(f\"🎭 Variação: {['Frontal Studio', 'Three-quarter Natural', 'Profile Artistic', 'Looking Up Golden', 'Close-up Fashion', 'Reference Frontal'][i-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Geração com parâmetros premium\n",
    "        image = pipeline(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=INFERENCE_STEPS,\n",
    "            guidance_scale=GUIDANCE_SCALE,\n",
    "            width=RESOLUTION,\n",
    "            height=RESOLUTION,\n",
    "            generator=torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "        ).images[0]\n",
    "        \n",
    "        # Salvar imagem\n",
    "        filename = f\"valentina_dataset_{i:02d}.png\"\n",
    "        filepath = f\"{COLAB_DATASET_PATH}/{filename}\"\n",
    "        image.save(filepath)\n",
    "        \n",
    "        # Metadados\n",
    "        meta = {\n",
    "            \"image\": filename,\n",
    "            \"prompt\": prompt,\n",
    "            \"seed\": seed,\n",
    "            \"steps\": INFERENCE_STEPS,\n",
    "            \"guidance\": GUIDANCE_SCALE,\n",
    "            \"resolution\": f\"{RESOLUTION}x{RESOLUTION}\",\n",
    "            \"base_model\": BASE_MODEL_ID,\n",
    "            \"nsfw_lora\": NSFW_LORA_ID,\n",
    "            \"nsfw_weight\": NSFW_LORA_WEIGHT,\n",
    "            \"midjourney_lora\": USE_MIDJOURNEY_LORA,\n",
    "            \"midjourney_weight\": MIDJOURNEY_LORA_WEIGHT if USE_MIDJOURNEY_LORA else None\n",
    "        }\n",
    "        \n",
    "        generated_images.append(image)\n",
    "        metadata.append(meta)\n",
    "        \n",
    "        print(f\"✅ Imagem {i} concluída: {filepath}\")\n",
    "        \n",
    "        # Limpeza de memória a cada imagem\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro na imagem {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Tempo total\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"\\n⏱️ Tempo total: {total_time:.1f}s ({total_time/60:.1f}min)\")\n",
    "print(f\"🏆 Dataset premium concluído: {len(generated_images)}/{NUM_IMAGES} imagens\")\n",
    "\n",
    "# Salvar metadados\n",
    "metadata_path = f\"{COLAB_DATASET_PATH}/dataset_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"📊 Metadados salvos: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 CRIAÇÃO DO PACOTE FINAL PARA DOWNLOAD\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"📦 Criando pacote do dataset premium...\")\n",
    "\n",
    "# Criar README para o dataset\n",
    "readme_content = f\"\"\"# Valentina High-Quality Dataset\n",
    "\n",
    "## Informações da Geração\n",
    "- **Modelo Base**: {BASE_MODEL_ID} (máxima qualidade)\n",
    "- **NSFW LoRA**: {NSFW_LORA_ID} (peso: {NSFW_LORA_WEIGHT})\n",
    "- **Midjourney LoRA**: {'Sim' if USE_MIDJOURNEY_LORA else 'Não'}{f' (peso: {MIDJOURNEY_LORA_WEIGHT})' if USE_MIDJOURNEY_LORA else ''}\n",
    "- **Arquitetura**: Sequential LoRA (Base + NSFW + {f'Midjourney' if USE_MIDJOURNEY_LORA else 'N/A'})\n",
    "- **GPU**: {GPU_NAME} com {INFERENCE_STEPS} steps\n",
    "- **Resolução**: {RESOLUTION}x{RESOLUTION}\n",
    "- **Guidance Scale**: {GUIDANCE_SCALE}\n",
    "- **Total de Imagens**: {len(generated_images)}\n",
    "\n",
    "## Arquitetura Sequential LoRA\n",
    "1. **Base Model**: FLUX.1-dev (modelo oficial Black Forest Labs)\n",
    "2. **1º LoRA**: NSFW_MASTER_FLUX (HuggingFace automático)\n",
    "3. **2º LoRA**: Midjourney LoRA {'(aplicada)' if USE_MIDJOURNEY_LORA else '(não aplicada)'}\n",
    "\n",
    "## Variações Incluídas\n",
    "1. **Frontal Studio**: Headshot profissional, fundo branco\n",
    "2. **Three-quarter Natural**: Ângulo 3/4, luz natural\n",
    "3. **Profile Artistic**: Perfil dramático, rim lighting\n",
    "4. **Looking Up Golden**: Perspectiva inferior, golden hour\n",
    "5. **Close-up Fashion**: Close-up intenso, fashion style\n",
    "6. **Reference Frontal**: Referência frontal limpa\n",
    "\n",
    "## Qualidade Premium\n",
    "- Gerado no Google Colab com {GPU_NAME}\n",
    "- {INFERENCE_STEPS} steps de inferência para máxima qualidade\n",
    "- FLUX.1-dev base model + Sequential LoRAs\n",
    "- Controle independente de pesos dos LoRAs\n",
    "- Múltiplas poses e iluminações para dataset diverso\n",
    "\n",
    "## Uso Recomendado\n",
    "- **Treinamento LoRA**: Substitua o dataset original por este\n",
    "- **Trigger Word**: vltna woman\n",
    "- **Qualidade**: Superior para treinamento de alta fidelidade\n",
    "- **Vantagem**: Base model FLUX.1-dev + LoRAs sequenciais = qualidade máxima\n",
    "\n",
    "---\n",
    "Gerado em: {time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n",
    "Tempo de geração: {total_time:.2f} segundos\n",
    "\"\"\"\n",
    "\n",
    "readme_path = f\"{COLAB_OUTPUT_PATH}/README.md\"\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "# Criar ZIP com tudo\n",
    "zip_filename = \"valentina_hq_dataset_flux_sequential.zip\"\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:\n",
    "    # Adicionar todas as imagens\n",
    "    for i, img_file in enumerate([f\"valentina_dataset_{j:02d}.png\" for j in range(1, len(generated_images)+1)]):\n",
    "        img_path = f\"{COLAB_DATASET_PATH}/{img_file}\"\n",
    "        if os.path.exists(img_path):\n",
    "            zipf.write(img_path, f\"images/{img_file}\")\n",
    "    \n",
    "    # Adicionar metadados\n",
    "    zipf.write(metadata_path, \"metadata/dataset_metadata.json\")\n",
    "    \n",
    "    # Adicionar README\n",
    "    zipf.write(readme_path, \"README.md\")\n",
    "\n",
    "# Verificar tamanho final\n",
    "zip_size_mb = os.path.getsize(zip_filename) / (1024*1024)\n",
    "print(f\"✅ Pacote criado: {zip_filename} ({zip_size_mb:.1f}MB)\")\n",
    "\n",
    "# Listar conteúdo\n",
    "print(f\"\\n📋 Conteúdo do dataset:\")\n",
    "print(f\"   • {len(generated_images)} imagens PNG em alta resolução\")\n",
    "print(f\"   • Metadados JSON com configurações\")\n",
    "print(f\"   • README com documentação completa\")\n",
    "\n",
    "print(f\"\\n🎯 RESUMO DO DATASET PREMIUM:\")\n",
    "print(f\"📊 {len(generated_images)} imagens em qualidade máxima\")\n",
    "print(f\"⚡ {INFERENCE_STEPS} steps com {GPU_NAME}\")\n",
    "print(f\"🎨 FLUX.1-dev + Sequential LoRAs (NSFW + {'Midjourney' if USE_MIDJOURNEY_LORA else 'N/A'})\")\n",
    "print(f\"📀 Resolução {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"🎭 6 variações de pose e iluminação\")\n",
    "print(f\"🔥 Qualidade superior ao dataset MacBook M3\")\n",
    "\n",
    "print(f\"\\n📥 Baixando dataset premium...\")\n",
    "files.download(zip_filename)\n",
    "\n",
    "print(f\"\\n🎉 DATASET DE ALTA QUALIDADE PRONTO!\")\n",
    "print(f\"💡 Substitua o dataset original por este para melhor qualidade de treinamento\")\n",
    "print(f\"🚀 Use este dataset no notebook de treinamento para resultados superiores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae569745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 LIMPEZA OPCIONAL (DESCOMENTE PARA LIBERAR MEMÓRIA)\n",
    "# print(\"🧹 Limpando memória...\")\n",
    "# del pipeline\n",
    "# torch.cuda.empty_cache()\n",
    "# print(\"✅ Memória liberada\")\n",
    "\n",
    "print(\"\\n🎯 GERAÇÃO COMPLETA!\")\n",
    "print(\"📋 Próximos passos:\")\n",
    "print(\"1. Baixe o arquivo valentina_hq_dataset.zip\")\n",
    "print(\"2. Substitua o dataset original por este\")\n",
    "print(\"3. Execute o notebook de treinamento LoRA\")\n",
    "print(\"4. Aproveite a qualidade superior!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
