{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e554695c",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Valentina High-Quality Dataset Generator - Google Colab\n",
    "\n",
    "Este notebook gera um dataset de **alta qualidade** para treinar a LoRA facial da Valentina usando a GPU superior do Google Colab.\n",
    "\n",
    "## ðŸš€ Vantagens do Colab:\n",
    "- **40-50 inference steps** vs 8 no MacBook\n",
    "- **ResoluÃ§Ã£o superior** (1024x1024+)\n",
    "- **Melhor qualidade** de detalhes faciais\n",
    "- **MÃºltiplas variaÃ§Ãµes** profissionais\n",
    "\n",
    "## ðŸ“‹ Stack Utilizada:\n",
    "- **Base**: FLUX.1-dev (mÃ¡xima qualidade)\n",
    "- **1Âº LoRA**: NSFW_MASTER_FLUX (capacidades NSFW)\n",
    "- **2Âº LoRA**: Midjourney LoRA (qualidade cinematogrÃ¡fica)\n",
    "- **GPU**: A100 optimized com 50 inference steps\n",
    "- **Output**: 6 imagens de referÃªncia premium sequenciais\n",
    "\n",
    "âš ï¸ **Execute as cÃ©lulas em ordem para gerar o dataset otimizado!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d621281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ CONFIGURAÃ‡Ã•ES PARA GERAÃ‡ÃƒO DE ALTA QUALIDADE - FLUX.1-dev + LoRAs Sequenciais\n",
    "\n",
    "# Modelo base e LoRAs sequenciais\n",
    "BASE_MODEL_ID = \"black-forest-labs/FLUX.1-dev\"  # Base model para mÃ¡xima qualidade\n",
    "NSFW_LORA_ID = \"Keltezaa/NSFW_MASTER_FLUX\"       # Primeiro LoRA: NSFW\n",
    "MIDJOURNEY_LORA_FILENAME = \"midjourney_LORA.safetensors\"  # Segundo LoRA: Midjourney (local)\n",
    "\n",
    "# ConfiguraÃ§Ãµes de qualidade PREMIUM (A100 Optimized)\n",
    "INFERENCE_STEPS = 50      # MÃ¡xima qualidade possÃ­vel na A100\n",
    "GUIDANCE_SCALE = 7.5      # BalanÃ§o ideal qualidade/criatividade  \n",
    "RESOLUTION = 1024         # ResoluÃ§Ã£o mÃ¡xima para detalhes\n",
    "NSFW_LORA_WEIGHT = 0.8    # Peso do primeiro LoRA (NSFW)\n",
    "MIDJOURNEY_LORA_WEIGHT = 0.7  # Peso do segundo LoRA (Midjourney)\n",
    "\n",
    "# ConfiguraÃ§Ãµes de diversidade\n",
    "NUM_IMAGES = 6        # 6 variaÃ§Ãµes diversas\n",
    "SEEDS = [42, 7777, 12345, 98765, 55555, 33333]  # Seeds especÃ­ficas\n",
    "\n",
    "# Prompts especializados para dataset\n",
    "BASE_CHARACTERISTICS = \"\"\"A stunning 23-year-old woman named Valentina Moreau. Oval face with delicately defined jawline and prominent cheekbones, large almond-shaped deep brown expressive eyes with long dark lashes, perfectly arched eyebrows, full plump lips with pronounced cupid's bow in natural pink tone, straight proportional nose with slightly tapered tip. Flawless sun-kissed golden-olive skin with healthy glow. Rich dark brown hair with subtle chocolate and mahogany highlights, long flowing past shoulders with voluminous natural waves, dense and shiny hair. Curvy and toned silhouette, confident posture.\"\"\"\n",
    "\n",
    "# VariaÃ§Ãµes de pose e iluminaÃ§Ã£o para dataset diverso\n",
    "DATASET_PROMPTS = [\n",
    "    f\"{BASE_CHARACTERISTICS} Professional headshot, direct gaze, neutral expression, studio lighting, white background, hyperrealistic portrait photography, 8k resolution, commercial photography\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Three-quarter angle portrait, subtle smile, natural daylight, window lighting, elegant and sophisticated, professional photography, high detail, photorealistic\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Side profile portrait, looking away, dramatic rim lighting, dark background, artistic portrait, professional studio photography, cinematic lighting, ultra detailed\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Looking up perspective, gentle smile, golden hour lighting, outdoor natural light, warm tones, Instagram-worthy, glamour photography, high quality\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Close-up portrait, intense direct gaze, soft box lighting, professional makeup, fashion photography style, magazine quality, hyperrealistic details\",\n",
    "    \n",
    "    f\"{BASE_CHARACTERISTICS} Full face frontal view, serene expression, balanced lighting, neutral background, reference photo style, documentary photography, crystal clear details\"\n",
    "]\n",
    "\n",
    "# Paths no Colab\n",
    "COLAB_MODELS_PATH = \"/content/models\"\n",
    "COLAB_OUTPUT_PATH = \"/content/valentina_hq_dataset\"\n",
    "\n",
    "print(\"ðŸŽ¨ ConfiguraÃ§Ãµes de ALTA QUALIDADE carregadas:\")\n",
    "print(f\"ðŸ“Š Inference Steps: {INFERENCE_STEPS} (vs 8 no MacBook)\")\n",
    "print(f\"ðŸŽ¯ ResoluÃ§Ã£o: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"ðŸ–¼ï¸  Imagens a gerar: {NUM_IMAGES}\")\n",
    "print(f\"ðŸŽ­ VariaÃ§Ãµes: poses, Ã¢ngulos e iluminaÃ§Ãµes diversos\")\n",
    "print(f\"â­ Qualidade: PREMIUM para treinamento superior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03453d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ INSTALAÃ‡ÃƒO OTIMIZADA DE DEPENDÃŠNCIAS VIA UV\n",
    "print(\"ðŸ”§ Instalando dependÃªncias usando uv para maior robustez...\")\n",
    "\n",
    "# 1. Instalar uv\n",
    "print(\"âš™ï¸ Instalando uv...\")\n",
    "!pip install -q uv\n",
    "print(\"âœ… uv instalado.\")\n",
    "\n",
    "# 2. Definir o conteÃºdo do requirements.txt baseado no pyproject.toml\n",
    "requirements_content = \"\"\"\\\n",
    "torch>=2.1.0,<2.4.0\n",
    "torchvision>=0.16.0,<0.19.0\n",
    "torchaudio>=2.1.0,<2.4.0\n",
    "diffusers[torch]>=0.27.0,<1.0\n",
    "transformers>=4.44.0,<5.0\n",
    "accelerate>=0.32.0,<1.0\n",
    "safetensors>=0.4.0,<0.5.0\n",
    "xformers>=0.0.27,<0.0.29\n",
    "pillow>=10.0.0,<11.0.0\n",
    "opencv-python>=4.10.0,<5.0\n",
    "huggingface-hub>=0.24.5,<1.0\n",
    "sentencepiece>=0.2.0,<0.3.0\n",
    "tokenizers>=0.19.0,<0.20.0\n",
    "protobuf>=5.27.0,<6.0.0\n",
    "numpy>=2.0.0,<3.0.0\n",
    "requests>=2.32.0,<3.0.0\n",
    "scipy>=1.14.0,<2.0.0\n",
    "matplotlib>=3.9.0,<4.0.0\n",
    "omegaconf>=2.3.0,<3.0.0\n",
    "einops>=0.8.0,<0.9.0\n",
    "invisible-watermark>=0.2.0,<0.3.0\n",
    "compel>=2.0.0,<3.0.0\n",
    "wandb>=0.17.0,<0.18.0\n",
    "peft>=0.12.0,<0.13.0\n",
    "bitsandbytes>=0.43.0,<0.44.0\n",
    "gradio>=4.39.0,<5.0.0\n",
    "albumentations>=1.4.0,<2.0.0\n",
    "imageio>=2.34.0,<3.0.0\n",
    "scikit-image>=0.24.0,<0.25.0\n",
    "tqdm>=4.66.0,<5.0.0\n",
    "ftfy>=6.2.0,<7.0.0\n",
    "tensorboard>=2.16.0,<3.0.0\n",
    "easydict>=1.13.0,<2.0.0\n",
    "clean-fid==0.1.35\n",
    "torchmetrics>=1.4.0,<2.0.0\n",
    "kornia>=0.7.0,<0.8.0\n",
    "lpips>=0.1.4,<0.2.0\n",
    "controlnet_aux>=0.0.7,<0.0.8\n",
    "segment-anything>=1.0.0,<2.0.0\n",
    "rembg[gpu]>=2.0.56,<3.0.0\n",
    "moviepy>=1.0.3,<2.0.0\n",
    "typer>=0.12.0,<0.13.0\n",
    "rich>=13.7.0,<14.0.0\n",
    "shellingham>=1.5.0,<2.0.0\n",
    "\"\"\"\n",
    "\n",
    "# 3. Criar o arquivo requirements.txt no ambiente do Colab\n",
    "requirements_file_path = \"/content/valentina_requirements.txt\"\n",
    "with open(requirements_file_path, \"w\") as f:\n",
    "    f.write(requirements_content)\n",
    "print(f\"ðŸ“„ {requirements_file_path} criado.\")\n",
    "\n",
    "# 4. Instalar dependÃªncias usando uv pip install\n",
    "print(f\"ðŸš€ Instalando dependÃªncias de {requirements_file_path} com uv...\")\n",
    "print(\"ðŸ•’ Isso pode levar alguns minutos...\")\n",
    "!uv pip install -q -r {requirements_file_path} --extra-index-url https://download.pytorch.org/whl/cu121 --index-strategy unsafe-best-match\n",
    "\n",
    "print(\"âœ… DependÃªncias instaladas com sucesso usando uv!\")\n",
    "print(\"ðŸŽ¯ Ambiente otimizado para geraÃ§Ã£o premium\")\n",
    "\n",
    "# VerificaÃ§Ã£o opcional (descomentar para depurar e ver as versÃµes instaladas)\n",
    "# print(\"\\\\nVerificando versÃµes instaladas (amostra):\")\n",
    "# !pip show torch torchvision torchaudio xformers transformers huggingface-hub opencv-python diffusers accelerate bitsandbytes clean-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ–¥ï¸ DETECÃ‡ÃƒO E OTIMIZAÃ‡ÃƒO DA GPU\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"ðŸ” Verificando GPU disponÃ­vel...\")\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits\n",
    "\n",
    "# Detectar GPU especÃ­fica\n",
    "gpu_name = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"]).decode().strip()\n",
    "print(f\"\\nðŸš€ GPU detectada: {gpu_name}\")\n",
    "\n",
    "# Otimizar configuraÃ§Ãµes baseado na GPU\n",
    "if \"T4\" in gpu_name:\n",
    "    print(\"âš¡ ConfiguraÃ§Ãµes Tesla T4 (15GB)\")\n",
    "    DTYPE = torch.float16\n",
    "    ENABLE_CPU_OFFLOAD = True\n",
    "    BATCH_SIZE = 1\n",
    "    INFERENCE_STEPS = 40  # Reduzido para T4\n",
    "elif \"V100\" in gpu_name:\n",
    "    print(\"ðŸ’Ž ConfiguraÃ§Ãµes V100 (16GB)\")\n",
    "    DTYPE = torch.float16\n",
    "    ENABLE_CPU_OFFLOAD = False\n",
    "    BATCH_SIZE = 1\n",
    "    INFERENCE_STEPS = 45  # Melhor que T4\n",
    "elif \"A100\" in gpu_name:\n",
    "    print(\"ðŸ”¥ ConfiguraÃ§Ãµes A100 PREMIUM - MÃ¡xima Qualidade\")\n",
    "    DTYPE = torch.bfloat16  # Melhor precisÃ£o na A100\n",
    "    ENABLE_CPU_OFFLOAD = False\n",
    "    BATCH_SIZE = 1  # Foco em qualidade, nÃ£o velocidade\n",
    "    INFERENCE_STEPS = 50  # MÃ¡xima qualidade possÃ­vel\n",
    "    print(\"ðŸŽ¯ A100 detectada: Configurando para mÃ¡xima qualidade com LoRAs sequenciais\")\n",
    "elif \"H100\" in gpu_name:\n",
    "    print(\"ðŸš€ ConfiguraÃ§Ãµes H100 ULTRA PREMIUM\")\n",
    "    DTYPE = torch.bfloat16\n",
    "    ENABLE_CPU_OFFLOAD = False\n",
    "    BATCH_SIZE = 2\n",
    "    INFERENCE_STEPS = 50\n",
    "else:\n",
    "    print(\"ðŸ“± ConfiguraÃ§Ãµes padrÃ£o\")\n",
    "    DTYPE = torch.float16\n",
    "    ENABLE_CPU_OFFLOAD = True\n",
    "    BATCH_SIZE = 1\n",
    "    INFERENCE_STEPS = 35\n",
    "\n",
    "print(f\"âœ… Configurado: {DTYPE}, CPU offload: {ENABLE_CPU_OFFLOAD}\")\n",
    "print(f\"ðŸŽ¯ Steps finais: {INFERENCE_STEPS}\")\n",
    "\n",
    "# Limpeza inicial\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"ðŸ§¹ MemÃ³ria GPU limpa\")\n",
    "\n",
    "# ðŸ“¦ INSTALAÃ‡ÃƒO OTIMIZADA DE DEPENDÃŠNCIAS VIA UV\n",
    "print(\"ðŸ”§ Instalando dependÃªncias usando uv para maior robustez...\")\n",
    "\n",
    "# 1. Instalar uv\n",
    "print(\"âš™ï¸ Instalando uv...\")\n",
    "!pip install -q uv\n",
    "print(\"âœ… uv instalado.\")\n",
    "\n",
    "# 2. Upload do arquivo uv.lock\n",
    "from google.colab import files\n",
    "print(\"ðŸ“¤ FaÃ§a upload do arquivo uv.lock...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# 3. Sincronizar dependÃªncias usando uv.lock com estratÃ©gia de Ã­ndice insegura\n",
    "print(\"ðŸš€ Instalando dependÃªncias com uv pip sync usando uv.lock...\")\n",
    "!uv pip sync uv.lock --index-strategy unsafe-best-match\n",
    "\n",
    "print(\"âœ… DependÃªncias instaladas com sucesso usando uv!\")\n",
    "print(\"ðŸŽ¯ Ambiente otimizado para geraÃ§Ã£o premium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” AUTENTICAÃ‡ÃƒO HUGGING FACE\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "print(\"ðŸ”‘ FaÃ§a login na sua conta Hugging Face para acessar modelos premium:\")\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ CRIAÃ‡ÃƒO DA ESTRUTURA DE DIRETÃ“RIOS\n",
    "import os\n",
    "\n",
    "directories = [\n",
    "    COLAB_MODELS_PATH,\n",
    "    COLAB_OUTPUT_PATH,\n",
    "    f\"{COLAB_OUTPUT_PATH}/metadata\"\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"ðŸ“‚ Criado: {directory}\")\n",
    "\n",
    "print(\"\\nâœ… Estrutura preparada para dataset premium!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¤ UPLOAD DA MIDJOURNEY LORA (OPCIONAL - 2Âº LORA)\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"ðŸŽ¨ Upload da Midjourney LoRA para qualidade cinematogrÃ¡fica:\")\n",
    "print(\"\\nðŸ“ Arquitetura Sequential LoRA:\")\n",
    "print(f\"   1ï¸âƒ£ Base: {BASE_MODEL_ID}\")\n",
    "print(f\"   2ï¸âƒ£ NSFW LoRA: {NSFW_LORA_ID} (automÃ¡tico)\")\n",
    "print(f\"   3ï¸âƒ£ Midjourney LoRA: {MIDJOURNEY_LORA_FILENAME} (upload opcional)\")\n",
    "print(\"\\nâš ï¸ Arquivo opcional. Se nÃ£o fornecido, usarÃ¡ apenas NSFW LoRA.\")\n",
    "print(f\"\\nðŸ“¤ Esperado: {MIDJOURNEY_LORA_FILENAME}\")\n",
    "\n",
    "uploaded_files = files.upload()\n",
    "\n",
    "if MIDJOURNEY_LORA_FILENAME in uploaded_files:\n",
    "    # Mover para pasta de modelos\n",
    "    lora_path = f\"{COLAB_MODELS_PATH}/{MIDJOURNEY_LORA_FILENAME}\"\n",
    "    shutil.move(MIDJOURNEY_LORA_FILENAME, lora_path)\n",
    "    \n",
    "    # Verificar tamanho\n",
    "    size_mb = os.path.getsize(lora_path) / (1024*1024)\n",
    "    print(f\"âœ… Midjourney LoRA carregada: {size_mb:.1f}MB\")\n",
    "    print(f\"ðŸ“ LocalizaÃ§Ã£o: {lora_path}\")\n",
    "    \n",
    "    USE_MIDJOURNEY_LORA = True\n",
    "    print(f\"\\nðŸŽ¯ ConfiguraÃ§Ã£o Final:\")\n",
    "    print(f\"   â€¢ NSFW Weight: {NSFW_LORA_WEIGHT}\")\n",
    "    print(f\"   â€¢ Midjourney Weight: {MIDJOURNEY_LORA_WEIGHT}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Midjourney LoRA nÃ£o fornecida.\")\n",
    "    print(\"ðŸš€ Continuando com configuraÃ§Ã£o: Base + NSFW LoRA\")\n",
    "    USE_MIDJOURNEY_LORA = False\n",
    "    lora_path = None\n",
    "\n",
    "print(f\"\\nðŸŽ¨ Usando Midjourney LoRA: {USE_MIDJOURNEY_LORA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ CARREGAMENTO DO PIPELINE OTIMIZADO\n",
    "from diffusers import FluxPipeline\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "print(f\"ðŸ“¦ Carregando modelo base: {BASE_MODEL_ID}\")\n",
    "print(\"â±ï¸ Isso pode levar alguns minutos...\")\n",
    "\n",
    "try:\n",
    "    # Carregar pipeline FLUX.1-dev base\n",
    "    pipeline = FluxPipeline.from_pretrained(\n",
    "        BASE_MODEL_ID,\n",
    "        torch_dtype=DTYPE,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    \n",
    "    print(\"ðŸ”§ Configurando pipeline...\")\n",
    "    \n",
    "    # OtimizaÃ§Ãµes de memÃ³ria\n",
    "    if ENABLE_CPU_OFFLOAD:\n",
    "        pipeline.enable_model_cpu_offload()\n",
    "        print(\"ðŸ’¾ CPU offload ativado\")\n",
    "    else:\n",
    "        pipeline.to(\"cuda\")\n",
    "        print(\"ðŸš€ Pipeline totalmente na GPU\")\n",
    "    \n",
    "    # SEQUENTIAL LORA APPLICATION\n",
    "    # 1ï¸âƒ£ Primeiro: Carregar NSFW LoRA do HuggingFace\n",
    "    print(f\"\\nðŸ”¥ Aplicando NSFW LoRA: {NSFW_LORA_ID}\")\n",
    "    print(\"ðŸ“¥ Baixando do HuggingFace...\")\n",
    "    pipeline.load_lora_weights(NSFW_LORA_ID, adapter_name=\"nsfw\")\n",
    "    print(f\"âœ… NSFW LoRA aplicada com peso {NSFW_LORA_WEIGHT}\")\n",
    "    \n",
    "    # 2ï¸âƒ£ Segundo: Carregar Midjourney LoRA se disponÃ­vel\n",
    "    lora_adapters = [\"nsfw\"]\n",
    "    lora_weights = [NSFW_LORA_WEIGHT]\n",
    "    \n",
    "    if USE_MIDJOURNEY_LORA and lora_path:\n",
    "        print(f\"\\nðŸŽ¨ Aplicando Midjourney LoRA: {lora_path}\")\n",
    "        pipeline.load_lora_weights(lora_path, adapter_name=\"midjourney\")\n",
    "        lora_adapters.append(\"midjourney\")\n",
    "        lora_weights.append(MIDJOURNEY_LORA_WEIGHT)\n",
    "        print(f\"âœ… Midjourney LoRA aplicada com peso {MIDJOURNEY_LORA_WEIGHT}\")\n",
    "    \n",
    "    # Configurar adaptadores sequenciais\n",
    "    pipeline.set_adapters(lora_adapters, adapter_weights=lora_weights)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Pipeline configurado com:\")\n",
    "    print(f\"   â€¢ Base: {BASE_MODEL_ID}\")\n",
    "    print(f\"   â€¢ LoRAs: {' + '.join(lora_adapters)}\")\n",
    "    print(f\"   â€¢ Pesos: {lora_weights}\")\n",
    "    print(\"\\nðŸš€ Pipeline pronto para geraÃ§Ã£o de mÃ¡xima qualidade!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao carregar pipeline: {e}\")\n",
    "    raise\n",
    "\n",
    "# Limpeza de memÃ³ria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"ðŸ§¹ MemÃ³ria otimizada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8450b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¨ GERAÃ‡ÃƒO DO DATASET DE ALTA QUALIDADE\n",
    "import time\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "print(\"ðŸš€ INICIANDO GERAÃ‡ÃƒO DO DATASET PREMIUM\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸ“Š ConfiguraÃ§Ãµes:\")\n",
    "print(f\"   â€¢ ResoluÃ§Ã£o: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"   â€¢ Inference Steps: {INFERENCE_STEPS}\")\n",
    "print(f\"   â€¢ Guidance Scale: {GUIDANCE_SCALE}\")\n",
    "print(f\"   â€¢ Base Model: {BASE_MODEL_ID}\")\n",
    "print(f\"   â€¢ NSFW LoRA: {NSFW_LORA_ID} (peso: {NSFW_LORA_WEIGHT})\")\n",
    "if USE_MIDJOURNEY_LORA:\n",
    "    print(f\"   â€¢ Midjourney LoRA: {MIDJOURNEY_LORA_FILENAME} (peso: {MIDJOURNEY_LORA_WEIGHT})\")\n",
    "else:\n",
    "    print(f\"   â€¢ Midjourney LoRA: NÃ£o usado\")\n",
    "print(f\"   â€¢ Imagens: {NUM_IMAGES}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "generated_images = []\n",
    "metadata = []\n",
    "\n",
    "for i, (prompt, seed) in enumerate(zip(DATASET_PROMPTS, SEEDS), 1):\n",
    "    print(f\"\\nðŸ–¼ï¸ Gerando imagem {i}/{NUM_IMAGES} (seed: {seed})\")\n",
    "    print(f\"ðŸŽ­ VariaÃ§Ã£o: {['Frontal Studio', 'Three-quarter Natural', 'Profile Artistic', 'Looking Up Golden', 'Close-up Fashion', 'Reference Frontal'][i-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # GeraÃ§Ã£o com parÃ¢metros premium\n",
    "        image = pipeline(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=INFERENCE_STEPS,\n",
    "            guidance_scale=GUIDANCE_SCALE,\n",
    "            width=RESOLUTION,\n",
    "            height=RESOLUTION,\n",
    "            generator=torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "        ).images[0]\n",
    "        \n",
    "        # Salvar imagem\n",
    "        filename = f\"valentina_dataset_{i:02d}.png\"\n",
    "        filepath = f\"{COLAB_DATASET_PATH}/{filename}\"\n",
    "        image.save(filepath)\n",
    "        \n",
    "        # Metadados\n",
    "        meta = {\n",
    "            \"image\": filename,\n",
    "            \"prompt\": prompt,\n",
    "            \"seed\": seed,\n",
    "            \"steps\": INFERENCE_STEPS,\n",
    "            \"guidance\": GUIDANCE_SCALE,\n",
    "            \"resolution\": f\"{RESOLUTION}x{RESOLUTION}\",\n",
    "            \"base_model\": BASE_MODEL_ID,\n",
    "            \"nsfw_lora\": NSFW_LORA_ID,\n",
    "            \"nsfw_weight\": NSFW_LORA_WEIGHT,\n",
    "            \"midjourney_lora\": USE_MIDJOURNEY_LORA,\n",
    "            \"midjourney_weight\": MIDJOURNEY_LORA_WEIGHT if USE_MIDJOURNEY_LORA else None\n",
    "        }\n",
    "        \n",
    "        generated_images.append(image)\n",
    "        metadata.append(meta)\n",
    "        \n",
    "        print(f\"âœ… Imagem {i} concluÃ­da: {filepath}\")\n",
    "        \n",
    "        # Limpeza de memÃ³ria a cada imagem\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro na imagem {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Tempo total\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"\\nâ±ï¸ Tempo total: {total_time:.1f}s ({total_time/60:.1f}min)\")\n",
    "print(f\"ðŸ† Dataset premium concluÃ­do: {len(generated_images)}/{NUM_IMAGES} imagens\")\n",
    "\n",
    "# Salvar metadados\n",
    "metadata_path = f\"{COLAB_DATASET_PATH}/dataset_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"ðŸ“Š Metadados salvos: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ CRIAÃ‡ÃƒO DO PACOTE FINAL PARA DOWNLOAD\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"ðŸ“¦ Criando pacote do dataset premium...\")\n",
    "\n",
    "# Criar README para o dataset\n",
    "readme_content = f\"\"\"# Valentina High-Quality Dataset\n",
    "\n",
    "## InformaÃ§Ãµes da GeraÃ§Ã£o\n",
    "- **Modelo Base**: {BASE_MODEL_ID} (mÃ¡xima qualidade)\n",
    "- **NSFW LoRA**: {NSFW_LORA_ID} (peso: {NSFW_LORA_WEIGHT})\n",
    "- **Midjourney LoRA**: {'Sim' if USE_MIDJOURNEY_LORA else 'NÃ£o'}{f' (peso: {MIDJOURNEY_LORA_WEIGHT})' if USE_MIDJOURNEY_LORA else ''}\n",
    "- **Arquitetura**: Sequential LoRA (Base + NSFW + {f'Midjourney' if USE_MIDJOURNEY_LORA else 'N/A'})\n",
    "- **GPU**: {GPU_NAME} com {INFERENCE_STEPS} steps\n",
    "- **ResoluÃ§Ã£o**: {RESOLUTION}x{RESOLUTION}\n",
    "- **Guidance Scale**: {GUIDANCE_SCALE}\n",
    "- **Total de Imagens**: {len(generated_images)}\n",
    "\n",
    "## Arquitetura Sequential LoRA\n",
    "1. **Base Model**: FLUX.1-dev (modelo oficial Black Forest Labs)\n",
    "2. **1Âº LoRA**: NSFW_MASTER_FLUX (HuggingFace automÃ¡tico)\n",
    "3. **2Âº LoRA**: Midjourney LoRA {'(aplicada)' if USE_MIDJOURNEY_LORA else '(nÃ£o aplicada)'}\n",
    "\n",
    "## VariaÃ§Ãµes IncluÃ­das\n",
    "1. **Frontal Studio**: Headshot profissional, fundo branco\n",
    "2. **Three-quarter Natural**: Ã‚ngulo 3/4, luz natural\n",
    "3. **Profile Artistic**: Perfil dramÃ¡tico, rim lighting\n",
    "4. **Looking Up Golden**: Perspectiva inferior, golden hour\n",
    "5. **Close-up Fashion**: Close-up intenso, fashion style\n",
    "6. **Reference Frontal**: ReferÃªncia frontal limpa\n",
    "\n",
    "## Qualidade Premium\n",
    "- Gerado no Google Colab com {GPU_NAME}\n",
    "- {INFERENCE_STEPS} steps de inferÃªncia para mÃ¡xima qualidade\n",
    "- FLUX.1-dev base model + Sequential LoRAs\n",
    "- Controle independente de pesos dos LoRAs\n",
    "- MÃºltiplas poses e iluminaÃ§Ãµes para dataset diverso\n",
    "\n",
    "## Uso Recomendado\n",
    "- **Treinamento LoRA**: Substitua o dataset original por este\n",
    "- **Trigger Word**: vltna woman\n",
    "- **Qualidade**: Superior para treinamento de alta fidelidade\n",
    "- **Vantagem**: Base model FLUX.1-dev + LoRAs sequenciais = qualidade mÃ¡xima\n",
    "\n",
    "---\n",
    "Gerado em: {time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n",
    "Tempo de geraÃ§Ã£o: {total_time:.2f} segundos\n",
    "\"\"\"\n",
    "\n",
    "readme_path = f\"{COLAB_OUTPUT_PATH}/README.md\"\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "# Criar ZIP com tudo\n",
    "zip_filename = \"valentina_hq_dataset_flux_sequential.zip\"\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:\n",
    "    # Adicionar todas as imagens\n",
    "    for i, img_file in enumerate([f\"valentina_dataset_{j:02d}.png\" for j in range(1, len(generated_images)+1)]):\n",
    "        img_path = f\"{COLAB_DATASET_PATH}/{img_file}\"\n",
    "        if os.path.exists(img_path):\n",
    "            zipf.write(img_path, f\"images/{img_file}\")\n",
    "    \n",
    "    # Adicionar metadados\n",
    "    zipf.write(metadata_path, \"metadata/dataset_metadata.json\")\n",
    "    \n",
    "    # Adicionar README\n",
    "    zipf.write(readme_path, \"README.md\")\n",
    "\n",
    "# Verificar tamanho final\n",
    "zip_size_mb = os.path.getsize(zip_filename) / (1024*1024)\n",
    "print(f\"âœ… Pacote criado: {zip_filename} ({zip_size_mb:.1f}MB)\")\n",
    "\n",
    "# Listar conteÃºdo\n",
    "print(f\"\\nðŸ“‹ ConteÃºdo do dataset:\")\n",
    "print(f\"   â€¢ {len(generated_images)} imagens PNG em alta resoluÃ§Ã£o\")\n",
    "print(f\"   â€¢ Metadados JSON com configuraÃ§Ãµes\")\n",
    "print(f\"   â€¢ README com documentaÃ§Ã£o completa\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ RESUMO DO DATASET PREMIUM:\")\n",
    "print(f\"ðŸ“Š {len(generated_images)} imagens em qualidade mÃ¡xima\")\n",
    "print(f\"âš¡ {INFERENCE_STEPS} steps com {GPU_NAME}\")\n",
    "print(f\"ðŸŽ¨ FLUX.1-dev + Sequential LoRAs (NSFW + {'Midjourney' if USE_MIDJOURNEY_LORA else 'N/A'})\")\n",
    "print(f\"ðŸ“€ ResoluÃ§Ã£o {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"ðŸŽ­ 6 variaÃ§Ãµes de pose e iluminaÃ§Ã£o\")\n",
    "print(f\"ðŸ”¥ Qualidade superior ao dataset MacBook M3\")\n",
    "\n",
    "print(f\"\\nðŸ“¥ Baixando dataset premium...\")\n",
    "files.download(zip_filename)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ DATASET DE ALTA QUALIDADE PRONTO!\")\n",
    "print(f\"ðŸ’¡ Substitua o dataset original por este para melhor qualidade de treinamento\")\n",
    "print(f\"ðŸš€ Use este dataset no notebook de treinamento para resultados superiores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae569745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¹ LIMPEZA OPCIONAL (DESCOMENTE PARA LIBERAR MEMÃ“RIA)\n",
    "# print(\"ðŸ§¹ Limpando memÃ³ria...\")\n",
    "# del pipeline\n",
    "# torch.cuda.empty_cache()\n",
    "# print(\"âœ… MemÃ³ria liberada\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ GERAÃ‡ÃƒO COMPLETA!\")\n",
    "print(\"ðŸ“‹ PrÃ³ximos passos:\")\n",
    "print(\"1. Baixe o arquivo valentina_hq_dataset.zip\")\n",
    "print(\"2. Substitua o dataset original por este\")\n",
    "print(\"3. Execute o notebook de treinamento LoRA\")\n",
    "print(\"4. Aproveite a qualidade superior!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
